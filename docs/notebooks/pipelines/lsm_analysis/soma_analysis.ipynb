{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soma Detection Analysis of Whole-Brain Light-Sheet Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Before Using this notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install brainlit, and other packages that this notebook uses\n",
    "### 1b. Write images to s3 using CloudReg\n",
    "    - e.g. python -m cloudreg.scripts.create_precomputed_volumes --s3_input_paths /mnt/NAS/SmartSPIM_Data/2022_03_02/20220302_14_40_04_8529_destriped_DONE/Ex_561_Em_600_stitched --s3_output_paths  s3://smartspim-precomputed-volumes/2022_03_02/8529/Ch_561_v2  --voxel_size 1.83 1.83 2 --num_procs 24 --resample_iso False\n",
    "### 1c. Make point annotations in neuroglancer to identify subvolumes for validation (and possible training)\n",
    "    - instructions: https://neurodata.io/help/neuroglancer-pt-annotations/\n",
    "    ,\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"soma_val\",\n",
    "    \"points\": []\n",
    "    },\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"nonsoma_val\",\n",
    "    \"points\":[]\n",
    "    }\n",
    "### 1d. Update soma_data.py file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibody_layer = \"Ch_647\"\n",
    "background_layer = \"Ch_561\"\n",
    "endogenous_layer = \"Ch_488\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "from skimage import io, measure\n",
    "import napari\n",
    "import random\n",
    "import h5py\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import tables\n",
    "from napari_animation import AnimationWidget\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from parse_ara import *\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "import pandas as pd\n",
    "import brainrender\n",
    "from skimage.morphology import skeletonize\n",
    "from soma_data import brain2paths, brain2centers\n",
    "import os\n",
    "from util import json_to_points, find_atlas_level_label, fold\n",
    "import scipy.ndimage as ndi\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "from cloudreg.scripts.transform_points import NGLink\n",
    "\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in brain2paths.keys():\n",
    "    if \"base\" in brain2paths[id].keys() and \"val_info\" in brain2paths[id].keys():\n",
    "        base = brain2paths[id][\"base\"]\n",
    "        if \"http\" in base:\n",
    "            print(f\"Sample {id}: http in basepath, which may cause write errors\")\n",
    "        for layer in [antibody_layer, background_layer, endogenous_layer]:\n",
    "            try:\n",
    "                CloudVolume(base + layer)\n",
    "            except:\n",
    "                print(f\"Sample {id}: Layer {layer} not found in {base}\")\n",
    "\n",
    "        try:\n",
    "            url = brain2paths[id][\"val_info\"][\"url\"]\n",
    "            layer = brain2paths[id][\"val_info\"][\"somas_layer\"]\n",
    "            layer = brain2paths[id][\"val_info\"][\"nonsomas_layer\"]\n",
    "            pts = json_to_points(url)[layer]\n",
    "        except:\n",
    "            print(f\"Sample {id}: Error with val_info\")\n",
    "\n",
    "        if \"train_info\" in brain2paths[id].keys():\n",
    "            try:\n",
    "                url = brain2paths[id][\"train_info\"][\"url\"]\n",
    "                layer = brain2paths[id][\"train_info\"][\"layer\"]\n",
    "                pts = json_to_points(url)[layer]\n",
    "            except:\n",
    "                print(f\"Sample {id}: Error with train_info\")\n",
    "    else:\n",
    "        print(f\"Sample {id}: Does not conform to desired format\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download benchmark data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"8446\"  # brain ID\n",
    "axon_data_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/\"  # path to directory where training/validation data should be stored\n",
    "dataset_to_save = \"train\"  # train or val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful variables\n",
    "base_dir = axon_data_dir + \"brain\" + brain + \"/\" + dataset_to_save + \"/\"\n",
    "\n",
    "if brain not in brain2paths.keys():\n",
    "    raise ValueError(f\"brain {brain} not an entry in brain2paths in axon_data.py file\")\n",
    "\n",
    "if f\"{dataset_to_save}_info\" not in brain2paths[\n",
    "    brain\n",
    "].keys() or dataset_to_save not in [\"train\", \"val\"]:\n",
    "    raise ValueError(f\"{dataset_to_save}_info not in brain2paths[{brain}].keys()\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"val_info\" in brain2paths[brain].keys():\n",
    "    if dataset_to_save == \"val\":\n",
    "        url = brain2paths[brain][\"val_info\"][\"url\"]\n",
    "        l_dict = json_to_points(url)\n",
    "        soma_centers = l_dict[brain2paths[brain][\"val_info\"][\"somas_layer\"]]\n",
    "        nonsoma_centers = l_dict[brain2paths[brain][\"val_info\"][\"nonsomas_layer\"]]\n",
    "    elif dataset_to_save == \"train\":\n",
    "        url = brain2paths[brain][\"train_info\"][\"url\"]\n",
    "        l_dict = json_to_points(url)\n",
    "        soma_centers = l_dict[brain2paths[brain][\"train_info\"][\"somas_layer\"]]\n",
    "        nonsoma_centers = l_dict[brain2paths[brain][\"train_info\"][\"nonsomas_layer\"]]\n",
    "elif \"vizlink\" in brain2paths[brain]:\n",
    "    url = brain2paths[brain][\"vizlink\"]\n",
    "    l_dict = json_to_points(url)\n",
    "    if dataset_to_save == \"val\":\n",
    "        soma_centers = l_dict[\"soma_val\"]\n",
    "        nonsoma_centers = l_dict[\"nonsoma_val\"]\n",
    "    elif dataset_to_save == \"train\":\n",
    "        soma_centers = l_dict[\"soma_train\"]\n",
    "        nonsoma_centers = l_dict[\"nonsoma_train\"]\n",
    "    elif dataset_to_save == \"train-obj\":\n",
    "        soma_centers = l_dict[\"soma_train_obj\"]\n",
    "        nonsoma_centers = l_dict[\"nonsoma_train_obj\"]\n",
    "elif brain in brain2centers.keys():\n",
    "    soma_centers = brain2centers[brain][0][0]\n",
    "    nonsoma_centers = brain2centers[brain][1][0]\n",
    "else:\n",
    "    print(\"No training/validation points\")\n",
    "\n",
    "print(f\"{len(soma_centers)} soma centers\")\n",
    "print(f\"{len(nonsoma_centers)} nonsoma centers\")\n",
    "\n",
    "mip = 0\n",
    "if \"base\" in brain2paths[brain].keys():\n",
    "    base_dir_s3 = brain2paths[brain][\"base\"]\n",
    "    dir = base_dir_s3 + antibody_layer\n",
    "    vol_fg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"fg shape: {vol_fg.shape} at {vol_fg.resolution}\")\n",
    "    dir = base_dir_s3 + background_layer\n",
    "    vol_bg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"bg shape: {vol_bg.shape} at {vol_bg.resolution}\")\n",
    "    dir = base_dir_s3 + endogenous_layer\n",
    "    vol_endo = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"endo shape: {vol_endo.shape} at {vol_endo.resolution}\")\n",
    "else:\n",
    "    dir = brain2paths[brain][\"ab\"]\n",
    "    vol_fg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"fg shape: {vol_fg.shape} at {vol_fg.resolution}\")\n",
    "    dir = brain2paths[brain][\"bg\"]\n",
    "    vol_bg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"bg shape: {vol_bg.shape} at {vol_bg.resolution}\")\n",
    "    dir = brain2paths[brain][\"endo\"]\n",
    "    vol_endo = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"endo shape: {vol_endo.shape} at {vol_endo.resolution}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isExist = os.path.exists(base_dir)\n",
    "if not isExist:\n",
    "    print(f\"Creating directory: {base_dir}\")\n",
    "    os.makedirs(base_dir)\n",
    "else:\n",
    "    print(f\"Downloaded data will be stored in {base_dir}\")\n",
    "\n",
    "for type, centers in zip([\"pos\", \"neg\"], [soma_centers, nonsoma_centers]):\n",
    "    for i, center in enumerate(tqdm(centers, desc=\"Saving positive samples\")):\n",
    "        image_fg = vol_fg[\n",
    "            center[0] - 24 : center[0] + 25,\n",
    "            center[1] - 24 : center[1] + 25,\n",
    "            center[2] - 24 : center[2] + 25,\n",
    "        ]\n",
    "        image_fg = image_fg[:, :, :, 0]\n",
    "        image_bg = vol_bg[\n",
    "            center[0] - 24 : center[0] + 25,\n",
    "            center[1] - 24 : center[1] + 25,\n",
    "            center[2] - 24 : center[2] + 25,\n",
    "        ]\n",
    "        image_bg = image_bg[:, :, :, 0]\n",
    "        image_endo = vol_endo[\n",
    "            center[0] - 24 : center[0] + 25,\n",
    "            center[1] - 24 : center[1] + 25,\n",
    "            center[2] - 24 : center[2] + 25,\n",
    "        ]\n",
    "        image_endo = image_endo[:, :, :, 0]\n",
    "\n",
    "        image = np.squeeze(np.stack([image_fg, image_bg, image_endo], axis=0))\n",
    "\n",
    "        fname = (\n",
    "            base_dir + f\"{int(center[0])}_{int(center[1])}_{int(center[2])}_{type}.h5\"\n",
    "        )\n",
    "        with h5py.File(fname, \"w\") as f:\n",
    "            dset = f.create_dataset(\"image_3channel\", data=image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View downloaded data (optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/brainr2/val/891_4202_1717_pos.h5\"  # path to file for viewing\n",
    "scale = [1.8, 1.8, 2]  # voxel size in microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, \"r\") as f:\n",
    "    pred = f.get(\"image_3channel\")\n",
    "    image_fg = pred[0, :, :, :]\n",
    "    image_bg = pred[1, :, :, :]\n",
    "    image_endo = pred[2, :, :, :]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg, scale=scale)\n",
    "viewer.add_image(image_bg, scale=scale)\n",
    "viewer.add_image(image_endo, scale=scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply ilastik to validation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to do two things:\n",
    "- apply soma segmentation model to the downloaded data. Results should be located in the same directory at the subvolumes, with the addition of \"_Probabilities\" appended to the file names. You can use `soma_apply_ilastik.py` to help apply ilastik programmatically.\n",
    "- identify files that have two somas in variable below. Since voxel coordinates are likely to be unique across samples, the file names below do not include sample IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles = [\n",
    "    \"3972_1636_1575_pos_Probabilities.h5\",\n",
    "    \"2867_4336_1296_pos_Probabilities.h5\",\n",
    "    \"2607_1845_1309_pos_Probabilities.h5\",\n",
    "    \"2101_3397_1747_pos_Probabilities.h5\",\n",
    "    \"2011_3452_1911_pos_Probabilities.h5\",\n",
    "    \"2113_3353_1727_pos_Probabilities.h5\",\n",
    "    \"1968_3472_?1784_pos_Probabilities.h5\",\n",
    "]  # 8446"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "files_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/brain{brain}/val/\"\n",
    "onlyfiles = [\n",
    "    f for f in os.listdir(files_dir) if os.path.isfile(os.path.join(files_dir, f))\n",
    "]\n",
    "test_files = [f for f in onlyfiles if \"Probabilities\" in f]  # \"probabilities\"\n",
    "print(test_files)\n",
    "\n",
    "size_thresh = 500\n",
    "\n",
    "thresholds = list(np.arange(0.0, 1.0, 0.02))\n",
    "\n",
    "for threshold in thresholds:\n",
    "    tot_pos = 0\n",
    "    tot_neg = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    for filename in tqdm(test_files, disable=True):\n",
    "        if filename in doubles:\n",
    "            newpos = 2\n",
    "        else:\n",
    "            newpos = 1\n",
    "\n",
    "        fname = files_dir + filename\n",
    "        f = h5py.File(fname, \"r\")\n",
    "        pred = f.get(\"exported_data\")\n",
    "        pred = pred[0, :, :, :]\n",
    "        mask = pred > threshold\n",
    "        labels = measure.label(mask)\n",
    "        props = measure.regionprops(labels)\n",
    "\n",
    "        if \"pos\" in filename:\n",
    "            num_detected = 0\n",
    "            tot_pos += newpos\n",
    "            for prop in props:\n",
    "                if prop[\"area\"] > size_thresh:\n",
    "                    if num_detected < newpos:\n",
    "                        true_pos += 1\n",
    "                        num_detected += 1\n",
    "                    else:\n",
    "                        false_pos += 1\n",
    "        elif \"neg\" in filename:\n",
    "            tot_neg += 1\n",
    "            for prop in props:\n",
    "                if prop[\"area\"] > size_thresh:\n",
    "                    false_pos += 1\n",
    "\n",
    "    recall = true_pos / tot_pos\n",
    "    recalls.append(recall)\n",
    "    if true_pos + false_pos == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "    precisions.append(precision)\n",
    "    if precision == 0 and recall == 0:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = 2 * precision * recall / (precision + recall)\n",
    "    print(\n",
    "        f\"threshold: {threshold}: precision: {precision}, recall: {recall}, f-score: {fscore} for {tot_pos} positive samples in {len(test_files)} images\"\n",
    "    )\n",
    "\n",
    "fscores = [\n",
    "    2 * precision * recall / (precision + recall)\n",
    "    if (precision != 0 and recall != 0)\n",
    "    else 0\n",
    "    for precision, recall in zip(precisions, recalls)\n",
    "]\n",
    "dict = {\n",
    "    \"Recall\": recalls,\n",
    "    \"Precision\": precisions,\n",
    "    \"F-score\": fscores,\n",
    "    \"Threshold\": thresholds,\n",
    "}\n",
    "df = pd.DataFrame(dict)\n",
    "max_fscore = df[\"F-score\"].max()\n",
    "best_threshold = float(df.loc[df[\"F-score\"] == max_fscore][\"Threshold\"].iloc[0])\n",
    "best_rec = float(df.loc[df[\"F-score\"] == max_fscore][\"Recall\"].iloc[0])\n",
    "best_prec = float(df.loc[df[\"F-score\"] == max_fscore][\"Precision\"].iloc[0])\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.lineplot(data=df, x=\"Recall\", y=\"Precision\", estimator=np.amax, ci=False)\n",
    "plt.scatter(\n",
    "    best_rec,\n",
    "    best_prec,\n",
    "    c=\"r\",\n",
    "    label=f\"Max f-score: {max_fscore:.2f} thresh:{best_threshold:.2f}\",\n",
    ")\n",
    "plt.xlim([0, 1.1])\n",
    "plt.ylim([0, 1.1])\n",
    "plt.title(f\"Brain {brain} Validation: {tot_pos}+ {tot_neg}-\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If results above are not adequate, improve model and try again\n",
    "\n",
    "In my case, I identify more subvolumes from the sample at hand using the same process as for validation data, and add it as training data to the model and retrain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(test_files, disable=True):\n",
    "    print(f\"*************File: {filename}*********\")\n",
    "    if filename in doubles:\n",
    "        newpos = 2\n",
    "    else:\n",
    "        newpos = 1\n",
    "\n",
    "    im_fname = files_dir + filename[:-17] + \".h5\"\n",
    "    fname = files_dir + filename\n",
    "    f = h5py.File(fname, \"r\")\n",
    "    pred = f.get(\"exported_data\")\n",
    "    pred = pred[0, :, :, :]\n",
    "    mask = pred > best_threshold\n",
    "    labels = measure.label(mask)\n",
    "    props = measure.regionprops(labels)\n",
    "\n",
    "    if \"pos\" in filename:\n",
    "        num_detected = 0\n",
    "        tot_pos += newpos\n",
    "        for prop in props:\n",
    "            area = prop[\"area\"]\n",
    "            if area > size_thresh:\n",
    "                print(f\"area of detected object: {area}\")\n",
    "                if num_detected < newpos:\n",
    "                    true_pos += 1\n",
    "                    num_detected += 1\n",
    "                else:\n",
    "                    print(f\"Soma false positive Area: {area}\")\n",
    "                    f = h5py.File(im_fname, \"r\")\n",
    "                    im = f.get(\"image_3channel\")\n",
    "                    viewer = napari.Viewer(ndisplay=3)\n",
    "                    viewer.add_image(im[0, :, :, :], name=filename)\n",
    "                    viewer.add_image(im[1, :, :, :], name=\"bg\")\n",
    "                    viewer.add_image(im[2, :, :, :], name=\"endo\")\n",
    "                    viewer.add_labels(mask)\n",
    "                    viewer.add_labels(\n",
    "                        labels == prop[\"label\"],\n",
    "                        name=f\"soma false positive area: {area}\",\n",
    "                    )\n",
    "                    false_pos += 1\n",
    "        if num_detected == 0:\n",
    "            print(f\"Soma false negative\")\n",
    "            f = h5py.File(im_fname, \"r\")\n",
    "            im = f.get(\"image_3channel\")\n",
    "            viewer = napari.Viewer(ndisplay=3)\n",
    "            viewer.add_image(im[0, :, :, :], name=filename)\n",
    "            viewer.add_image(im[1, :, :, :], name=\"bg\")\n",
    "            viewer.add_image(im[2, :, :, :], name=\"endo\")\n",
    "            viewer.add_labels(mask, name=\"Soma false negative\")\n",
    "    elif \"neg\" in filename:\n",
    "        for prop in props:\n",
    "            area = prop[\"area\"]\n",
    "            if area > size_thresh:\n",
    "                print(f\"Nonsoma false positive Area: {area}\")\n",
    "                f = h5py.File(im_fname, \"r\")\n",
    "                im = f.get(\"image_3channel\")\n",
    "                viewer = napari.Viewer(ndisplay=3)\n",
    "                viewer.add_image(im[0, :, :, :], name=filename)\n",
    "                viewer.add_image(im[1, :, :, :], name=\"bg\")\n",
    "                viewer.add_image(im[2, :, :, :], name=\"endo\")\n",
    "                viewer.add_labels(mask)\n",
    "                viewer.add_labels(\n",
    "                    labels == prop[\"label\"], name=f\"nonsoma false positive area: {area}\"\n",
    "                )\n",
    "                false_pos += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper figure for all validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brains = [\n",
    "    \"8607\",\n",
    "    \"8606\",\n",
    "    \"8477\",\n",
    "    \"8531\",\n",
    "    \"8608\",\n",
    "    \"8529\",\n",
    "    \"8557\",\n",
    "    \"8555\",\n",
    "    \"8446\",\n",
    "    \"8454\",\n",
    "    \"887\",\n",
    "]\n",
    "\n",
    "recalls = []\n",
    "precisions = []\n",
    "brain_ids = []\n",
    "\n",
    "best_precisions = []\n",
    "best_recalls = []\n",
    "best_fscores = {}\n",
    "\n",
    "for brain_id in tqdm(brains, desc=\"Computing validation...\"):\n",
    "\n",
    "    if brain_id == \"8557\":\n",
    "        brain_name = \"r1\"\n",
    "    elif brain_id == \"8555\":\n",
    "        brain_name = \"r2\"\n",
    "    else:\n",
    "        brain_name = brain_id\n",
    "\n",
    "    files_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/brain{brain_name}/val/\"\n",
    "    onlyfiles = [\n",
    "        f for f in os.listdir(files_dir) if os.path.isfile(os.path.join(files_dir, f))\n",
    "    ]\n",
    "    test_files = [f for f in onlyfiles if \"Probabilities\" in f]\n",
    "\n",
    "    best_fscore = 0\n",
    "\n",
    "    size_thresh = 500\n",
    "\n",
    "    thresholds = list(np.arange(0.0, 1.0, 0.02))\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        tot_pos = 0\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        for filename in tqdm(test_files, disable=True):\n",
    "            if filename in doubles:\n",
    "                newpos = 2\n",
    "            else:\n",
    "                newpos = 1\n",
    "\n",
    "            fname = files_dir + filename\n",
    "            f = h5py.File(fname, \"r\")\n",
    "            pred = f.get(\"exported_data\")\n",
    "            pred = pred[0, :, :, :]\n",
    "            mask = pred > threshold\n",
    "            labels = measure.label(mask)\n",
    "            props = measure.regionprops(labels)\n",
    "\n",
    "            if \"pos\" in filename:\n",
    "                num_detected = 0\n",
    "                tot_pos += newpos\n",
    "                for prop in props:\n",
    "                    if prop[\"area\"] > size_thresh:\n",
    "                        if num_detected < newpos:\n",
    "                            true_pos += 1\n",
    "                            num_detected += 1\n",
    "                        else:\n",
    "                            false_pos += 1\n",
    "            elif \"neg\" in filename:\n",
    "                for prop in props:\n",
    "                    if prop[\"area\"] > size_thresh:\n",
    "                        false_pos += 1\n",
    "\n",
    "        recall = true_pos / tot_pos\n",
    "        recalls.append(recall)\n",
    "        if true_pos + false_pos == 0:\n",
    "            precision = 1\n",
    "        else:\n",
    "            precision = true_pos / (true_pos + false_pos)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        if precision == 0 and recall == 0:\n",
    "            fscore = 0\n",
    "        else:\n",
    "            fscore = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        if fscore > best_fscore:\n",
    "            best_fscore = fscore\n",
    "            best_prec = precision\n",
    "            best_recall = recall\n",
    "\n",
    "        brain_ids.append(brain_id)\n",
    "    best_fscores[brain_id] = best_fscore\n",
    "    best_precisions.append(best_prec)\n",
    "    best_recalls.append(best_recall)\n",
    "\n",
    "\n",
    "for i, brain_id in enumerate(brain_ids):\n",
    "    brain_ids[i] = brain_id + f\" - Max F-score: {best_fscores[brain_id]:.2f}\"\n",
    "\n",
    "data = {\"Sample\": brain_ids, \"Recall\": recalls, \"Precision\": precisions}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "sns.set(font_scale=2)\n",
    "sns.lineplot(data=df, x=\"Recall\", y=\"Precision\", hue=\"Sample\", estimator=\"max\", ci=None)\n",
    "sns.scatterplot(x=best_recalls, y=best_precisions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Annotation layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\"\n",
    ")\n",
    "for layer in [\n",
    "    antibody_layer,\n",
    "    background_layer,\n",
    "]:  # axon_mask is transformed into an image because nearest interpolation doesnt work well after downsampling\n",
    "\n",
    "    layer_path = brain2paths[brain][\"base\"] + layer + \"_transformed\"\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"image\",\n",
    "        data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=atlas_vol.voxel_offset,\n",
    "        chunk_size=[32, 32, 32],  # units are voxels\n",
    "        volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(layer_path, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply ilastik to whole image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. using `soma_detect_image.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Register volume using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. You need to find an initial affine alignment using cloudreg.scripts.registration.get_affine_matrix. For example: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from cloudreg.scripts.registration import get_affine_matrix\n",
    "get_affine_matrix([1,1,1], [15,0,0], \"PIR\", \"RAI\", 1.15, \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Run registration using cloudreg.scripts.registration. For example:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.registration -input_s3_path precomputed://s3://smartspim-precomputed-volumes/2022_11_01/8790/Ch_561 --output_s3_path precomputed://s3://smartspim-precomputed-volumes/2022_11_01/8790/atlas_to_target --atlas_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_50um/average_50um --parcellation_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --atlas_orientation PIR -orientation RAI --rotation 0 0 0 --translation 0 0 0 --fixed_scale 1.2 -log_s3_path precomputed://s3://smartspim-precomputed-volumes/2022_11_01/8790/atlas_to_target --missing_data_correction True --grid_correction False --bias_correction True --regularization 5000.0 --iterations 3000 --registration_resolution 100\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Collect region based results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `soma_collect_results.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Transform soma detection coordinates to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.transform_points --target_viz_link https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=6ti276yAxXF_Rw --atlas_viz_link https://ara.viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=HvyNDGaPsd1wyg --affine_path /mnt/NAS/Neuroglancer\\ Data/  --velocity_path /mnt/NAS/Neuroglancer\\ Data/  --transformation_direction atlas\n",
    "```\n",
    "\n",
    "This will produce a neuroglancer link with the transformed soma coordinates, which should be added to `soma_data.py` under the `somas_atlas_url` key. Then the code below, or `soma_brainrender.py`, can be used to visualize the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View coronal maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_level = 5  # level of ARA to partition the figures\n",
    "\n",
    "colors = {\n",
    "    \"tph2 vglut3\": \"blue\",\n",
    "    \"tph2 gad2\": \"red\",\n",
    "    \"gad2 vgat\": \"green\",\n",
    "}  # colors for different genotypes\n",
    "symbols = [\"o\", \"+\", \"^\", \"vbar\"]  # symbols for different samples within genotype group\n",
    "\n",
    "atlas_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/ara/ara_10um.tif\"  # Path to 10um atlas parcellation\n",
    "# atlas can be downloaded from here: https://neurodata.io/data/allen_atlas/\n",
    "fold_on = False  # Whether to fold results over midline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from parse_ara import *\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "\n",
    "# create vikram object\n",
    "f = json.load(\n",
    "    open(\n",
    "        \"ara_structure_ontology.json\",\n",
    "        \"r\",\n",
    "    )\n",
    ")\n",
    "\n",
    "tree = build_tree(f)\n",
    "stack = [tree]\n",
    "\n",
    "# create nx graph\n",
    "queue = [tree]\n",
    "cur_level = -1\n",
    "counter = 0\n",
    "G = nx.DiGraph()\n",
    "max_level = 0\n",
    "\n",
    "\n",
    "while len(queue) > 0:\n",
    "    node = queue.pop(0)\n",
    "    if node.level > max_level:\n",
    "        max_level = node.level\n",
    "    G.add_node(\n",
    "        node.id,\n",
    "        level=node.level,\n",
    "        st_level=node.st_level,\n",
    "        name=node.name,\n",
    "        acronym=node.acronym,\n",
    "        label=str(node.st_level) + \") \" + node.name,\n",
    "    )\n",
    "    if node.parent_id is not None:\n",
    "        G.add_edge(node.parent_id, node.id)\n",
    "\n",
    "    queue += node.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_level_nodes = []\n",
    "\n",
    "print(f\"Regions in selected atlas level ({atlas_level})\")\n",
    "for node in G.nodes:\n",
    "    if G.nodes[node][\"st_level\"] == atlas_level:\n",
    "        atlas_level_nodes.append(node)\n",
    "        print(f\"{node}: {G.nodes[node]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcellation = CloudVolume(\n",
    "    \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\"\n",
    ")\n",
    "atlas = io.imread(atlas_path)\n",
    "\n",
    "\n",
    "atlas_points = {}\n",
    "\n",
    "for key in brain2paths.keys():\n",
    "    if \"somas_atlas_url\" in brain2paths[key].keys():\n",
    "        viz_link = brain2paths[key][\"somas_atlas_url\"]\n",
    "        viz_link = NGLink(viz_link.split(\"json_url=\")[-1])\n",
    "        ngl_json = viz_link._json\n",
    "        for layer in ngl_json[\"layers\"]:\n",
    "            if layer[\"type\"] == \"annotation\":\n",
    "                points = []\n",
    "                for annot in layer[\"annotations\"]:\n",
    "                    points.append(annot[\"point\"])\n",
    "\n",
    "                atlas_points[key] = np.array(points)\n",
    "                print(\n",
    "                    f'Brain {key}: Collecting atlas space soma points from layer: {layer[\"name\"]}'\n",
    "                )\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {}\n",
    "for z in np.arange(100, 1300, 500):\n",
    "    slice = atlas[z, :, :]\n",
    "    newslice = np.copy(slice)\n",
    "    for label in tqdm(np.unique(slice), desc=f\"Relabeling in z={z}\"):\n",
    "        atlas_level_label = find_atlas_level_label(\n",
    "            label, atlas_level_nodes, atlas_level, G\n",
    "        )\n",
    "        newslice[slice == label] = atlas_level_label\n",
    "        if atlas_level_label not in new_labels.keys():\n",
    "            if atlas_level_label in G.nodes:\n",
    "                name = G.nodes[atlas_level_label][\"name\"]\n",
    "            else:\n",
    "                name = \"??\"\n",
    "            new_labels[atlas_level_label] = name\n",
    "\n",
    "    labels = measure.label(newslice)\n",
    "    borders = 0 * labels\n",
    "    for label in tqdm(np.unique(labels), desc=f\"Processing labels in z={z}\"):\n",
    "        if label != 0:\n",
    "            mask = np.array(labels == label, dtype=\"int\")\n",
    "            erode = np.array(ndi.binary_erosion(mask))\n",
    "            outline = mask - erode\n",
    "            borders += outline\n",
    "\n",
    "    if fold_on:\n",
    "        half_width = np.round(borders.shape[1] / 2).astype(int)\n",
    "        borders = borders[:, :half_width]\n",
    "        newslice = newslice[:, :half_width]\n",
    "\n",
    "    v = napari.Viewer()\n",
    "    v.add_labels(newslice, scale=[10, 10])\n",
    "    v.add_image(borders, scale=[10, 10], name=f\"z={z}\")\n",
    "\n",
    "    gtype_counts = {\"tph2 vglut3\": 0, \"tph2 gad2\": 0, \"gad2 vgat\": 0}\n",
    "    for key in tqdm(atlas_points.keys(), desc=f\"Processing brains in z={z}\"):\n",
    "        ra = atlas_points[key]\n",
    "        gtype = brain2paths[key][\"genotype\"]\n",
    "\n",
    "        ra = atlas_points[key]\n",
    "        points = ra[(ra[:, 0] < z + 10) & (ra[:, 0] > z - 10)]\n",
    "\n",
    "        # only select points that fall on an ROI\n",
    "        fg_points = []\n",
    "        for point in points:\n",
    "            im_coord = [int(point[1]), int(point[2])]\n",
    "\n",
    "            if (\n",
    "                im_coord[0] in range(0, newslice.shape[0])\n",
    "                and im_coord[1] in range(0, newslice.shape[1])\n",
    "                and newslice[im_coord[0], im_coord[1]] != 0\n",
    "            ):\n",
    "                if fold_on and im_coord[1] >= half_width:\n",
    "                    im_coord[1] = 2 * half_width - im_coord[1]\n",
    "\n",
    "                fg_points.append([im_coord[0], im_coord[1]])\n",
    "\n",
    "        v.add_points(\n",
    "            fg_points,\n",
    "            symbol=symbols[gtype_counts[gtype]],\n",
    "            face_color=colors[gtype],\n",
    "            size=10,\n",
    "            name=f\"{key}: {gtype}\",\n",
    "            scale=[10, 10],\n",
    "        )\n",
    "        gtype_counts[gtype] = gtype_counts[gtype] + 1\n",
    "\n",
    "    v.scale_bar.unit = \"um\"\n",
    "    v.scale_bar.visible = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Display bar charts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholebrain_results_dir = \"\"  #\n",
    "\n",
    "brains = {\n",
    "    \"8557\": \"tph2 vglut3\",\n",
    "    \"8555\": \"tph2 vglut3\",\n",
    "    \"8607\": \"tph2 gad2\",\n",
    "    \"8606\": \"tph2 gad2\",\n",
    "    \"8477\": \"gad2/vgat\",\n",
    "    \"8531\": \"gad2/vgat\",\n",
    "    \"8608\": \"tph2 gad2\",\n",
    "    \"8529\": \"gad2/vgat\",\n",
    "    \"8454\": \"gad2/vgat\",\n",
    "    \"8446\": \"gad2/vgat\",\n",
    "}  # dictionary with key as sample ID and value as subtype for results to be shown\n",
    "\n",
    "regions = [\n",
    "    688,  # cerebral cortex\n",
    "    698,  # olfactory areas\n",
    "    1089,  # hippocampal formation\n",
    "    # 583, # claustrum\n",
    "    477,  # striatum\n",
    "    # 803, # pallidum\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    # 703, #cortical subplate\n",
    "    1097,  # hypothalamus\n",
    "    549,  # thalamus\n",
    "    186,  # lateral habenula\n",
    "    519,  # cerebellar nuclei\n",
    "    313,  # midbrain\n",
    "    1065,  # hindbrain\n",
    "]  # allen atlas region IDs to be shown\n",
    "# see: https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3\n",
    "\n",
    "composite_regions = {\n",
    "    \"Amygdalar Nuclei\": [131, 295, 319, 780]\n",
    "}  # Custom composite allen regions where key is region name and value is list of allen regions\n",
    "\n",
    "level = \"coarse\"  # coarse or fine, dictates whether the regions specified above will be shown (coarse), or their subregions (fine)\n",
    "\n",
    "if level not in [\"coarse\", \"fine\"]:\n",
    "    raise ValueError(f\"level must be coarse or fine, not {level}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for gene in set(brains.values()):\n",
    "    count = 0\n",
    "    for brain in brains.keys():\n",
    "        if brains[brain] == gene:\n",
    "            count += 1\n",
    "    counts[gene] = count\n",
    "\n",
    "\n",
    "quantification_dicts = {}\n",
    "\n",
    "for brain in brains.keys():\n",
    "    path = (\n",
    "        \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/wholebrain_results/quantification_dict_\"\n",
    "        + brain\n",
    "        + \".pickle\"\n",
    "    )\n",
    "    with open(path, \"rb\") as f:\n",
    "        quantification_dict = pickle.load(f)\n",
    "\n",
    "    quantification_dicts[brain] = quantification_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = json.load(\n",
    "    open(\n",
    "        \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/lsm_analysis/ara_structure_ontology.json\",\n",
    "        \"r\",\n",
    "    )\n",
    ")\n",
    "\n",
    "tree = build_tree(f)\n",
    "stack = [tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [tree]\n",
    "cur_level = -1\n",
    "counter = 0\n",
    "G = nx.DiGraph()\n",
    "max_level = 0\n",
    "\n",
    "# Initialize nodes\n",
    "\n",
    "while len(queue) > 0:\n",
    "    node = queue.pop(0)\n",
    "    if node.level > max_level:\n",
    "        max_level = node.level\n",
    "    G.add_node(\n",
    "        node.id,\n",
    "        level=node.level,\n",
    "        st_level=node.st_level,\n",
    "        name=node.name,\n",
    "        acronym=node.acronym,\n",
    "        label=str(node.st_level) + \") \" + node.name,\n",
    "    )\n",
    "    for brain in quantification_dicts.keys():\n",
    "        G.nodes[node.id][brain] = 0\n",
    "    if node.parent_id is not None:\n",
    "        G.add_edge(node.parent_id, node.id)\n",
    "\n",
    "    queue += node.children\n",
    "\n",
    "# add data\n",
    "i_test = 0\n",
    "print(f\"Max level: {max_level}\")\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test]])\n",
    "for brain, quantification_dict in quantification_dicts.items():\n",
    "    for key in quantification_dict.keys():\n",
    "        if key in G.nodes:\n",
    "            G.nodes[key][brain] = G.nodes[key][brain] + quantification_dict[key]\n",
    "\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test]])\n",
    "\n",
    "# add child data to parent data\n",
    "for brain in quantification_dicts.keys():\n",
    "    for lvl in range(max_level, 0, -1):\n",
    "        for node in G.nodes:\n",
    "            if G.nodes[node][\"level\"] == lvl:\n",
    "                parent = list(G.in_edges(node))[0][0]\n",
    "                G.nodes[parent][brain] = G.nodes[parent][brain] + G.nodes[node][brain]\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    total = 0\n",
    "    for node in G.nodes:\n",
    "        total += G.nodes[node][brain]\n",
    "    totals[brain] = total\n",
    "\n",
    "somas = []\n",
    "somas_norm = []\n",
    "somas_pct = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "brain_ids = []\n",
    "for region in regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    # choose level here\n",
    "    if level == \"fine\":\n",
    "        children = list(G.successors(region))\n",
    "    elif level == \"coarse\":\n",
    "        children = [region]\n",
    "    else:\n",
    "        raise ValueError(f\"level must be coarse or fine, not {level}\")\n",
    "\n",
    "    for child in children:\n",
    "        for brain in quantification_dicts.keys():\n",
    "            soma_count = G.nodes[child][brain]\n",
    "            drn_somas = G.nodes[872][brain]\n",
    "\n",
    "            somas.append(soma_count)\n",
    "            if drn_somas != 0:\n",
    "                somas_norm.append(soma_count / drn_somas)\n",
    "            else:\n",
    "                print(f\"Warning: brain {brain} has no inputs from DRN\")\n",
    "                somas_norm.append(0)\n",
    "            somas_pct.append(G.nodes[child][brain] / totals[brain] * 100)\n",
    "\n",
    "            gene.append(brains[brain] + f\" (n={counts[brains[brain]]})\")\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "            region_name.append(G.nodes[region][\"name\"])\n",
    "            brain_ids.append(brain)\n",
    "\n",
    "for region_component_name in composite_regions.keys():\n",
    "    print(f\"Populating: \" + region_component_name)\n",
    "    region_components = composite_regions[region_component_name]\n",
    "    for brain in quantification_dicts.keys():\n",
    "\n",
    "        soma_count = 0\n",
    "\n",
    "        for region_component in region_components:\n",
    "            soma_count += G.nodes[region_component][brain]\n",
    "\n",
    "        drn_somas = G.nodes[872][brain]\n",
    "\n",
    "        somas.append(soma_count)\n",
    "        if drn_somas != 0:\n",
    "            somas_norm.append(soma_count / drn_somas)\n",
    "        else:\n",
    "            print(f\"Warning: brain {brain} has no inputs from DRN\")\n",
    "            somas_norm.append(0)\n",
    "        somas_pct.append(G.nodes[child][brain] / totals[brain] * 100)\n",
    "\n",
    "        gene.append(brains[brain] + f\" (n={counts[brains[brain]]})\")\n",
    "        subregion_name.append(region_component_name)\n",
    "        region_name.append(region_component_name)\n",
    "        brain_ids.append(brain)\n",
    "\n",
    "d = {\n",
    "    \"Somas (#)\": somas,\n",
    "    \"Normalized Somas\": somas_norm,\n",
    "    \"Percent of Total Somas (%)\": somas_pct,\n",
    "    \"Gene\": gene,\n",
    "    \"Subregion\": subregion_name,\n",
    "    \"Region\": region_name,\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(39, 13))\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "test = \"Mann-Whitney\"\n",
    "test = \"t-test_ind\"\n",
    "correction = \"fdr_by\"\n",
    "\n",
    "# soma counts\n",
    "fig_args = {\n",
    "    \"y\": \"Somas (#)\",\n",
    "    \"x\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "pairs = []\n",
    "unq_subregions = []\n",
    "for subregion in subregion_name:\n",
    "    if subregion not in unq_subregions:\n",
    "        unq_subregions.append(subregion)\n",
    "\n",
    "\n",
    "genes = df[\"Gene\"].unique()\n",
    "gene_pairs = [(a, b) for idx, a in enumerate(genes) for b in genes[idx + 1 :]]\n",
    "\n",
    "for gene_pair in gene_pairs:\n",
    "    for subregion in unq_subregions:\n",
    "        pairs.append(\n",
    "            (\n",
    "                (subregion, gene_pair[0]),\n",
    "                (subregion, gene_pair[1]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "annotator = Annotator(axes[0], pairs, **fig_args)\n",
    "fig_args = {\n",
    "    \"x\": \"Somas (#)\",\n",
    "    \"y\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "bplot = sns.barplot(ax=axes[0], orient=\"h\", **fig_args)\n",
    "bplot.set_xscale(\"log\")\n",
    "\n",
    "annotator.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=correction\n",
    ")\n",
    "annotator.new_plot(bplot, orient=\"h\", plot=\"barplot\", **fig_args)\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "# soma counts\n",
    "fig_args = {\n",
    "    \"y\": \"Normalized Somas\",\n",
    "    \"x\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "pairs = []\n",
    "unq_subregions = []\n",
    "for subregion in subregion_name:\n",
    "    if subregion not in unq_subregions:\n",
    "        unq_subregions.append(subregion)\n",
    "\n",
    "\n",
    "genes = df[\"Gene\"].unique()\n",
    "gene_pairs = [(a, b) for idx, a in enumerate(genes) for b in genes[idx + 1 :]]\n",
    "\n",
    "for gene_pair in gene_pairs:\n",
    "    for subregion in unq_subregions:\n",
    "        pairs.append(\n",
    "            (\n",
    "                (subregion, gene_pair[0]),\n",
    "                (subregion, gene_pair[1]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "annotator = Annotator(axes[1], pairs, **fig_args)\n",
    "fig_args = {\n",
    "    \"x\": \"Normalized Somas\",\n",
    "    \"y\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "bplot = sns.barplot(ax=axes[1], orient=\"h\", **fig_args)\n",
    "bplot.set_xscale(\"log\")\n",
    "\n",
    "annotator.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=correction\n",
    ")\n",
    "annotator.new_plot(bplot, orient=\"h\", plot=\"barplot\", **fig_args)\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "# distribution\n",
    "fig_args = {\n",
    "    \"y\": \"Percent of Total Somas (%)\",\n",
    "    \"x\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "pairs = []\n",
    "unq_subregions = []\n",
    "for subregion in subregion_name:\n",
    "    if subregion not in unq_subregions:\n",
    "        unq_subregions.append(subregion)\n",
    "\n",
    "\n",
    "for gene_pair in gene_pairs:\n",
    "    for subregion in unq_subregions:\n",
    "        pairs.append(\n",
    "            (\n",
    "                (subregion, gene_pair[0]),\n",
    "                (subregion, gene_pair[1]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "annotator = Annotator(axes[2], pairs, **fig_args)\n",
    "fig_args = {\n",
    "    \"x\": \"Percent of Total Somas (%)\",\n",
    "    \"y\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "\n",
    "bplot = sns.barplot(ax=axes[2], orient=\"h\", **fig_args)\n",
    "bplot.set_xscale(\"log\")\n",
    "\n",
    "annotator.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=correction\n",
    ")\n",
    "annotator.new_plot(bplot, orient=\"h\", plot=\"barplot\", **fig_args)\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distributions with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "brain_ids = []\n",
    "genotypes = []\n",
    "\n",
    "for i, brain in enumerate(brains):\n",
    "    print(brain)\n",
    "    region_order = list(df.loc[df[\"Brain ID\"] == brain][\"Region\"])\n",
    "\n",
    "    if i == 0:\n",
    "        standard_region_order = region_order\n",
    "    elif standard_region_order != region_order:\n",
    "        raise ValueError(f\"Different region order for brain {brain}\")\n",
    "\n",
    "    distrib = list(df.loc[df[\"Brain ID\"] == brain][\"Percent of Total Somas (%)\"])\n",
    "    X.append(distrib)\n",
    "\n",
    "    brain_ids.append(brain)\n",
    "    genotypes.append(brains[brain])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2 = pca.fit_transform(X)\n",
    "\n",
    "df_pca = {\n",
    "    \"PC 1\": X_2[:, 0],\n",
    "    \"PC 2\": X_2[:, 1],\n",
    "    \"Genotype\": genotypes,\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df_pca = pd.DataFrame(data=df_pca)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "sns.scatterplot(data=df_pca, x=\"PC 1\", y=\"PC 2\", hue=\"Genotype\", ax=ax)\n",
    "\n",
    "\n",
    "for i in range(df_pca.shape[0]):\n",
    "    plt.text(\n",
    "        x=df_pca[\"PC 1\"][i] + 0.03,\n",
    "        y=df_pca[\"PC 2\"][i] + 0.03,\n",
    "        s=df_pca[\"Brain ID\"][i],\n",
    "        fontdict=dict(color=\"black\", size=20),\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Input Distribution PCA with Explained Variance: {pca.explained_variance_ratio_}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('docs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, May  4 2021, 03:05:50) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
