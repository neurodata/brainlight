{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.preprocessing.features import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction using brainlit\n",
    "The classes `LinearFeatures` and `NeighborhoodFeatures` convert swc files to a list of axon/background examples in a dataframe, with relevant features. \n",
    "\n",
    "First, instantiate the classes. You pass a `url` to pull data from, a `size` of the bounding box around each point, where the actual box is `2i+1` for each index `i`, and an `offset` to shift the bounding box to get a background point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearFeatures(url=\"s3://open-neurodata/brainlit/brain1\", size=[1,1,1], offset=[15,15,15])\n",
    "nbr = NeighborhoodFeatures(url=\"s3://open-neurodata/brainlit/brain1\", size=[1,1,1], offset=[15,15,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `LinearFeatures` class, you need to define the filters you want to convolve with the neighborhoods. To do so, you use the `add_filters` method. Currently, `brainlit` supports adding Gaussian, Gaussian Gradient Magnitude, Gaussian Laplace, and Gabor filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.add_filter('gaussian', sigma=[1, 1, 0.3])\n",
    "lin.add_filter('gaussian gradient', sigma=[1, 1, 0.3])\n",
    "lin.add_filter('gaussian laplace', sigma=[1, 1, 0.3])\n",
    "lin.add_filter('gabor', sigma=[1, 1, 0.3], phi=[0, 0], frequency=2)\n",
    "# lin.add_filter('gabor', sigma=[1, 1, 0.3], phi=[0, np.pi/2], frequency=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `fit` method for each class with a list of ids and a number of vertices to fit onto for each swc. If the second argument isn't given (or passed as `None`), features will be collected for every vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lin = lin.fit(seg_ids=[2, 7], num_verts=5)\n",
    "df_nbr = nbr.fit(seg_ids=[2, 7], num_verts=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputted dataframes themselves have a `Segment` column, `Vertex` column, `Label` column (1=axon 0=background), and feature columns that are indexed starting at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both neighborhood and linear features can be extracted using the `include_neighborhood` parameter in the `LinearFeatures` `fit` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lin = lin.fit(seg_ids=[2, 7], num_verts=5, include_neighborhood=True)\n",
    "df_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Extracted Features\n",
    "\n",
    "In cases where one wishes to extract features from many vertices, `Brainlit` allows batch loading and writing of the data. The data is written into the binary `feather` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lin = lin.fit(seg_ids=[2, 7], num_verts=10, file_path='demo', batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `batch_size` samples is output as a `feather` file. The `file_path` argument determines the prefix of the filenames. Afterwards, it is followed by the starting sample number, the last sample number, the segment ID for the last sample in the batch, and the vertex ID for the last sample in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob.glob('*.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `start_seg` and `start_vert` arguments, you can choose where in the data to start extracting information from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lin = lin.fit(seg_ids=[2, 7], num_verts=10, file_path='demo_2_', batch_size=10, start_seg=7, start_vert=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob.glob('demo_2*.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('scipydev': conda)",
   "language": "python",
   "name": "python37664bitscipydevcondaa561a5f26f384a3d8eec296dbbf704a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}