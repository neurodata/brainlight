{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.utils import upload\n",
    "import numpy as np\n",
    "import tifffile as tf\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting image data to neuroglancer precomputed format\n",
    "\n",
    "Image data will be assumed to be stored locally in octree format and at multiple resolutions, such as\n",
    "```default.0.tif 0/default.0.tif 1/default.0.tif ... 8/default.0.tif```.\n",
    "\n",
    "A user only needs to specity a path to the octree top level, and specify the number of resolutions to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The octree path can be modified to generated files from different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(\"..\") / \"..\" / \"..\" / \"tests\" # working directory containing octree data, modify this\n",
    "top_level = directory / \"data_octree\" # top level of octree data, modify thiss\n",
    "num_res = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining file paths, we call `get_volume_info` to set up the image channel parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ordered_files, \n",
    " bin_paths, \n",
    " vox_size, \n",
    " tiff_dims) = upload.get_volume_info(os.fspath(top_level), num_res, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The URL-formated layer location parameter can be modified to send generated files to\n",
    " - any location on a local machine by using the \"file://\" prefix and then filepath\n",
    " - a google storage account by using the \"gs://\" prefix and then url\n",
    " - an aws account by using the \"s3://\" prefix and then url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_location = \"file://\" + os.fspath(directory) + \"/test_precomputed/\" # file upload destination, modify this\n",
    "vols = upload.create_image_layer(\n",
    "    layer_location,\n",
    "    tiff_dims, vox_size, num_res\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# to suppress output\n",
    "for i in range(num_res):\n",
    "    upload.upload_chunks(\n",
    "        vols[i], ordered_files[i], bin_paths[i], parallel=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result is a set of folders, 1 per resolution, wherever we specified when defining our image layer, named by resolution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting swc data to neuroglancer precomputed\n",
    "\n",
    "SWC data will be assumed to be stored locally in `.swc` format, such as\n",
    "```default.0.swc```.\n",
    "\n",
    "As before, this tutorial simply shows how to generate the requisite files, and the user can provide any destination for said files. The dafault is a local folder, but this can be modified to any url.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils import upload_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The octree path can be modified to generated files from different data\n",
    "\n",
    "We use `get_volume_info` from the `upload_skeleton` module, defining a volume in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swcpath = directory / \"data_swcs\" # swc data location, modify this\n",
    "origin, vox_size, tiff_dims = upload_skeleton.get_volume_info(os.fspath(top_level), num_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The URL-formated layer location parameter can be modified to send generated files to different locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_location_swc = \"file://\" + os.fspath(directory) + \"/test_precomputed/\" # file upload destination, modify this\n",
    "vol = upload_skeleton.create_skeleton_layer(\n",
    "    layer_location_swc, \n",
    "    vox_size, tiff_dims, num_res\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the swc data is converted to the correct data type (Skeleton object). Then it is uploaded using similar methods as the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skels, segids = upload_skeleton.create_skel_segids(\n",
    "    os.fspath(swcpath), origin\n",
    ")\n",
    "for skel in skels:\n",
    "    vol.skeleton.upload(skel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a `skeletons` folder containing the swcs in precomputed format. Again, any destination url can be used other than `file://path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}