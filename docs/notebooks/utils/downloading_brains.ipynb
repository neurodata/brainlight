{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597865438763",
   "display_name": "Python 3.8.3 64-bit ('brainlit3.8': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.utils.swc import graph_to_paths\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Brain data tutorial\n",
    "We have prepared 2 brain volumes, as well as axon segment labels, at the below s3 urls (see `uploading_brains.ipynb`).\n",
    "The method demonstrated below pulls a region of the volume around an annotated axon point set by the user.\n",
    "\n",
    "## 1) Define Variables\n",
    "- `mip` ranges from higher resolution (0) to lower resolution (1).\n",
    "- `v_id` are vertex ids ranging from the soma (0) to the end of the axon (1649).\n",
    "- `radius` is the radius to pull around the selected point, in voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "dir_2 = \"s3://open-neurodata/brainlit/brain2\"\n",
    "dir_2_segments = \"s3://open-neurodata/brainlit/brain2_segments\"\n",
    "mip = 0\n",
    "v_id = 0\n",
    "radius = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a NeuroglancerSession instance and download the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\nDownloading: 46it [00:07,  6.05it/s]\n\nDownloaded volume is of shape (151, 151, 151), with total intensity 4968390.\n\n"
    }
   ],
   "source": [
    "# get image and center point\n",
    "ngl_sess = NeuroglancerSession(mip = mip, url = dir, url_segments=dir_segments)\n",
    "img, bbox, vox = ngl_sess.pull_voxel(2, v_id, radius)\n",
    "print(f\"\\n\\nDownloaded volume is of shape {img.shape}, with total intensity {sum(sum(sum(img)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate a graph from the segment data within the volume, and convert it to paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\nSelected volume contains 6 nodes and 2 paths\n"
    }
   ],
   "source": [
    "G_sub = ngl_sess.get_segments(2, bbox)\n",
    "paths = graph_to_paths(G_sub)\n",
    "print(f\"Selected volume contains {G_sub.number_of_nodes()} nodes and {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) View the volume with paths overlaid via napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_shapes(data=paths, shape_type='path', edge_width=0.1, edge_color='blue', opacity=0.1)\n",
    "    viewer.add_points(vox, size=1, opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
