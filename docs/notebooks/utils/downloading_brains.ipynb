{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasathey/Documents/mimlab/mouselight/env/lib/python3.8/site-packages/python_jsonschema_objects/__init__.py:50: UserWarning: Schema version http://json-schema.org/draft-04/schema not recognized. Some keywords and features may not be supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Brain data tutorial\n",
    "We have prepared 2 brain volumes, as well as axon segment labels, at the below s3 urls (see uploading_brains.ipynb). The method demonstrated below pulls a region of the volume around an annotated axon point set by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Define Variables\n",
    "- mip ranges from higher resolution (0) to lower resolution (1).\n",
    "\n",
    "- v_id are vertex ids ranging from the soma (0) to the end of the axon (1649).\n",
    "\n",
    "- radius is the radius to pull around the selected point, in voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "dir_2 = \"s3://open-neurodata/brainlit/brain2\"\n",
    "dir_2_segments = \"s3://open-neurodata/brainlit/brain2_segments\"\n",
    "mip = 0\n",
    "v_id = 0\n",
    "radius = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a NeuroglancerSession instance and download the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s]\n",
      "Downloading: 46it [00:01, 23.04it/s]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloaded volume is of shape (151, 151, 151), with total intensity 4946609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get image and center point\n",
    "ngl_sess = NeuroglancerSession(mip = mip, url = dir, url_segments=dir_segments)\n",
    "img, bbox, vox = ngl_sess.pull_voxel(2, v_id, radius)\n",
    "print(f\"\\n\\nDownloaded volume is of shape {img.shape}, with total intensity {sum(sum(sum(img)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate a graph from the segment data within the volume, and convert it to paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s]\n",
      "Downloading: 100%|██████████| 1/1 [00:00<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected volume contains 6 nodes and 2 paths\n"
     ]
    }
   ],
   "source": [
    "G_paths = ngl_sess.get_segments(2, bbox)\n",
    "G_sub = G_paths[0]\n",
    "paths = G_paths[1]\n",
    "\n",
    "print(f\"Selected volume contains {G_sub.number_of_nodes()} nodes and {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) View the volume with paths overlaid via napari.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_shapes(data=paths, shape_type='path', edge_width=0.5, edge_color='blue', opacity=0.5)\n",
    "    viewer.add_points(vox, size=2, opacity=0.5, face_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 151, 151)\n",
      "[75 75 75]\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "print(vox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
