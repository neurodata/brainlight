{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/thomasathey/Documents/mimlab/mouselight/env/lib/python3.8/site-packages/python_jsonschema_objects/__init__.py:50: UserWarning: Schema version http://json-schema.org/draft-04/schema not recognized. Some keywords and features may not be supported.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from brainlit.utils import upload, session\n",
    "from pathlib import Path\n",
    "import napari\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Brain Images from data in the Octree format.\n",
    "This notebook demonstrates uploading the 2 lowest-resolution brain volumes and a `.swc` segment file.\n",
    "The upload destination could easily be set to a url of a cloud data server such as s3.\n",
    "\n",
    "## 1) Define variables.\n",
    " - `source` is the root directory of the octree-formatted data with `.swc` files in a `consensus-swcs/` subfolder.\n",
    " - `p` is the prefix string. `file://` indicates a filepath, while `s3://` or `gc://` indicate URLs.\n",
    " - `dest` and `dest_segments` are the destinations for the uploads (in this case, filepaths).\n",
    " - `num_res` denotes the number of resolutions to upload. \n",
    " \n",
    "The below paths lead to sample data in the NDD Repo. Alter the below path definitions to point to your own local file locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = (Path().resolve().parents[2] / \"data\" / \"data_octree\").as_posix()\n",
    "dest = (Path().resolve().parents[2] / \"data\" / \"test_upload\").as_uri()\n",
    "dest_segments = (Path().resolve().parents[2] / \"data\" / \"test_upload_segments\").as_uri()\n",
    "num_res = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Upload the image data (.tif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the upload fails with the error: `timed out on a chunk on layer index 0. moving on to the next step of pipeline`, re-run the `upload_volumes` function but with the `continue_upload` parameter, which takes `layer index` (the layer index said in the error message) and `image index` (the last succesful image that uploaded).  \n",
    "\n",
    "For example, if the output failed after image 19, then run \n",
    "`upload.upload_volumes(source, dest, num_res, continue_upload = (0, 19))`. Repeat this till all of the upload is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Creating precomputed volume at layer index 0: 100%|██████████| 1/1 [00:04<00:00,  4.12s/it]\n",
      "Creating precomputed volume at layer index 1:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Finished layer index 0, took 4.121166944503784 seconds\n",
      "Creating precomputed volume at layer index 1: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n",
      "Finished layer index 1, took 9.971112966537476 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upload.upload_volumes(source, dest, num_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Upload the segmentation data (.swc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If uploading a `.swc` file associated with a brain volume, then use upload.py. Otherwise if uploading `swc` files with different name formats, use upload_benchmarking.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "converting swcs to neuroglancer format...: 100%|██████████| 1/1 [00:00<00:00, 44.48it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00, 140.59it/s]\n"
     ]
    }
   ],
   "source": [
    "upload.upload_segments(source, dest_segments, num_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data with NeuroglancerSession and generate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "sess = session.NeuroglancerSession(url=dest, url_segments=dest_segments, mip=0)  # create session object object\n",
    "img, bounds, vertices = sess.pull_vertex_list(2, range(250, 350), expand=True)  # get image containing some data\n",
    "labels = sess.create_tubes(2, bounds, radius=1)  # generate labels via tube segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Visualize the data with napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python386jvsc74a57bd0c48f87b51193a18c36f6ec1b39da40df380a4c3fb2fa54b3e413dc2378ec9052",
   "display_name": "Python 3.8.6 64-bit ('env')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}