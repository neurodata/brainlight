{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "import napari\n",
    "from skimage import io\n",
    "import random\n",
    "import h5py\n",
    "from skimage import measure\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import tables\n",
    "from napari_animation import AnimationWidget\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from parse_ara import *\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator\n",
    "import pandas as pd\n",
    "import brainrender\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import skeletonize\n",
    "from axon_data import brain2paths as brain2paths_axon\n",
    "from util import find_sample_names\n",
    "from soma_rabies_somadetector_data import brain2paths as brain2paths_soma\n",
    "import os\n",
    "from util import json_to_points\n",
    "import scipy.ndimage as ndi\n",
    "import random\n",
    "from cloudvolume import CloudVolume\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Axon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"8649\": ([2192, 1244, 1332], [901, 2559, 1332]),\"8650\": ([2378, 948, 1851], [2302, 5705, 1851]),\"8589\": ([4312, 4163, 1450], [1335, 6119, 1450]),\"8613\": ([3911, 3461, 1514], [1411, 5720, 1514]),\"8590\": ([1394, 1940, 1854], [4776, 816, 1854])} #axon center then nonaxon center\n",
    "\n",
    "data2 = {}\n",
    "for i in [\"8650\", \"8589\", \"8590\"]:\n",
    "    data2[i] = data[i]\n",
    "data = data2\n",
    "\n",
    "intensities = []\n",
    "brain_ids = []\n",
    "vol_type = []\n",
    "# viewer = napari.Viewer(ndisplay=2)\n",
    "\n",
    "\n",
    "for i, brain in enumerate(data.keys()):\n",
    "    vol = CloudVolume(brain2paths_axon[brain][\"ab\"])\n",
    "    coord = data[brain][0]\n",
    "    subvol = vol[coord[0]-9:coord[0]+10, coord[1]-9:coord[1]+10, coord[2]-9:coord[2]+10]\n",
    "    # viewer.add_image(np.squeeze(subvol), name=f\"{brain} axon\", scale = [1.83, 1.83, 2])\n",
    "    num_entries = len(subvol.flatten())\n",
    "    intensities += list(subvol.flatten())\n",
    "    brain_ids += [i] * num_entries\n",
    "    vol_type += [f\"Axon\"] * num_entries\n",
    "    \n",
    "\n",
    "\n",
    "    coord = data[brain][1]\n",
    "    subvol = vol[coord[0]-9:coord[0]+10, coord[1]-9:coord[1]+10, coord[2]-9:coord[2]+10]\n",
    "    # viewer.add_image(np.squeeze(subvol), name=f\"{brain} bg\", scale = [1.83, 1.83, 2])\n",
    "    num_entries = len(subvol.flatten())\n",
    "    intensities += list(subvol.flatten())\n",
    "    brain_ids += [i] * num_entries\n",
    "    vol_type += [f\"Background\"] * num_entries\n",
    "    \n",
    "# # viewer.camera.angles = [45, 45, 45]\n",
    "# viewer.scale_bar.visible = True\n",
    "# viewer.scale_bar.unit = \"um\"\n",
    "df = pd.DataFrame(data = {\"Intensity\": intensities, \"Subvolume Type\": vol_type, \"Sample\": brain_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, sharex=True, dpi=300, figsize=(5,5))\n",
    "for i in range(3):\n",
    "    hist = sns.histplot(data=df[df[\"Sample\"]==i], x=\"Intensity\", hue=\"Subvolume Type\", ax=axs[i], palette = ['green', 'red'])\n",
    "    axs[i].set_title(f\"Sample {i}\")\n",
    "    if i > 0:\n",
    "        hist.get_legend().remove()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set results\n",
    "training_brain_order = [3, 4, 8649, 8788]\n",
    "models = []\n",
    "for i, brain in enumerate(training_brain_order):\n",
    "    model = \"\"\n",
    "    for j, brain2 in enumerate(training_brain_order[:i+1]):\n",
    "        model += \"-\"\n",
    "        model += str(brain2)\n",
    "    models.append(model)\n",
    "\n",
    "sample_ids = {8589: 3, 8590: 4, 8613: 5, 8649: 6, 8650: 7, 8788: 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot best f scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inventory:\n",
    "Brains 8589, 8590, 8613, 8649, 8650\n",
    "models: All single ones, then sequential 8649, 8650, 8589, 8613, 8590\n",
    "Results: all single ones\n",
    "\n",
    "Plot idea: Total accuracy over time: need all models to be evaluated on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_order = [8650, 8649, 8613, 8589, 8590, 8788]\n",
    "models_results = []\n",
    "fscores = []\n",
    "brains = []\n",
    "av_fscores = []\n",
    "\n",
    "for model_n, model in enumerate(tqdm(models, desc=\"Cycling through models...\")):  \n",
    "    av_fscore = []    \n",
    "    for brain in tqdm(brain_order, desc=\"Evaluating brains...\"):\n",
    "        brain_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain{brain}/\"\n",
    "        results_dir = brain_dir + \"results\" + model\n",
    "\n",
    "        # identify images an split into val and test\n",
    "        files = find_sample_names(brain_dir, dset = \"val\", add_dir = False)\n",
    "        random.shuffle(files)\n",
    "        half = int(len(files)/2)\n",
    "        val_files = files[:half]\n",
    "        test_files = files[half:]\n",
    "\n",
    "        # val - choose best threshold\n",
    "        true_files = []\n",
    "        pred_files = []\n",
    "        for val_file in val_files:\n",
    "            true_file = f\"{brain_dir}/{val_file.split('.')[0]}-image_2channel_Labels.h5\"\n",
    "            true_files.append(true_file)\n",
    "            pred_file = f\"{results_dir}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "            pred_files.append(pred_file)\n",
    "\n",
    "        spacing = 0.02\n",
    "        thresholds = np.arange(spacing, 1.0, spacing)\n",
    "        best_fscore = 0\n",
    "        best_thresh = -1\n",
    "        \n",
    "        for threshold in tqdm(thresholds, desc=\"searching threshold...\", leave=False):\n",
    "            true_pos_total = 0\n",
    "            false_pos_total = 0\n",
    "            true_labels_total = 0\n",
    "\n",
    "            for true_file, pred_file in zip(true_files, pred_files):\n",
    "                f = h5py.File(pred_file, \"r\")\n",
    "                seg = f.get(\"exported_data\")\n",
    "                seg = seg[1, :, :, :]\n",
    "                mask_forward = seg > threshold\n",
    "\n",
    "                f = h5py.File(true_file, \"r\")\n",
    "                gt = f.get(\"exported_data\")\n",
    "                gt = gt[0, :, :, :]\n",
    "                pos_labels = gt == 2\n",
    "                neg_labels = gt == 1\n",
    "\n",
    "                true_pos = np.sum(np.logical_and(mask_forward, pos_labels))\n",
    "                true_pos_total += true_pos\n",
    "\n",
    "                false_pos = np.sum(np.logical_and(mask_forward, gt == 1))\n",
    "                false_pos_total += false_pos\n",
    "\n",
    "                true_labels = np.sum(pos_labels)\n",
    "                true_labels_total += true_labels\n",
    "\n",
    "            precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "            recall_total = true_pos_total / true_labels_total\n",
    "            fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "            if fscore > best_fscore:\n",
    "                best_fscore = fscore\n",
    "                best_thresh = threshold\n",
    "\n",
    "        # test\n",
    "        true_files = []\n",
    "        pred_files = []\n",
    "        for val_file in test_files:\n",
    "            true_file = f\"{brain_dir}/{val_file.split('.')[0]}-image_2channel_Labels.h5\"\n",
    "            true_files.append(true_file)\n",
    "            pred_file = f\"{results_dir}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "            pred_files.append(pred_file)\n",
    "\n",
    "        true_pos_total = 0\n",
    "        false_pos_total = 0\n",
    "        true_labels_total = 0\n",
    "\n",
    "        for true_file, pred_file in zip(true_files, pred_files):\n",
    "            f = h5py.File(pred_file, \"r\")\n",
    "            seg = f.get(\"exported_data\")\n",
    "            seg = seg[1, :, :, :]\n",
    "            mask_forward = seg > best_thresh\n",
    "\n",
    "            f = h5py.File(true_file, \"r\")\n",
    "            gt = f.get(\"exported_data\")\n",
    "            gt = gt[0, :, :, :]\n",
    "            pos_labels = gt == 2\n",
    "            neg_labels = gt == 1\n",
    "\n",
    "            true_pos = np.sum(np.logical_and(mask_forward, pos_labels))\n",
    "            true_pos_total += true_pos\n",
    "\n",
    "            false_pos = np.sum(np.logical_and(mask_forward, gt == 1))\n",
    "            false_pos_total += false_pos\n",
    "\n",
    "            true_labels = np.sum(pos_labels)\n",
    "            true_labels_total += true_labels\n",
    "\n",
    "        precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "        recall_total = true_pos_total / true_labels_total\n",
    "        fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "        fscores.append(fscore)\n",
    "        models_results.append(model_n)\n",
    "        brains.append(sample_ids[brain])\n",
    "        \n",
    "        av_fscore.append(fscore)\n",
    "\n",
    "    av_fscores.append(np.mean(av_fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Test F-Score\": fscores, \"Training Dataset\": models_results, \"Brain\": brains})\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5,5), dpi=300)\n",
    "sns.lineplot(data=df, x=\"Training Dataset\", y=\"Test F-Score\", hue=\"Brain\", ax=axes, alpha=0.5, linestyle='dashed', palette=\"tab10\")\n",
    "\n",
    "axes.plot(np.arange(len(models)), av_fscores, color='red', label=\"Average\")\n",
    "leg = axes.legend(loc='lower right')\n",
    "leg_lines = leg.get_lines()\n",
    "for i in range(len(brain_order)): \n",
    "    leg_lines[i].set_linestyle(\"--\")\n",
    "axes.set_xticks(np.arange(len(models)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to sample number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set results\n",
    "training_brain_order = [3, 4, 8649, 8788]\n",
    "models_diff = []\n",
    "models_same = []\n",
    "\n",
    "for i, brain in enumerate(training_brain_order):\n",
    "    model_diff = \"-compare\"\n",
    "    for j, brain2 in enumerate(training_brain_order[:i+1]):\n",
    "        model_diff += \"-\"\n",
    "        model_diff += str(brain2)\n",
    "\n",
    "        model_same = \"-compare-3\"\n",
    "        if j > 0:\n",
    "            model_same += f\"_{j+1}\"\n",
    "\n",
    "    models_diff.append(model_diff)\n",
    "    models_same.append(model_same)\n",
    "\n",
    "print(f\"heterogeneous: {models_diff} homogeneous: {models_same}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_order = [8650, 8649, 8613, 8589, 8590, 8788]\n",
    "training_set_sizes = [10, 20, 25, 30]\n",
    "train_sizes = []\n",
    "model_lines = []\n",
    "fscores = []\n",
    "brains = []\n",
    "\n",
    "for brain in tqdm(brain_order, desc=\"Evaluating brains...\"):\n",
    "    brain_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain{brain}/\"\n",
    "    # identify images an split into val and test\n",
    "    files = find_sample_names(brain_dir, dset = \"val\", add_dir = False)\n",
    "    random.shuffle(files)\n",
    "    half = int(len(files)/2)\n",
    "    val_files = files[:half]\n",
    "    test_files = files[half:]\n",
    "\n",
    "    for model_line, models in zip([\"Heterogeneous\", \"Homogeneous\"],[models_diff, models_same]):\n",
    "        for model, train_size in zip(models, training_set_sizes):     \n",
    "            results_dir = brain_dir + \"results\" + model\n",
    "\n",
    "\n",
    "            # val - choose best threshold\n",
    "            true_files = []\n",
    "            pred_files = []\n",
    "            for val_file in val_files:\n",
    "                true_file = f\"{brain_dir}/{val_file.split('.')[0]}-image_2channel_Labels.h5\"\n",
    "                true_files.append(true_file)\n",
    "                pred_file = f\"{results_dir}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "                pred_files.append(pred_file)\n",
    "\n",
    "            spacing = 0.02\n",
    "            thresholds = np.arange(spacing, 1.0, spacing)\n",
    "            best_fscore = 0\n",
    "            best_thresh = -1\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                true_pos_total = 0\n",
    "                false_pos_total = 0\n",
    "                true_labels_total = 0\n",
    "\n",
    "                for true_file, pred_file in zip(true_files, pred_files):\n",
    "                    f = h5py.File(pred_file, \"r\")\n",
    "                    seg = f.get(\"exported_data\")\n",
    "                    seg = seg[1, :, :, :]\n",
    "                    mask_forward = seg > threshold\n",
    "\n",
    "                    f = h5py.File(true_file, \"r\")\n",
    "                    gt = f.get(\"exported_data\")\n",
    "                    gt = gt[0, :, :, :]\n",
    "                    pos_labels = gt == 2\n",
    "                    neg_labels = gt == 1\n",
    "\n",
    "                    true_pos = np.sum(np.logical_and(mask_forward, pos_labels))\n",
    "                    true_pos_total += true_pos\n",
    "\n",
    "                    false_pos = np.sum(np.logical_and(mask_forward, gt == 1))\n",
    "                    false_pos_total += false_pos\n",
    "\n",
    "                    true_labels = np.sum(pos_labels)\n",
    "                    true_labels_total += true_labels\n",
    "\n",
    "                precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "                recall_total = true_pos_total / true_labels_total\n",
    "                fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "                if fscore > best_fscore:\n",
    "                    best_fscore = fscore\n",
    "                    best_thresh = threshold\n",
    "\n",
    "            # test\n",
    "            true_files = []\n",
    "            pred_files = []\n",
    "            for val_file in test_files:\n",
    "                true_file = f\"{brain_dir}/{val_file.split('.')[0]}-image_2channel_Labels.h5\"\n",
    "                true_files.append(true_file)\n",
    "                pred_file = f\"{results_dir}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "                pred_files.append(pred_file)\n",
    "\n",
    "            true_pos_total = 0\n",
    "            false_pos_total = 0\n",
    "            true_labels_total = 0\n",
    "\n",
    "            for true_file, pred_file in zip(true_files, pred_files):\n",
    "                f = h5py.File(pred_file, \"r\")\n",
    "                seg = f.get(\"exported_data\")\n",
    "                seg = seg[1, :, :, :]\n",
    "                mask_forward = seg > best_thresh\n",
    "\n",
    "                f = h5py.File(true_file, \"r\")\n",
    "                gt = f.get(\"exported_data\")\n",
    "                gt = gt[0, :, :, :]\n",
    "                pos_labels = gt == 2\n",
    "                neg_labels = gt == 1\n",
    "\n",
    "                true_pos = np.sum(np.logical_and(mask_forward, pos_labels))\n",
    "                true_pos_total += true_pos\n",
    "\n",
    "                false_pos = np.sum(np.logical_and(mask_forward, gt == 1))\n",
    "                false_pos_total += false_pos\n",
    "\n",
    "                true_labels = np.sum(pos_labels)\n",
    "                true_labels_total += true_labels\n",
    "\n",
    "            precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "            recall_total = true_pos_total / true_labels_total\n",
    "            fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "            fscores.append(fscore)\n",
    "            train_sizes.append(train_size)\n",
    "            brains.append(brain)\n",
    "            \n",
    "            model_lines.append(model_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Test F-Score\": fscores, \"Number of Subvolumes in Training Set\": train_sizes, \"Brain\": brains, \"Training Type\": model_lines})\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5,5), dpi=300)\n",
    "sns.lineplot(data=df, x=\"Number of Subvolumes in Training Set\", y=\"Test F-Score\", hue=\"Brain\", style=\"Training Type\", ax=axes, alpha=0.5, linestyle='dashed', palette=\"tab10\")\n",
    "\n",
    "\n",
    "# axes.plot(np.arange(len(models)), av_fscores, color='red', label=\"Average\")\n",
    "# leg = axes.legend(loc='lower right')\n",
    "# leg_lines = leg.get_lines()\n",
    "# for i in range(len(brain_order)): \n",
    "#     leg_lines[i].set_linestyle(\"--\")\n",
    "axes.set_xticks(training_set_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Test F-Score\": fscores, \"Number of Subvolumes in Training Set\": train_sizes, \"Brain\": brains, \"Training Type\": model_lines})\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5,5), dpi=300)\n",
    "sns.lineplot(data=df, x=\"Number of Subvolumes in Training Set\", y=\"Test F-Score\", hue=\"Training Type\")\n",
    "axes.set_xticks(training_set_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly choose training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/paper-brains/brain8650/\"\n",
    "files = os.listdir(base_dir)\n",
    "files = [base_dir + f for f in files if \".h5\" in f]\n",
    "l = len(files)\n",
    "l_train = int(np.ceil(l/2))\n",
    "random.shuffle(files)\n",
    "print(files[:l_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/paper-brains/brain8650/labels/\"\n",
    "files = os.listdir(base_dir)\n",
    "files = [base_dir + f for f in files if \"_Labels\" in f]\n",
    "files = [f for f in files if \".h5\" in f]\n",
    "\n",
    "for file in files:\n",
    "    with h5py.File(file) as hf:\n",
    "        labels = np.array(hf['exported_data'])\n",
    "    io.imsave(file[:-3] + '.tif', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"8650\"\n",
    "model = \"brain3\"\n",
    "\n",
    "base_dir = (\n",
    "            \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/val/brain\"\n",
    "            + brain\n",
    "            + \"/\"\n",
    "        )\n",
    "\n",
    "files = os.listdir(base_dir)\n",
    "files = [f for f in files if \"_Probabilities\" in f]\n",
    "\n",
    "move = input(f\"Rename {files} to {base_dir}{model}? (y/n)\")\n",
    "if move == \"y\":\n",
    "    for file in files:\n",
    "        os.rename(base_dir + file, f\"{base_dir}{model}/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Learning Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lFLEs = []\n",
    "tasks = np.arange(1, len(brain_order)+1)\n",
    "\n",
    "for brain in tqdm(brain_order, desc=\"Evaluating brains...\"):\n",
    "    brain_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/paper-brains/brain{brain}/\"\n",
    "    trains = training_ids[brain]\n",
    "\n",
    "    files = os.listdir(brain_dir)\n",
    "    files = [f for f in files if \".h5\" in f]\n",
    "\n",
    "    val_files = []\n",
    "    if isinstance(trains[0], str):\n",
    "        for file in files:\n",
    "            add = True\n",
    "            for train in trains:\n",
    "                if train in file:\n",
    "                    add = False\n",
    "                    break\n",
    "            \n",
    "            if add:\n",
    "                val_files.append(file)\n",
    "    elif isinstance(trains[0], int):\n",
    "        for file in files:\n",
    "            file_num = file.split(\"_\")[1]\n",
    "            file_num = int(file_num.split(\".\")[0])\n",
    "\n",
    "            if file_num not in trains:\n",
    "                val_files.append(file)\n",
    "    else:\n",
    "        raise ValueError(\"Training id's are neither strnigs or ints\")\n",
    "\n",
    "\n",
    "    forward_model = f\"results\"\n",
    "    for i, fwd_brain in enumerate(brain_order):\n",
    "        if i > 0:\n",
    "            forward_model += \"-\"\n",
    "        forward_model += f\"{fwd_brain}\"\n",
    "\n",
    "        if fwd_brain == brain:\n",
    "            break\n",
    "\n",
    "    true_files = []\n",
    "    baseline_files = []\n",
    "    forward_files = []\n",
    "    for val_file in val_files:\n",
    "        true_file = f\"{brain_dir}labels/{val_file.split('.')[0]}-image_2channel_Labels.h5\"\n",
    "        true_files.append(true_file)\n",
    "        baseline_file = f\"{brain_dir}results{brain}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "        baseline_files.append(baseline_file)\n",
    "        forward_file = f\"{brain_dir}{forward_model}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "        forward_files.append(forward_file)\n",
    "\n",
    "\n",
    "    # Baseline\n",
    "    spacing = 0.02\n",
    "    thresholds = np.arange(spacing, 1.0, spacing)\n",
    "    best_fscore_base = 0\n",
    "    best_fscore_fwd = 0\n",
    "    \n",
    "    for threshold in tqdm(thresholds, desc=\"searching threshold...\", leave=False):\n",
    "        true_pos_total_base = 0\n",
    "        true_pos_total_fwd = 0\n",
    "        false_pos_total_base = 0\n",
    "        false_pos_total_fwd = 0\n",
    "        true_labels_total = 0\n",
    "\n",
    "        for true_file, baseline_file, forward_file in zip(true_files, baseline_files, forward_files):\n",
    "            f = h5py.File(baseline_file, \"r\")\n",
    "            seg = f.get(\"exported_data\")\n",
    "            seg = seg[1, :, :, :]\n",
    "            mask_base = seg > threshold\n",
    "\n",
    "            f = h5py.File(forward_file, \"r\")\n",
    "            seg = f.get(\"exported_data\")\n",
    "            seg = seg[1, :, :, :]\n",
    "            mask_forward = seg > threshold\n",
    "\n",
    "            f = h5py.File(true_file, \"r\")\n",
    "            gt = f.get(\"exported_data\")\n",
    "            gt = gt[0, :, :, :]\n",
    "            pos_labels = gt == 2\n",
    "            neg_labels = gt == 1\n",
    "\n",
    "            true_pos = np.sum(np.logical_and(mask_base, pos_labels))\n",
    "            true_pos_total_base += true_pos\n",
    "            true_pos = np.sum(np.logical_and(mask_forward, pos_labels))\n",
    "            true_pos_total_fwd += true_pos\n",
    "\n",
    "            false_pos = np.sum(np.logical_and(mask_base, gt == 1))\n",
    "            false_pos_total_base += false_pos\n",
    "            false_pos = np.sum(np.logical_and(mask_forward, gt == 1))\n",
    "            false_pos_total_fwd += false_pos\n",
    "\n",
    "            true_labels = np.sum(pos_labels)\n",
    "            true_labels_total += true_labels\n",
    "\n",
    "\n",
    "        precision_total_base = true_pos_total_base / (true_pos_total_base + false_pos_total_base)\n",
    "        recall_total_base = true_pos_total_base / true_labels_total\n",
    "        fscore_base = 2 / (1 / precision_total_base + 1 / recall_total_base)\n",
    "\n",
    "        precision_total_fwd = true_pos_total_fwd / (true_pos_total_fwd + false_pos_total_fwd)\n",
    "        recall_total_fwd = true_pos_total_fwd / true_labels_total\n",
    "        fscore_fwd = 2 / (1 / precision_total_fwd + 1 / recall_total_fwd)\n",
    "\n",
    "        if fscore_base > best_fscore_base:\n",
    "            best_fscore_base = fscore_base\n",
    "        if fscore_fwd > best_fscore_fwd:\n",
    "            best_fscore_fwd = fscore_fwd\n",
    "    lFLEs.append(np.log((1-best_fscore_base)/(1-best_fscore_fwd)))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"Total Replay\" for t in tasks]\n",
    "data = {\"Task\": tasks, \"log Forward LE\": lFLEs, \"Resource Growing\": methods}\n",
    "df = pd.DataFrame(data=data)\n",
    "sns.lineplot(data=df, x=\"Task\", y=\"log Forward LE\", hue = \"Resource Growing\")\n",
    "plt.xticks(tasks, tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Learning Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lBLEs = []\n",
    "tasks = []\n",
    "dsets = []\n",
    "\n",
    "for brain1_id, brain1 in enumerate(tqdm(brain_order, desc=\"Evaluating brains...\")):\n",
    "    brain_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/paper-brains/brain{brain1}/\"\n",
    "    trains = training_ids[brain1]\n",
    "\n",
    "    files = os.listdir(brain_dir)\n",
    "    files = [f for f in files if \".h5\" in f]\n",
    "\n",
    "    val_files = []\n",
    "    if isinstance(trains[0], str):\n",
    "        for file in files:\n",
    "            add = True\n",
    "            for train in trains:\n",
    "                if train in file:\n",
    "                    add = False\n",
    "                    break\n",
    "            \n",
    "            if add:\n",
    "                val_files.append(file)\n",
    "    elif isinstance(trains[0], int):\n",
    "        for file in files:\n",
    "            file_num = file.split(\"_\")[1]\n",
    "            file_num = int(file_num.split(\".\")[0])\n",
    "\n",
    "            if file_num not in trains:\n",
    "                val_files.append(file)\n",
    "    else:\n",
    "        raise ValueError(\"Training id's are neither strnigs or ints\")\n",
    "\n",
    "    # Intermediate datasets\n",
    "    for brain2_id, brain2 in enumerate(tqdm(brain_order[brain1_id:], desc=\"Iterating through intermediate datasets...\", leave=False)):\n",
    "        backward_model = f\"results\"\n",
    "        for i, fwd_brain in enumerate(brain_order[:brain2_id+brain1_id+1]):\n",
    "            if i > 0:\n",
    "                backward_model += \"-\"\n",
    "            backward_model += f\"{fwd_brain}\"\n",
    "\n",
    "            if fwd_brain == brain:\n",
    "                break\n",
    "\n",
    "        true_files = []\n",
    "        backward_files = []\n",
    "        for val_file in val_files:\n",
    "            true_file = f\"{brain_dir}labels/{val_file.split('.')[0]}-image_2channel_Labels.h5\"\n",
    "            true_files.append(true_file)\n",
    "            backward_file = f\"{brain_dir}{backward_model}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "            backward_files.append(backward_file)\n",
    "\n",
    "\n",
    "        # Baseline\n",
    "        spacing = 0.02\n",
    "        thresholds = np.arange(spacing, 1.0, spacing)\n",
    "        best_fscore_back = 0\n",
    "        \n",
    "        for threshold in tqdm(thresholds, desc=\"searching threshold...\", leave=False):\n",
    "            true_pos_total_back = 0\n",
    "            false_pos_total_back = 0\n",
    "            true_labels_total = 0\n",
    "\n",
    "            for true_file, backward_file in zip(true_files, backward_files):\n",
    "                f = h5py.File(backward_file, \"r\")\n",
    "                seg = f.get(\"exported_data\")\n",
    "                seg = seg[1, :, :, :]\n",
    "                mask_back = seg > threshold\n",
    "\n",
    "                f = h5py.File(true_file, \"r\")\n",
    "                gt = f.get(\"exported_data\")\n",
    "                gt = gt[0, :, :, :]\n",
    "                pos_labels = gt == 2\n",
    "                neg_labels = gt == 1\n",
    "\n",
    "                true_pos = np.sum(np.logical_and(mask_back, pos_labels))\n",
    "                true_pos_total_back += true_pos\n",
    "\n",
    "                false_pos = np.sum(np.logical_and(mask_back, gt == 1))\n",
    "                false_pos_total_back += false_pos\n",
    "\n",
    "                true_labels = np.sum(pos_labels)\n",
    "                true_labels_total += true_labels\n",
    "\n",
    "\n",
    "            precision_total_back = true_pos_total_back / (true_pos_total_back + false_pos_total_back)\n",
    "            recall_total_back = true_pos_total_back / true_labels_total\n",
    "            fscore_back = 2 / (1 / precision_total_back + 1 / recall_total_back)\n",
    "\n",
    "            if fscore_back > 1:\n",
    "                raise ValueError(f\"Invalid f score: base {precision_total_back}, {recall_total_back} -> {fscore_back}\")\n",
    "\n",
    "            if fscore_back > best_fscore_back:\n",
    "                best_fscore_back = fscore_back\n",
    "        if brain2 == brain1:\n",
    "            best_fscore_base = best_fscore_back\n",
    "\n",
    "\n",
    "        tasks.append(brain1_id)\n",
    "        dsets.append(brain2_id+brain1_id)  \n",
    "        lBLEs.append(np.log((1-best_fscore_base)/(1-best_fscore_back)))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"Total Replay\" for t in tasks]\n",
    "data = {\"Task\": tasks, \"log Backward LE\": lBLEs, \"Training Dataset\": dsets}\n",
    "df = pd.DataFrame(data=data)\n",
    "sns.lineplot(data=df, x=\"Training Dataset\", y=\"log Backward LE\", hue=\"Task\")\n",
    "plt.xticks(tasks, tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/paper-brains/test/val_2_Probabilities_full.h5\", \"r\")\n",
    "seg = f.get(\"exported_data\")\n",
    "seg_full = seg[1, :, :, :]\n",
    "\n",
    "f = h5py.File(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/paper-brains/test/val_2_Probabilities.h5\", \"r\")\n",
    "seg = f.get(\"exported_data\")\n",
    "seg_seq = seg[1, :, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brains = [\"8650\", \"8649\", \n",
    "    \"8613\", \"8589\", \"8590\"]\n",
    "\n",
    "model_names = [\"brain8649\", \"brain8649-3\", \"brain3-4-8649\"] #[\"brain3\", \"brain3-4\", \"brain3-4-8649\"]\n",
    "\n",
    "brain_ids = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "models = []\n",
    "\n",
    "best_precisions = []\n",
    "best_recalls = []\n",
    "best_fscores = {}\n",
    "\n",
    "for model in model_names: \n",
    "    for brain in brains:\n",
    "\n",
    "        base_dir = (\n",
    "            \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/val/brain\"\n",
    "            + brain\n",
    "            + \"/\"\n",
    "        )\n",
    "\n",
    "        spacing = 0.02\n",
    "        thresholds = np.arange(spacing, 1.0, spacing)\n",
    "        best_fscore = 0\n",
    "\n",
    "        files = os.listdir(base_dir)\n",
    "        files = [f for f in files if \"val\" in f]\n",
    "        files = [f for f in files if \"_Labels.h5\" not in f]\n",
    "        files = [f for f in files if \"_Probabilities.h5\" not in f]\n",
    "\n",
    "        print(f\"{len(files)} total validation subvolumes for brain {brain}\")\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            true_pos_total = 0\n",
    "            false_pos_total = 0\n",
    "            true_labels_total = 0\n",
    "            true_labels_total_neg = 0\n",
    "            for fname in files:\n",
    "                fname_im = base_dir + fname\n",
    "                f = h5py.File(fname_im, \"r\")\n",
    "                im = f.get(\"image_2channel\")\n",
    "                im_bg = im[0, :, :, :]\n",
    "                im_fg = im[1, :, :, :]\n",
    "\n",
    "                fname_prob = f\"{base_dir}{model}/{fname[:-3]}_Probabilities.h5\"\n",
    "                f = h5py.File(fname_prob, \"r\")\n",
    "                seg = f.get(\"exported_data\")\n",
    "                seg = seg[1, :, :, :]\n",
    "                mask = seg > threshold\n",
    "\n",
    "                fname_lab = f\"{base_dir}labels/{fname[:-3]}-image_2channel_Labels.h5\" \n",
    "                f = h5py.File(fname_lab, \"r\")\n",
    "                gt = f.get(\"exported_data\")\n",
    "                gt = gt[0, :, :, :]\n",
    "                pos_labels = gt == 2\n",
    "                neg_labels = gt == 1\n",
    "\n",
    "                true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "                true_pos_total += true_pos\n",
    "                false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "                false_pos_total += false_pos\n",
    "                true_labels = np.sum(pos_labels)\n",
    "                true_labels_total += true_labels\n",
    "                true_labels_neg = np.sum(neg_labels)\n",
    "                true_labels_total_neg += true_labels_neg\n",
    "\n",
    "            precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "            recall_total = true_pos_total / true_labels_total\n",
    "\n",
    "            precisions.append(precision_total)\n",
    "            recalls.append(recall_total)\n",
    "            brain_ids.append(brain)\n",
    "            models.append(model)\n",
    "\n",
    "            fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "            if fscore > best_fscore:\n",
    "                best_fscore = fscore\n",
    "                best_prec = precision_total\n",
    "                best_recall = recall_total\n",
    "                best_threshold = threshold\n",
    "        best_precisions.append(best_prec)\n",
    "        best_recalls.append(best_recall)\n",
    "        best_fscores[brain] = best_fscore\n",
    "\n",
    "for i, brain_id in enumerate(brain_ids):\n",
    "    brain_ids[i] = brain_id + f\" - Max F-score: {best_fscores[brain_id]:.2f}\"\n",
    "\n",
    "data = {\"Sample\": brain_ids, \"Recall\": recalls, \"Precision\": precisions, \"Model\": models}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "sns.set(font_scale=2)\n",
    "sns.lineplot(data=df, x=\"Recall\", y=\"Precision\", hue=\"Sample\", style=\"Model\")\n",
    "sns.scatterplot(x=best_recalls, y=best_precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change of max f score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brains = [\"8650\", \"8649\", \n",
    "    \"8613\", \"8589\", \"8590\"]\n",
    "\n",
    "model_names = [\"brain3\", \"brain3-4\", \"brain3-4-8649\"]\n",
    "\n",
    "brain_ids = []\n",
    "best_fscores = []\n",
    "models = []\n",
    "\n",
    "best_precisions = []\n",
    "best_recalls = []\n",
    "best_fscores_dict = {}\n",
    "\n",
    "for model in model_names: \n",
    "    for brain in brains:\n",
    "\n",
    "        base_dir = (\n",
    "            \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/continual-learning/val/brain\"\n",
    "            + brain\n",
    "            + \"/\"\n",
    "        )\n",
    "\n",
    "        spacing = 0.02\n",
    "        thresholds = np.arange(spacing, 1.0, spacing)\n",
    "        best_fscore = 0\n",
    "\n",
    "        files = os.listdir(base_dir)\n",
    "        files = [f for f in files if \"val\" in f]\n",
    "        files = [f for f in files if \"_Labels.h5\" not in f]\n",
    "        files = [f for f in files if \"_Probabilities.h5\" not in f]\n",
    "\n",
    "        print(f\"{len(files)} total validation subvolumes for brain {brain}\")\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            true_pos_total = 0\n",
    "            false_pos_total = 0\n",
    "            true_labels_total = 0\n",
    "            true_labels_total_neg = 0\n",
    "            for fname in files:\n",
    "                fname_im = base_dir + fname\n",
    "                f = h5py.File(fname_im, \"r\")\n",
    "                im = f.get(\"image_2channel\")\n",
    "                im_bg = im[0, :, :, :]\n",
    "                im_fg = im[1, :, :, :]\n",
    "\n",
    "                fname_prob = f\"{base_dir}{model}/{fname[:-3]}_Probabilities.h5\"\n",
    "                f = h5py.File(fname_prob, \"r\")\n",
    "                seg = f.get(\"exported_data\")\n",
    "                seg = seg[1, :, :, :]\n",
    "                mask = seg > threshold\n",
    "\n",
    "                fname_lab = f\"{base_dir}labels/{fname[:-3]}-image_2channel_Labels.h5\" \n",
    "                f = h5py.File(fname_lab, \"r\")\n",
    "                gt = f.get(\"exported_data\")\n",
    "                gt = gt[0, :, :, :]\n",
    "                pos_labels = gt == 2\n",
    "                neg_labels = gt == 1\n",
    "\n",
    "                true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "                true_pos_total += true_pos\n",
    "                false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "                false_pos_total += false_pos\n",
    "                true_labels = np.sum(pos_labels)\n",
    "                true_labels_total += true_labels\n",
    "                true_labels_neg = np.sum(neg_labels)\n",
    "                true_labels_total_neg += true_labels_neg\n",
    "\n",
    "            precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "            recall_total = true_pos_total / true_labels_total\n",
    "\n",
    "            fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "            if fscore > best_fscore:\n",
    "                best_fscore = fscore\n",
    "                best_prec = precision_total\n",
    "                best_recall = recall_total\n",
    "                best_threshold = threshold\n",
    "        best_fscores.append(best_fscore)\n",
    "        brain_ids.append(brain)\n",
    "        models.append(model)\n",
    "\n",
    "        best_fscores_dict[brain] = best_fscore\n",
    "\n",
    "for i, brain_id in enumerate(brain_ids):\n",
    "    brain_ids[i] = brain_id + f\" - Max F-score: {best_fscores_dict[brain_id]:.2f}\"\n",
    "\n",
    "data = {\"Sample\": brain_ids, \"Best F-score\": best_fscores, \"Model\": models}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "sns.set(font_scale=2)\n",
    "sns.catplot(data=df, x=\"Model\", y=\"Best F-score\", hue=\"Sample\", kind=\"point\", height=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(rc={\"figure.figsize\": (20, 10)})\n",
    "sns.set(font_scale=2)\n",
    "sns.catplot(data=df, x=\"Model\", y=\"Best F-score\", hue=\"Sample\", kind=\"point\", height=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"8606\": ([1726, 2619, 1687], [3071, 4360, 1687]),\"8446\": ([1979, 3491, 1791], [1258, 3502, 1791]),\"887\": ([3537, 3787, 1385], [2088, 1924, 1385])} # soma center then nonsoma center\n",
    "\n",
    "intensities = []\n",
    "brain_ids = []\n",
    "vol_type = []\n",
    "\n",
    "for i, brain in enumerate(data.keys()):\n",
    "    vol = CloudVolume(brain2paths_soma[brain][\"ab\"])\n",
    "    coord = data[brain][0]\n",
    "    subvol = np.array(vol[coord[0]-9:coord[0]+10, coord[1]-9:coord[1]+10, coord[2]-9:coord[2]+10], dtype='float')\n",
    "    num_entries = len(subvol.flatten())\n",
    "    intensities += list(subvol.flatten())\n",
    "    brain_ids += [i] * num_entries\n",
    "    vol_type += [\"Soma\"] * num_entries\n",
    "\n",
    "\n",
    "    coord = data[brain][1]\n",
    "    subvol = np.array(vol[coord[0]-9:coord[0]+10, coord[1]-9:coord[1]+10, coord[2]-9:coord[2]+10], dtype='float')\n",
    "    num_entries = len(subvol.flatten())\n",
    "    intensities += list(subvol.flatten())\n",
    "    brain_ids += [i] * num_entries\n",
    "    vol_type += [\"Background\"] * num_entries\n",
    "\n",
    "df = pd.DataFrame(data = {\"Intensity\": intensities, \"Subvolume Type\": vol_type, \"Sample\": brain_ids})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, sharex=True, dpi=300, figsize=(5,5))\n",
    "for i in range(3):\n",
    "    hist = sns.histplot(data=df[df[\"Sample\"]==i], x=\"Intensity\", hue=\"Subvolume Type\", ax=axs[i], palette = ['green', 'red'])\n",
    "    axs[i].set_title(f\"Sample {i}\")\n",
    "    if i > 0:\n",
    "        hist.get_legend().remove()\n",
    "\n",
    "axs[0].set_xlim(-500, 8000)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set results\n",
    "brain_order = [\"r1\", \"r2\", \"878\", \"887\"]\n",
    "brains = [8607, 8606, 8477, 8531, 8608, 8529, 8557, 8555, 8446, 8454, 887]\n",
    "models = []\n",
    "for i, brain in enumerate(brain_order):\n",
    "    model = \"results\"\n",
    "    for j, brain2 in enumerate(brain_order[:i+1]):\n",
    "        if j > 0:\n",
    "            model += \"_\"\n",
    "        model += str(brain2)\n",
    "    models.append(model)\n",
    "\n",
    "print(models)\n",
    "\n",
    "size_thresh = 500\n",
    "doubles = [\"3972_1636_1575_pos_Probabilities.h5\", \"2867_4336_1296_pos_Probabilities.h5\", \"2607_1845_1309_pos_Probabilities.h5\",\n",
    "\"2101_3397_1747_pos_Probabilities.h5\", \"2011_3452_1911_pos_Probabilities.h5\", \"2113_3353_1727_pos_Probabilities.h5\", \"1968_3472_1784_pos_Probabilities.h5\"] #8446\n",
    "\n",
    "\n",
    "sample_ids = {b : i+2 for i, b in enumerate(np.sort(brains))}\n",
    "print(f\"sample ids: {sample_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results = []\n",
    "fscores = []\n",
    "brains_results = []\n",
    "av_fscores = []\n",
    "\n",
    "for model_n, model in enumerate(tqdm(models, desc=\"Cycling through models...\")):\n",
    "    av_fscore = []  \n",
    "    for brain in tqdm(brains, desc=\"Evaluating brains...\"):\n",
    "        if brain == 8557:\n",
    "            brain_name = \"r1\"\n",
    "        elif brain == 8555:\n",
    "            brain_name = \"r2\"\n",
    "        else:\n",
    "            brain_name = brain\n",
    "\n",
    "        images_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/brain{brain_name}/3channel/test/images_only/\"\n",
    "        results_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/brain{brain_name}/3channel/test/{model}/\"\n",
    "        files = find_sample_names(images_dir, dset = \"\", add_dir = False)\n",
    "        files = [r[:-3] + \"_Probabilities.h5\" for r in files]\n",
    "\n",
    "        reshuffle = True\n",
    "        while reshuffle:\n",
    "            random.shuffle(files)\n",
    "            half = int(len(files)/2)\n",
    "            val_files = files[:half]\n",
    "            test_files = files[half:]\n",
    "            for val_file in val_files:\n",
    "                if \"pos\" in val_file:\n",
    "                    for test_file in test_files:\n",
    "                        if \"pos\" in test_file:\n",
    "                            reshuffle=False\n",
    "                            break\n",
    "                    \n",
    "                    break\n",
    "\n",
    "        \n",
    "        # Baseline\n",
    "        spacing = 0.02\n",
    "        thresholds = np.arange(spacing, 1.0, spacing)\n",
    "        best_fscore = 0\n",
    "        best_thresh = -1\n",
    "        \n",
    "        for threshold in tqdm(thresholds, desc=\"searching threshold...\", leave=False, disable=True):\n",
    "            tot_pos = 0\n",
    "            true_pos = 0\n",
    "            false_pos = 0\n",
    "\n",
    "            for results_file in val_files:\n",
    "                if results_file in doubles:\n",
    "                    newpos = 2\n",
    "                else:\n",
    "                    newpos = 1\n",
    "\n",
    "                f = h5py.File(results_dir+results_file, \"r\")\n",
    "                seg = f.get(\"exported_data\")\n",
    "                seg = seg[0, :, :, :]\n",
    "                mask = seg > threshold\n",
    "                labels = measure.label(mask)\n",
    "                props = measure.regionprops(labels)\n",
    "\n",
    "                if \"pos\" in results_file:\n",
    "                    num_detected = 0\n",
    "                    tot_pos += newpos\n",
    "                    for prop in props:\n",
    "                        if prop[\"area\"] > size_thresh:\n",
    "                            if num_detected < newpos:\n",
    "                                true_pos += 1\n",
    "                                num_detected += 1\n",
    "                            else:\n",
    "                                false_pos += 1\n",
    "                elif \"neg\" in results_file:\n",
    "                    for prop in props:\n",
    "                        if prop[\"area\"] > size_thresh:\n",
    "                            false_pos += 1\n",
    "\n",
    "\n",
    "            recall = true_pos / tot_pos\n",
    "            if true_pos + false_pos == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = true_pos / (true_pos + false_pos)\n",
    "                \n",
    "            if precision == 0 and recall == 0:\n",
    "                fscore = 0\n",
    "            else:\n",
    "                fscore = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "            if fscore > best_fscore:\n",
    "                best_fscore = fscore\n",
    "                best_thresh = threshold\n",
    "\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        tot_pos = 0\n",
    "\n",
    "        for results_file in test_files:\n",
    "            if results_file in doubles:\n",
    "                newpos = 2\n",
    "            else:\n",
    "                newpos = 1\n",
    "\n",
    "            f = h5py.File(results_dir+results_file, \"r\")\n",
    "            seg = f.get(\"exported_data\")\n",
    "            seg = seg[0, :, :, :]\n",
    "            mask = seg > best_thresh\n",
    "            labels = measure.label(mask)\n",
    "            props = measure.regionprops(labels)\n",
    "\n",
    "            if \"pos\" in results_file:\n",
    "                num_detected = 0\n",
    "                tot_pos += newpos\n",
    "                for prop in props:\n",
    "                    if prop[\"area\"] > size_thresh:\n",
    "                        if num_detected < newpos:\n",
    "                            true_pos += 1\n",
    "                            num_detected += 1\n",
    "                        else:\n",
    "                            false_pos += 1\n",
    "            elif \"neg\" in results_file:\n",
    "                for prop in props:\n",
    "                    if prop[\"area\"] > size_thresh:\n",
    "                        false_pos += 1\n",
    "\n",
    "\n",
    "        recall = true_pos / tot_pos\n",
    "        if true_pos + false_pos == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = true_pos / (true_pos + false_pos)\n",
    "            \n",
    "        if precision == 0 and recall == 0:\n",
    "            fscore = 0\n",
    "        else:\n",
    "            fscore = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "        av_fscore.append(fscore)\n",
    "        fscores.append(fscore)\n",
    "        models_results.append(model_n)\n",
    "        brains_results.append(sample_ids[brain])\n",
    "\n",
    "    av_fscores.append(np.mean(av_fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Test F-Score\": fscores, \"Training Dataset\": models_results, \"Brain\": brains_results})\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5), dpi=300)\n",
    "\n",
    "sns.lineplot(data=df, x=\"Training Dataset\", y=\"Test F-Score\", hue=\"Brain\", ax=ax, linestyle='dashed', alpha=0.5, palette=\"tab10\")\n",
    "ax.plot(np.arange(len(models)), av_fscores, color='red', label=\"Average\")\n",
    "leg = ax.legend(loc='lower right')\n",
    "leg_lines = leg.get_lines()\n",
    "for i in range(len(brains)): \n",
    "    leg_lines[i].set_linestyle(\"--\")\n",
    "    \n",
    "ax.set_xticks(np.arange(len(models)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to sample number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set results\n",
    "training_brain_order = ['r1', 'r2', '878', '887']\n",
    "models_diff = []\n",
    "models_same = []\n",
    "\n",
    "for i, brain in enumerate(training_brain_order):\n",
    "    model_diff = \"-compare\"\n",
    "    for j, brain2 in enumerate(training_brain_order[:i+1]):\n",
    "        model_diff += \"-\"\n",
    "        model_diff += str(brain2)\n",
    "\n",
    "        model_same = \"-compare-r1\"\n",
    "        if j > 0:\n",
    "            model_same += f\"_{j+1}\"\n",
    "\n",
    "    models_diff.append(model_diff)\n",
    "    models_same.append(model_same)\n",
    "\n",
    "print(f\"heterogeneous: {models_diff} homogeneous: {models_same}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles = [\"3972_1636_1575_pos_Probabilities.h5\", \"2867_4336_1296_pos_Probabilities.h5\", \"2607_1845_1309_pos_Probabilities.h5\",\n",
    "\"2101_3397_1747_pos_Probabilities.h5\", \"2011_3452_1911_pos_Probabilities.h5\", \"2113_3353_1727_pos_Probabilities.h5\", \"1968_3472_1784_pos_Probabilities.h5\"] #8446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_order = [\"8607\", \"8606\", \"8477\", \"8531\", \"8608\", \"8529\", \"8557\", \"8555\", \"8446\", \"8454\", \"887\"]\n",
    "training_set_sizes = [25, 45, 51, 59]\n",
    "train_sizes = []\n",
    "model_lines = []\n",
    "fscores = []\n",
    "brains = []\n",
    "size_thresh = 500\n",
    "\n",
    "for brain in tqdm(brain_order, desc=\"Evaluating brains...\"):\n",
    "    if brain == \"8557\":\n",
    "        brain_name = \"r1\"\n",
    "    elif brain == \"8555\":\n",
    "        brain_name = \"r2\"\n",
    "    else:\n",
    "        brain_name = brain\n",
    "\n",
    "    brain_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/brain{brain_name}/3channel/test/\"\n",
    "    # identify images an split into val and test\n",
    "    files = find_sample_names(brain_dir, dset = \"\", add_dir = False)\n",
    "    random.shuffle(files)\n",
    "    half = int(len(files)/2)\n",
    "    val_files = files[:half]\n",
    "    test_files = files[half:]\n",
    "\n",
    "    for model_line, models in zip([\"Heterogeneous\", \"Homogeneous\"],[models_diff, models_same]):\n",
    "        for model, train_size in zip(models, training_set_sizes):  \n",
    "            results_dir = brain_dir + \"results\" + model+ \"/\"\n",
    "\n",
    "\n",
    "            # val - choose best threshold\n",
    "            pred_files = []\n",
    "            for val_file in val_files:\n",
    "                pred_file = f\"{results_dir}{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "                pred_files.append(pred_file)\n",
    "\n",
    "            spacing = 0.02\n",
    "            thresholds = np.arange(spacing, 1.0, spacing)\n",
    "            best_fscore = 0\n",
    "            best_thresh = -1\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                tot_pos = 0\n",
    "                true_pos = 0\n",
    "                false_pos = 0\n",
    "\n",
    "                for pred_file in pred_files:\n",
    "                    if pred_file in doubles:\n",
    "                        newpos = 2\n",
    "                    else:\n",
    "                        newpos = 1\n",
    "\n",
    "                    f = h5py.File(pred_file, \"r\")\n",
    "                    seg = f.get(\"exported_data\")\n",
    "                    seg = seg[0, :, :, :]\n",
    "                    mask = seg > threshold\n",
    "                    labels = measure.label(mask)\n",
    "                    props = measure.regionprops(labels)\n",
    "\n",
    "                    if \"pos\" in pred_file:\n",
    "                        num_detected = 0\n",
    "                        tot_pos += newpos\n",
    "                        for prop in props:\n",
    "                            if prop[\"area\"] > size_thresh:\n",
    "                                if num_detected < newpos:\n",
    "                                    true_pos += 1\n",
    "                                    num_detected += 1\n",
    "                                else:\n",
    "                                    false_pos += 1\n",
    "                    elif \"neg\" in pred_file:\n",
    "                        for prop in props:\n",
    "                            if prop[\"area\"] > size_thresh:\n",
    "                                false_pos += 1\n",
    "                if tot_pos == 0:\n",
    "                    recall = 1\n",
    "                else:\n",
    "                    recall = true_pos / tot_pos\n",
    "\n",
    "                if true_pos + false_pos == 0:\n",
    "                    precision = 0\n",
    "                else:\n",
    "                    precision = true_pos / (true_pos + false_pos)\n",
    "\n",
    "                if precision == 0 and recall == 0:\n",
    "                    fscore = 0\n",
    "                else:\n",
    "                    fscore = 2 / (1 / precision + 1 / recall)\n",
    "\n",
    "                if fscore > best_fscore:\n",
    "                    best_fscore = fscore\n",
    "                    best_thresh = threshold\n",
    "\n",
    "            # test\n",
    "            pred_files = []\n",
    "            for val_file in test_files:\n",
    "                pred_file = f\"{results_dir}/{val_file.split('.')[0]}_Probabilities.h5\"\n",
    "                pred_files.append(pred_file)\n",
    "\n",
    "\n",
    "            tot_pos = 0\n",
    "            true_pos = 0\n",
    "            false_pos = 0\n",
    "\n",
    "            for pred_file in pred_files:\n",
    "                if pred_file in doubles:\n",
    "                    newpos = 2\n",
    "                else:\n",
    "                    newpos = 1\n",
    "\n",
    "                f = h5py.File(pred_file, \"r\")\n",
    "                seg = f.get(\"exported_data\")\n",
    "                seg = seg[0, :, :, :]\n",
    "                mask = seg > best_thresh\n",
    "                labels = measure.label(mask)\n",
    "                props = measure.regionprops(labels)\n",
    "\n",
    "                if \"pos\" in pred_file:\n",
    "                    num_detected = 0\n",
    "                    tot_pos += newpos\n",
    "                    for prop in props:\n",
    "                        if prop[\"area\"] > size_thresh:\n",
    "                            if num_detected < newpos:\n",
    "                                true_pos += 1\n",
    "                                num_detected += 1\n",
    "                            else:\n",
    "                                false_pos += 1\n",
    "                elif \"neg\" in pred_file:\n",
    "                    for prop in props:\n",
    "                        if prop[\"area\"] > size_thresh:\n",
    "                            false_pos += 1\n",
    "                            \n",
    "            if tot_pos == 0:\n",
    "                recall = 1\n",
    "            else:\n",
    "                recall = true_pos / tot_pos\n",
    "\n",
    "            if true_pos + false_pos == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = true_pos / (true_pos + false_pos)\n",
    "\n",
    "            if precision == 0 and recall == 0:\n",
    "                fscore = 0\n",
    "            else:\n",
    "                fscore = 2 / (1 / precision + 1 / recall)\n",
    "\n",
    "            fscores.append(fscore)\n",
    "            train_sizes.append(train_size)\n",
    "            brains.append(brain)\n",
    "            \n",
    "            model_lines.append(model_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Test F-Score\": fscores, \"Number of Subvolumes in Training Set\": train_sizes, \"Brain\": brains, \"Training Type\": model_lines})\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5,5), dpi=300)\n",
    "sns.lineplot(data=df, x=\"Number of Subvolumes in Training Set\", y=\"Test F-Score\", hue=\"Brain\", style=\"Training Type\", ax=axes, alpha=0.5, linestyle='dashed', palette=\"tab10\")\n",
    "\n",
    "\n",
    "# axes.plot(np.arange(len(models)), av_fscores, color='red', label=\"Average\")\n",
    "# leg = axes.legend(loc='lower right')\n",
    "# leg_lines = leg.get_lines()\n",
    "# for i in range(len(brain_order)): \n",
    "#     leg_lines[i].set_linestyle(\"--\")\n",
    "axes.set_xticks(training_set_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Test F-Score\": fscores, \"Number of Subvolumes in Training Set\": train_sizes, \"Brain\": brains, \"Training Type\": model_lines})\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5,5), dpi=300)\n",
    "sns.lineplot(data=df, x=\"Number of Subvolumes in Training Set\", y=\"Test F-Score\", hue=\"Training Type\")\n",
    "axes.set_xticks(training_set_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('docs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, May  4 2021, 03:05:50) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
