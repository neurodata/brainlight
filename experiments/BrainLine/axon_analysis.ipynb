{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Axon Segmentation Analysis of Whole-Brain Light-Sheet Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Before Using this notebook:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install brainlit, and other packages that this notebook uses\n",
    "### 1b. Write images to s3 using CloudReg\n",
    "    - e.g. python -m cloudreg.scripts.create_precomputed_volumes --s3_input_paths /mnt/NAS/SmartSPIM_Data/2022_03_02/20220302_14_40_04_8529_destriped_DONE/Ex_561_Em_600_stitched --s3_output_paths  s3://smartspim-precomputed-volumes/2022_03_02/8529/Ch_561_v2  --voxel_size 1.83 1.83 2 --num_procs 24 --resample_iso False\n",
    "### 1c. Make point annotations in neuroglancer to identify subvolumes for validation (and possible training)\n",
    "    - instructions: https://neurodata.io/help/neuroglancer-pt-annotations/\n",
    "        ,\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"val\",\n",
    "    \"points\": []\n",
    "    }\n",
    "### 1d. Update axon_data.py file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.preprocessing import removeSmallCCs\n",
    "from brainlit.BrainLine.util import (\n",
    "    json_to_points,\n",
    "    find_atlas_level_label,\n",
    "    fold,\n",
    "    setup_atlas_graph,\n",
    "    get_atlas_level_nodes,\n",
    ")\n",
    "from brainlit.BrainLine.data.axon_data import brain2paths, brain2centers\n",
    "from brainlit.BrainLine.parse_ara import *\n",
    "import xml.etree.ElementTree as ET\n",
    "from brainlit.BrainLine.imports import *\n",
    "from brainlit.BrainLine.apply_ilastik import (\n",
    "    ApplyIlastik,\n",
    "    ApplyIlastik_LargeImage,\n",
    "    plot_results,\n",
    ")\n",
    "from brainlit.BrainLine.analyze_results import AxonDistribution\n",
    "\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to brainlit: /Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit\n",
      "Sample atlas: Does not conform to desired format\n",
      "Sample 2: Does not conform to desired format\n",
      "Sample 1: Does not conform to desired format\n",
      "Sample 3: Does not conform to desired format\n",
      "Sample 4: Does not conform to desired format\n",
      "Sample 8613: Does not conform to desired format\n",
      "Sample 8604: Does not conform to desired format\n",
      "Sample 8590_v2: Does not conform to desired format\n",
      "Sample 8612: Does not conform to desired format\n",
      "Sample 8788: Does not conform to desired format\n",
      "Sample 11537: Does not conform to desired format\n"
     ]
    }
   ],
   "source": [
    "brainlit_path = Path(os.path.abspath(\"\"))\n",
    "brainlit_path = brainlit_path.parents[3]\n",
    "print(f\"Path to brainlit: {brainlit_path}\")\n",
    "\n",
    "for id in brain2paths.keys():\n",
    "    if \"base\" in brain2paths[id].keys() and \"val_info\" in brain2paths[id].keys():\n",
    "        base = brain2paths[id][\"base\"]\n",
    "        if \"http\" in base:\n",
    "            print(f\"Sample {id}: http in basepath, which may cause write errors\")\n",
    "\n",
    "        try:\n",
    "            url = brain2paths[id][\"val_info\"][\"url\"]\n",
    "            layer = brain2paths[id][\"val_info\"][\"layer\"]\n",
    "            pts = json_to_points(url)[layer]\n",
    "        except:\n",
    "            print(f\"Sample {id}: Error with val_info\")\n",
    "\n",
    "        if \"train_info\" in brain2paths[id].keys():\n",
    "            try:\n",
    "                url = brain2paths[id][\"train_info\"][\"url\"]\n",
    "                layer = brain2paths[id][\"train_info\"][\"layer\"]\n",
    "                pts = json_to_points(url)[layer]\n",
    "            except:\n",
    "                print(f\"Sample {id}: Error with train_info\")\n",
    "    else:\n",
    "        print(f\"Sample {id}: Does not conform to desired format\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download benchmark data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibody_layer = \"Ch_647\"\n",
    "background_layer = \"Ch_561\"\n",
    "endogenous_layer = \"Ch_488\"\n",
    "\n",
    "brain = \"8589\"  # brain ID\n",
    "axon_data_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/\"  # path to directory where training/validation data should be stored\n",
    "dataset_to_save = \"val\"  # train or val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful variables\n",
    "base_dir = axon_data_dir + \"brain\" + brain + \"/\"\n",
    "\n",
    "base = brain2paths[brain][\"base\"]\n",
    "for layer in [antibody_layer, background_layer, endogenous_layer]:\n",
    "    try:\n",
    "        CloudVolume(base + layer)\n",
    "    except:\n",
    "        print(f\"Sample {id}: Layer {layer} not found in {base}\")\n",
    "\n",
    "if brain not in brain2paths.keys():\n",
    "    raise ValueError(f\"brain {brain} not an entry in brain2paths in axon_data.py file\")\n",
    "\n",
    "if f\"{dataset_to_save}_info\" not in brain2paths[\n",
    "    brain\n",
    "].keys() or dataset_to_save not in [\"train\", \"val\"]:\n",
    "    raise ValueError(f\"{dataset_to_save}_info not in brain2paths[{brain}].keys()\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if brain in brain2centers.keys():\n",
    "    centers_train = brain2centers[brain][0]\n",
    "    centers_val = brain2centers[brain][1]  # annotate z slice 25, 50 and 75\n",
    "    print(f\"{len(centers_train)} training samples, {len(centers_val)} val samples\")\n",
    "elif \"val_info\" in brain2paths[brain].keys():\n",
    "    centers_val = json_to_points(brain2paths[brain][\"val_info\"][\"url\"])[\n",
    "        brain2paths[brain][\"val_info\"][\"layer\"]\n",
    "    ]\n",
    "    print(f\"{len(centers_val)} val samples\")\n",
    "\n",
    "\n",
    "if \"train_info\" in brain2paths[brain].keys():\n",
    "    centers_train = json_to_points(brain2paths[brain][\"train_info\"][\"url\"])[\n",
    "        brain2paths[brain][\"train_info\"][\"layer\"]\n",
    "    ]\n",
    "    print(f\"{len(centers_train)} train samples\")\n",
    "\n",
    "if dataset_to_save == \"train\":\n",
    "    centers = centers_train\n",
    "elif dataset_to_save == \"val\":\n",
    "    centers = centers_val\n",
    "\n",
    "\n",
    "mip = 0\n",
    "\n",
    "if \"base\" in brain2paths[brain].keys():\n",
    "    base_dir_s3 = brain2paths[brain][\"base\"]\n",
    "    dir = base_dir_s3 + antibody_layer\n",
    "    vol_fg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"fg shape: {vol_fg.shape} at {vol_fg.resolution}\")\n",
    "    dir = base_dir_s3 + background_layer\n",
    "    vol_bg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"bg shape: {vol_bg.shape} at {vol_bg.resolution}\")\n",
    "    dir = base_dir_s3 + endogenous_layer\n",
    "    vol_endo = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"endo shape: {vol_endo.shape} at {vol_endo.resolution}\")\n",
    "\n",
    "    dir = base_dir_s3 + \"axon_mask\"\n",
    "    try:\n",
    "        vol_mask = CloudVolume(dir, parallel=1, mip=mip, fill_missing=True)\n",
    "    except:\n",
    "        print(\"vol_mask not found\")\n",
    "else:\n",
    "    dir = brain2paths[brain][\"ab\"]\n",
    "    vol_fg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"fg shape: {vol_fg.shape} at {vol_fg.resolution}\")\n",
    "    dir = brain2paths[brain][\"bg\"]\n",
    "    vol_bg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"bg shape: {vol_bg.shape} at {vol_bg.resolution}\")\n",
    "    dir = brain2paths[brain][\"endo\"]\n",
    "    vol_endo = CloudVolume(dir, parallel=1, mip=mip, fill_missing=False)\n",
    "    print(f\"endo shape: {vol_endo.shape} at {vol_endo.resolution}\")\n",
    "\n",
    "    if \"mask\" in brain2paths[brain].keys():\n",
    "        dir = brain2paths[brain][\"mask\"]\n",
    "        try:\n",
    "            vol_mask = CloudVolume(dir, parallel=1, mip=mip, fill_missing=True)\n",
    "        except:\n",
    "            print(\"vol_mask not found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ilastik - blue/1 is axon yellow/0 is bg\n",
    "# prediction model is /Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/axon_segmentation.ilp\n",
    "\n",
    "\n",
    "isExist = os.path.exists(base_dir)\n",
    "if not isExist:\n",
    "    print(f\"Creating directory: {base_dir}\")\n",
    "    os.makedirs(base_dir)\n",
    "else:\n",
    "    print(f\"Downloaded data will be stored in {base_dir}\")\n",
    "\n",
    "if dataset_to_save == \"train\":\n",
    "    centers = centers_train\n",
    "elif dataset_to_save == \"val\":\n",
    "    centers = centers_val\n",
    "\n",
    "for i, center in enumerate(centers):\n",
    "    print(f\"Downdloading subvolumes around: {center}\")\n",
    "    image_fg = vol_fg[\n",
    "        center[0] - 49 : center[0] + 50,\n",
    "        center[1] - 49 : center[1] + 50,\n",
    "        center[2] - 49 : center[2] + 50,\n",
    "    ]\n",
    "    image_fg = image_fg[:, :, :, 0]\n",
    "\n",
    "    image_bg = vol_bg[\n",
    "        center[0] - 49 : center[0] + 50,\n",
    "        center[1] - 49 : center[1] + 50,\n",
    "        center[2] - 49 : center[2] + 50,\n",
    "    ]\n",
    "    image_bg = image_bg[:, :, :, 0]\n",
    "\n",
    "    image_endo = vol_endo[\n",
    "        center[0] - 49 : center[0] + 50,\n",
    "        center[1] - 49 : center[1] + 50,\n",
    "        center[2] - 49 : center[2] + 50,\n",
    "    ]\n",
    "    image_endo = image_endo[:, :, :, 0]\n",
    "\n",
    "    image_2channel = np.stack([image_bg, image_fg, image_endo], axis=0)\n",
    "\n",
    "    fname = f\"{base_dir}{dataset_to_save}_{int(center[0])}_{int(center[1])}_{int(center[2])}.h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View downloaded data (optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8649/val_775_4829_2459.h5\"  # path to file for viewing\n",
    "scale = [1.8, 1.8, 2]  # voxel size in microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, \"r\") as f:\n",
    "    pred = f.get(\"image_2channel\")\n",
    "    image_bg = pred[0, :, :, :]\n",
    "    image_fg = pred[1, :, :, :]\n",
    "    image_endo = pred[2, :, :, :]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg, scale=scale)\n",
    "viewer.add_image(image_bg, scale=scale)\n",
    "viewer.add_image(image_endo, scale=scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Ilastik to validation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to do two things:\n",
    "- add annotations to the downloaded data (for me, partial labels on 3 of the z-slices using ilastik)\n",
    "- apply axon segmentation model to the downloaded data. Results should be located in the same directory at the subvolumes, with the addition of \"_Probabilities\" appended to the file names: you can do this programmatically (below), or you can use the ilastik GUI (which is sometimes faster)\n",
    "\n",
    "Note: make sure foreground/background labels are matched between the model and your annotations (for me, blue/1 =axon yellow/0=bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/axon_segmentation.ilp\"  # path to ilastik model to be used\n",
    "ilastik_path = (\n",
    "    \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"\n",
    ")\n",
    "brains = [brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering brains...: 100%|██████████| 1/1 [00:00<00:00, 1548.28it/s]\n",
      "running ilastik...: 100%|██████████| 10/10 [00:00<00:00, 37.26it/s]\n"
     ]
    }
   ],
   "source": [
    "applyilastik = ApplyIlastik(\n",
    "    ilastk_path=ilastik_path,\n",
    "    project_path=project_path,\n",
    "    brains_path=axon_data_dir,\n",
    "    brains=brains,\n",
    ")\n",
    "applyilastik.process_subvols()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_9_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_8_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_3_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_7_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_6_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_2_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_5_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_1_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_0_Probabilities.h5', '/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8589/val/val_4_Probabilities.h5']\n",
      "3051 3051\n",
      "Threshold: 0.0 --- Total prec.: 0.3227205415697059, total rec.: 1.0 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.48796481407437026 \n",
      "3050 3051\n",
      "Threshold: 0.02 --- Total prec.: 0.4628224582701062, total rec.: 0.9996722386102918 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.6327144487086401 \n",
      "3050 3051\n",
      "Threshold: 0.04 --- Total prec.: 0.5601469237832875, total rec.: 0.9996722386102918 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.717984934086629 \n",
      "3048 3051\n",
      "Threshold: 0.06 --- Total prec.: 0.643445218492717, total rec.: 0.9990167158308751 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.7827426810477658 \n",
      "3043 3051\n",
      "Threshold: 0.08 --- Total prec.: 0.7136491557223265, total rec.: 0.9973779088823337 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.831989063568011 \n",
      "3039 3051\n",
      "Threshold: 0.1 --- Total prec.: 0.772299872935197, total rec.: 0.9960668633235005 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.870025765817349 \n",
      "3035 3051\n",
      "Threshold: 0.12 --- Total prec.: 0.8110636023516836, total rec.: 0.9947558177646674 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.8935669071102605 \n",
      "3026 3051\n",
      "Threshold: 0.14 --- Total prec.: 0.8495227400336889, total rec.: 0.9918059652572927 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9151670951156813 \n",
      "3020 3051\n",
      "Threshold: 0.16 --- Total prec.: 0.8758700696055685, total rec.: 0.989839396919043 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9293737498076627 \n",
      "3007 3051\n",
      "Threshold: 0.18 --- Total prec.: 0.8984164923812369, total rec.: 0.9855784988528351 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9399812441387934 \n",
      "2997 3051\n",
      "Threshold: 0.2 --- Total prec.: 0.9167941266442338, total rec.: 0.9823008849557522 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9484177215189874 \n",
      "2980 3051\n",
      "Threshold: 0.22 --- Total prec.: 0.9303777708398376, total rec.: 0.9767289413307112 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9529900863447394 \n",
      "2968 3051\n",
      "Threshold: 0.24 --- Total prec.: 0.9416243654822335, total rec.: 0.9727958046542118 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9569563114621957 \n",
      "2949 3051\n",
      "Threshold: 0.26 --- Total prec.: 0.952211817888279, total rec.: 0.9665683382497542 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9593363695510736 \n",
      "2929 3051\n",
      "Threshold: 0.28 --- Total prec.: 0.9596985583224116, total rec.: 0.9600131104555883 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9598558086187121 \n",
      "2912 3051\n",
      "Threshold: 0.3 --- Total prec.: 0.9655172413793104, total rec.: 0.9544411668305474 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9599472556452943 \n",
      "2890 3051\n",
      "Threshold: 0.32 --- Total prec.: 0.9701242027526016, total rec.: 0.9472304162569649 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9585406301824212 \n",
      "2865 3051\n",
      "Threshold: 0.34 --- Total prec.: 0.974821367812181, total rec.: 0.9390363815142576 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9565943238731218 \n",
      "2841 3051\n",
      "Threshold: 0.36 --- Total prec.: 0.977296181630547, total rec.: 0.9311701081612586 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9536757301107754 \n",
      "2820 3051\n",
      "Threshold: 0.38 --- Total prec.: 0.9808695652173913, total rec.: 0.9242871189773845 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.951738103273709 \n",
      "2789 3051\n",
      "Threshold: 0.4 --- Total prec.: 0.9851642529141647, total rec.: 0.9141265158964273 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9483168990139408 \n",
      "2763 3051\n",
      "Threshold: 0.42 --- Total prec.: 0.9864334166369154, total rec.: 0.9056047197640118 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9442925495557074 \n",
      "2719 3051\n",
      "Threshold: 0.44 --- Total prec.: 0.9880087209302325, total rec.: 0.8911832186168469 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.937101499224539 \n",
      "2689 3051\n",
      "Threshold: 0.46 --- Total prec.: 0.990058910162003, total rec.: 0.8813503769255981 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9325472516039535 \n",
      "2648 3051\n",
      "Threshold: 0.48 --- Total prec.: 0.9932483120780196, total rec.: 0.8679121599475582 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9263599790099704 \n",
      "2606 3051\n",
      "Threshold: 0.5 --- Total prec.: 0.994276993513926, total rec.: 0.8541461815798099 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9188998589562765 \n",
      "2567 3051\n",
      "Threshold: 0.52 --- Total prec.: 0.9949612403100775, total rec.: 0.8413634873811865 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9117385899484993 \n",
      "2516 3051\n",
      "Threshold: 0.54 --- Total prec.: 0.995253164556962, total rec.: 0.8246476565060635 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.9019537551532532 \n",
      "2458 3051\n",
      "Threshold: 0.56 --- Total prec.: 0.9955447549615228, total rec.: 0.8056374959029826 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.8905797101449275 \n",
      "2399 3051\n",
      "Threshold: 0.58 --- Total prec.: 0.9954356846473029, total rec.: 0.7862995739101933 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.8785936641640726 \n",
      "2327 3051\n",
      "Threshold: 0.6 --- Total prec.: 0.9961472602739726, total rec.: 0.7627007538511963 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.8639316873955819 \n",
      "2259 3051\n",
      "Threshold: 0.62 --- Total prec.: 0.9969108561341571, total rec.: 0.7404129793510325 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.8497272898250894 \n",
      "2173 3051\n",
      "Threshold: 0.64 --- Total prec.: 0.9977043158861341, total rec.: 0.7122254998361193 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.8311340600497226 \n",
      "2085 3051\n",
      "Threshold: 0.66 --- Total prec.: 0.9980852082336046, total rec.: 0.6833824975417896 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.811284046692607 \n",
      "2001 3051\n",
      "Threshold: 0.68 --- Total prec.: 0.9980049875311721, total rec.: 0.655850540806293 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.7915348101265823 \n",
      "1905 3051\n",
      "Threshold: 0.7000000000000001 --- Total prec.: 0.9984276729559748, total rec.: 0.6243854473942969 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.7683000604960677 \n",
      "1791 3051\n",
      "Threshold: 0.72 --- Total prec.: 0.9983277591973244, total rec.: 0.5870206489675516 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.7393188854489163 \n",
      "1674 3051\n",
      "Threshold: 0.74 --- Total prec.: 0.9988066825775657, total rec.: 0.5486725663716814 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.7082716310556377 \n",
      "1522 3051\n",
      "Threshold: 0.76 --- Total prec.: 0.9986876640419947, total rec.: 0.49885283513602097 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.6653551912568306 \n",
      "1370 3051\n",
      "Threshold: 0.78 --- Total prec.: 0.9992706053975201, total rec.: 0.44903310390036055 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.6196291270918137 \n",
      "1215 3051\n",
      "Threshold: 0.8 --- Total prec.: 0.9991776315789473, total rec.: 0.39823008849557523 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.5694867588469651 \n",
      "1045 3051\n",
      "Threshold: 0.8200000000000001 --- Total prec.: 1.0, total rec.: 0.3425106522451655 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.51025390625 \n",
      "890 3051\n",
      "Threshold: 0.84 --- Total prec.: 1.0, total rec.: 0.2917076368403802 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.4516620147170769 \n",
      "720 3051\n",
      "Threshold: 0.86 --- Total prec.: 1.0, total rec.: 0.2359882005899705 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.3818615751789976 \n",
      "553 3051\n",
      "Threshold: 0.88 --- Total prec.: 1.0, total rec.: 0.18125204850868568 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.30688124306326303 \n",
      "382 3051\n",
      "Threshold: 0.9 --- Total prec.: 1.0, total rec.: 0.1252048508685677 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.2225458782406059 \n",
      "204 3051\n",
      "Threshold: 0.92 --- Total prec.: 1.0, total rec.: 0.06686332350049164 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.12534562211981565 \n",
      "90 3051\n",
      "Threshold: 0.9400000000000001 --- Total prec.: 1.0, total rec.: 0.029498525073746312 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.05730659025787966 \n",
      "30 3051\n",
      "Threshold: 0.96 --- Total prec.: 1.0, total rec.: 0.00983284169124877 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.01947419668938656 \n",
      "4 3051\n",
      "Threshold: 0.98 --- Total prec.: 1.0, total rec.: 0.0013110455588331695 w/3051/12344 total pos/neg samples in 10 images. F-score: 0.0026186579378068738 \n",
      "Max f-score: 0.96 thresh:0.30\n",
      "If this performance is not adequate, improve model and try again\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(data_dir=axon_data_dir, brain_id=brain, object_type=\"axon\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If results above are not adequate improve the model and try again\n",
    "\n",
    "In my case, I identify more subvolumes from the sample at hand using the same process as for validation data, and add it as training data to the model and retrain.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(base_dir)\n",
    "files = [base_dir + f for f in files if \"val\" in f]\n",
    "files = [f for f in files if \"_Probabilities.h5\" in f]\n",
    "print(f\"{len(files)} total validation subvolumes\")\n",
    "\n",
    "\n",
    "for i, fname_prob in enumerate(files):\n",
    "    fname_im = fname_prob[:-17] + \".h5\"\n",
    "    f = h5py.File(fname_im, \"r\")\n",
    "    im = f.get(\"image_2channel\")\n",
    "    im_bg = im[0, :, :, :]\n",
    "    im_fg = im[1, :, :, :]\n",
    "    im_endo = im[2, :, :, :]\n",
    "\n",
    "    fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "    f = h5py.File(fname_lab, \"r\")\n",
    "    gt = f.get(\"exported_data\")\n",
    "    gt = gt[0, :, :, :]\n",
    "    pos_labels = gt == 2\n",
    "    neg_labels = gt == 1\n",
    "\n",
    "    f = h5py.File(fname_prob, \"r\")\n",
    "    seg = f.get(\"exported_data\")\n",
    "    seg = seg[1, :, :, :]\n",
    "    mask = seg > best_threshold\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "    false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "    true_labels = np.sum(pos_labels)\n",
    "    true_labels_neg = np.sum(neg_labels)\n",
    "\n",
    "    if true_labels == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = true_pos / true_labels\n",
    "\n",
    "    if true_pos + false_pos == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "\n",
    "    if precision < 0.8 or recall < 0.8:\n",
    "        print(f\"{i}) {fname_prob}: prec{precision} recall: {recall}\")\n",
    "        viewer = napari.Viewer(ndisplay=3)\n",
    "        viewer.add_image(im_fg, name=f\"fg {i}\")\n",
    "        viewer.add_image(im_bg, name=\"bg\")\n",
    "        viewer.add_image(im_endo, name=\"endo\")\n",
    "        viewer.add_labels(mask, name=\"mask\")\n",
    "        viewer.add_labels(pos_labels + 2 * neg_labels, name=\"pos labels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper figure for all validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brains = [\"8650\", \"8649\", \"8613\", \"8589\", \"8590\", \"8788\"]\n",
    "\n",
    "brain_ids = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "best_precisions = []\n",
    "best_recalls = []\n",
    "best_fscores = {}\n",
    "\n",
    "for brain_id in brains:\n",
    "    base_dir = (\n",
    "        \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain\"\n",
    "        + brain_id\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    spacing = 0.02\n",
    "    thresholds = np.arange(spacing, 1.0, spacing)\n",
    "    best_fscore = 0\n",
    "\n",
    "    files = os.listdir(base_dir)\n",
    "    files = [base_dir + f for f in files if \"val\" in f]\n",
    "    files = [f for f in files if \"_Probabilities.h5\" in f]\n",
    "    fiiles = [f for f in files if \"val\" in f]\n",
    "\n",
    "    print(f\"{len(files)} total validation subvolumes for brain {brain_id}\")\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        true_pos_total = 0\n",
    "        false_pos_total = 0\n",
    "        true_labels_total = 0\n",
    "        true_labels_total_neg = 0\n",
    "        for fname_prob in files:\n",
    "            fname_im = fname_prob[:-17] + \".h5\"\n",
    "            f = h5py.File(fname_im, \"r\")\n",
    "            im = f.get(\"image_2channel\")\n",
    "            im_bg = im[0, :, :, :]\n",
    "            im_fg = im[1, :, :, :]\n",
    "\n",
    "            fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "            f = h5py.File(fname_lab, \"r\")\n",
    "            gt = f.get(\"exported_data\")\n",
    "            gt = gt[0, :, :, :]\n",
    "            pos_labels = gt == 2\n",
    "            neg_labels = gt == 1\n",
    "\n",
    "            f = h5py.File(fname_prob, \"r\")\n",
    "            seg = f.get(\"exported_data\")\n",
    "            seg = seg[1, :, :, :]\n",
    "            mask = seg > threshold\n",
    "\n",
    "            true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "            true_pos_total += true_pos\n",
    "            false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "            false_pos_total += false_pos\n",
    "            true_labels = np.sum(pos_labels)\n",
    "            true_labels_total += true_labels\n",
    "            true_labels_neg = np.sum(neg_labels)\n",
    "            true_labels_total_neg += true_labels_neg\n",
    "\n",
    "        precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "        recall_total = true_pos_total / true_labels_total\n",
    "\n",
    "        precisions.append(precision_total)\n",
    "        recalls.append(recall_total)\n",
    "        brain_ids.append(brain_id)\n",
    "\n",
    "        fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "        if fscore > best_fscore:\n",
    "            best_fscore = fscore\n",
    "            best_prec = precision_total\n",
    "            best_recall = recall_total\n",
    "            best_threshold = threshold\n",
    "    best_precisions.append(best_prec)\n",
    "    best_recalls.append(best_recall)\n",
    "    best_fscores[brain_id] = best_fscore\n",
    "for i, brain_id in enumerate(brain_ids):\n",
    "    brain_ids[i] = brain_id + f\" - Max F-score: {best_fscores[brain_id]:.2f}\"\n",
    "\n",
    "data = {\"Sample\": brain_ids, \"Recall\": recalls, \"Precision\": precisions}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "sns.set(font_scale=2)\n",
    "sns.lineplot(data=df, x=\"Recall\", y=\"Precision\", hue=\"Sample\")\n",
    "sns.scatterplot(x=best_recalls, y=best_precisions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make annotation layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axon segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"base\" in brain2paths[brain].keys():\n",
    "    dir = brain2paths[brain][\"base\"] + \"axon_mask\"\n",
    "else:\n",
    "    dir = brain2paths[brain][\"mask\"]\n",
    "\n",
    "try:\n",
    "    CloudVolume(dir)\n",
    "except:\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"segmentation\",\n",
    "        data_type=\"uint64\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=vol_bg.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=vol_bg.voxel_offset,  # x,y,z offset in voxels from the origin\n",
    "        # mesh            = 'mesh',\n",
    "        # Pick a convenient size for your underlying chunk representation\n",
    "        # Powers of two are recommended, doesn't need to cover image exactly\n",
    "        chunk_size=[128, 128, 2],  # units are voxels\n",
    "        volume_size=vol_bg.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(dir, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\"\n",
    ")\n",
    "for layer in [\n",
    "    antibody_layer,\n",
    "    background_layer,\n",
    "    \"axon_mask\",\n",
    "]:  # axon_mask is transformed into an image because nearest interpolation doesnt work well after downsampling\n",
    "    layer_path = brain2paths[brain][\"base\"] + layer + \"_transformed\"\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"image\",\n",
    "        data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=atlas_vol.voxel_offset,\n",
    "        chunk_size=[32, 32, 32],  # units are voxels\n",
    "        volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(layer_path, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply ilastik to whole image:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*\n",
    "\n",
    "You can use the notebook code below or the script using `axon_segment_image.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"test\"\n",
    "antibody_layer = \"antibody\"\n",
    "background_layer = \"background\"\n",
    "endogenous_layer = \"endogenous\"\n",
    "\n",
    "threshold = 0.12  # threshold to use for ilastik\n",
    "data_dir = (\n",
    "    str(Path.cwd().parents[0]) + \"/brain_temp/\"\n",
    ")  # data_dir = \"/data/tathey1/matt_wright/brain_temp/\"  # directory to store temporary subvolumes for segmentation\n",
    "\n",
    "# Ilastik will run in \"headless mode\", and the following paths are needed to do so:\n",
    "ilastik_path = \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"  # \"/data/tathey1/matt_wright/ilastik/ilastik-1.4.0rc5-Linux/run_ilastik.sh\"  # path to ilastik executable\n",
    "ilastik_project = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/axon_segmentation.ilp\"  # \"/data/tathey1/matt_wright/ilastik/model1/axon_segmentation.ilp\"  # path to ilastik project\n",
    "\n",
    "\n",
    "max_coords = [\n",
    "    3072,\n",
    "    4352,\n",
    "    1792,\n",
    "]  # max coords or -1 if you want to process everything along that dimension\n",
    "ncpu = 1  # 16  # number of cores to use for detection\n",
    "chunk_size = [256, 256, 256]  # [256, 256, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [antibody_layer, background_layer, endogenous_layer]\n",
    "alli = ApplyIlastik_LargeImage(\n",
    "    ilastik_path=ilastik_path,\n",
    "    ilastik_project=ilastik_project,\n",
    "    ncpu=ncpu,\n",
    "    object_type=\"axon\",\n",
    ")\n",
    "alli.apply_ilastik_parallel(\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    threshold=threshold,\n",
    "    data_dir=data_dir,\n",
    "    chunk_size=chunk_size,\n",
    "    max_coords=max_coords,\n",
    ")\n",
    "alli.collect_axon_results(brain_id=brain, ng_layer_name=\"127.0.0.1:9010\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Register volume and transform data to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. You need to find an initial affine alignment using cloudreg.scripts.registration.get_affine_matrix. For example: \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A link to the ARA parcellation is:\n",
    "\n",
    "`precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017`\n",
    "\n",
    "And some python commands to help with affine alignment is:\n",
    "\n",
    "```\n",
    "from cloudreg.scripts.registration import get_affine_matrix\n",
    "get_affine_matrix([1,1,1], [15,0,0], \"PIR\", \"RAI\", 1.15, \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Run registration using cloudreg.scripts.registration. For example:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.registration -input_s3_path precomputed://s3://smartspim-precomputed-volumes/2022_11_01/8790/Ch_561 --output_s3_path precomputed://s3://smartspim-precomputed-volumes/2022_11_01/8790/atlas_to_target --atlas_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_50um/average_50um --parcellation_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --atlas_orientation PIR -orientation RAI --rotation 0 0 0 --translation 0 0 0 --fixed_scale 1.2 -log_s3_path precomputed://s3://smartspim-precomputed-volumes/2022_11_01/8790/atlas_to_target --missing_data_correction True --grid_correction False --bias_correction True --regularization 5000.0 --iterations 3000 --registration_resolution 100\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Transform segmentation to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_11_03/8589/axon_mask --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_11_03/8589/axon_mask_transformed --affine_path /mnt/NAS/Neuroglancer\\ Data/2021_11_03/8589/8589_Ch_561_registration/downloop_1_A.mat  --velocity_path /mnt/NAS/Neuroglancer\\ Data/2021_11_03/8589/8589_Ch_561_registration/downloop_1_v.mat\n",
    "```\n",
    "\n",
    "This will write a layer to s3 with the transformed axon mask. The s3 path to this layer should be added to `axon_data.py` under the `axon_mask_transformed` key. Then the code below, or `axon_brainrender.py`, can be used to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://file:///cis/home/tathey/projects/mouselight/brainlit/brainlit/BrainLine/data/example/axon_mask --transformed_layer_source precomputed://file:///cis/home/tathey/projects/mouselight/brainlit/brainlit/BrainLine/data/example/axon_mask_transformed --affine_path /cis/home/tathey/projects/mouselight/brainlit/brainlit/BrainLine/data/example/downloop_1_A.mat  --velocity_path /cis/home/tathey/projects/mouselight/brainlit/brainlit/BrainLine/data/example/downloop_1_v.mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. View coronal heat maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A couple useful lists of samples\n",
    "brain_ids_good = [\"8650\", \"8788\", \"8613\", \"8589\", \"8786\"]\n",
    "brain_ids_select = [\"8650\", \"8788\"]\n",
    "brain_ids = [\"8650\", \"8649\", \"8589\", \"8590\", \"8613\"]\n",
    "\n",
    "colors = {\n",
    "    \"tph2 gad2\": \"red\",\n",
    "    \"tph2 vglut3\": \"green\",\n",
    "}  # colors for different genotypes\n",
    "fold_on = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Relabeling slice: 100%|██████████| 4/4 [00:00<00:00, 375.06it/s]\n",
      "Processing labels: 100%|██████████| 13/13 [00:00<00:00, 50.34it/s]\n",
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 178.54it/s]\n",
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 197.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 570)\n",
      "float64\n",
      "(800, 570)\n",
      "uint64\n",
      "(800, 570)\n",
      "uint64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Relabeling slice: 100%|██████████| 163/163 [00:00<00:00, 319.71it/s]\n",
      "Processing labels: 100%|██████████| 141/141 [00:02<00:00, 68.40it/s]\n",
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 168.63it/s]\n",
      "Downloading: 100%|██████████| 1800/1800 [00:11<00:00, 161.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 570)\n",
      "float64\n",
      "(800, 570)\n",
      "uint64\n",
      "(800, 570)\n",
      "uint64\n"
     ]
    }
   ],
   "source": [
    "ad = AxonDistribution(brain_ids=brain_ids)\n",
    "\n",
    "for z in np.arange(100, 1300, 700):\n",
    "    ad.napari_coronal_section(z=z, subtype_colors=colors, fold_on=fold_on)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Collect region based results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `axon_collect_results.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Display bar charts \\*\\*Wrong!!!!!!!!! normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholebrain_results_dir = \"\"  #\n",
    "\n",
    "brains = [\n",
    "    # \"3\",\n",
    "    # \"4\",\n",
    "    \"8613\",\n",
    "    # \"8604\",\n",
    "    \"8650\",\n",
    "    \"8589\",\n",
    "    # \"8590\",\n",
    "    # \"8649\",\n",
    "    \"8788\",\n",
    "    \"8786\",\n",
    "    \"11537\",\n",
    "    \"8790\",\n",
    "]  # list of sample IDs to be shown\n",
    "\n",
    "regions = [\n",
    "    688,  # cerebral cortex\n",
    "    698,  # olfactory areas\n",
    "    1089,  # hippocampal formation\n",
    "    # 583, # claustrum\n",
    "    477,  # striatum\n",
    "    # 803, # pallidum\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    # 703, #cortical subplate\n",
    "    1097,  # hypothalamus\n",
    "    549,  # thalamus\n",
    "    186,  # lateral habenula\n",
    "    519,  # cerebellar nuclei\n",
    "    313,  # midbrain\n",
    "    1065,  # hindbrain\n",
    "]  # allen atlas region IDs to be shown\n",
    "# see: https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3\n",
    "\n",
    "composite_regions = {\n",
    "    \"Amygdalar Nuclei\": [131, 295, 319, 780]\n",
    "}  # Custom composite allen regions where key is region name and value is list of allen regions\n",
    "\n",
    "\n",
    "level = \"coarse\"  # coarse or fine, dictates whether the regions specified above will be shown (coarse), or their subregions (fine)\n",
    "\n",
    "if level not in [\"coarse\", \"fine\"]:\n",
    "    raise ValueError(f\"level must be coarse or fine, not {level}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "genotypes = []\n",
    "for brain_id in brains:\n",
    "    genotypes.append(brain2paths[brain_id][\"genotype\"])\n",
    "for unq_gene in set(genotypes):\n",
    "    count = 0\n",
    "    for genotype in genotypes:\n",
    "        if genotype == unq_gene:\n",
    "            count += 1\n",
    "    counts[unq_gene] = count\n",
    "\n",
    "\n",
    "quantification_dicts = {}\n",
    "\n",
    "for brain in brains:\n",
    "    path = (\n",
    "        \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/wholebrain_results/wholebrain_\"\n",
    "        + brain\n",
    "        + \".pkl\"\n",
    "    )\n",
    "    with open(path, \"rb\") as f:\n",
    "        quantification_dict = pickle.load(f)\n",
    "\n",
    "    quantification_dicts[brain] = quantification_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = setup_atlas_graph()\n",
    "max_level = 0\n",
    "\n",
    "for node in G.nodes:\n",
    "    if G.nodes[node][\"level\"] > max_level:\n",
    "        max_level = G.nodes[node][\"level\"]\n",
    "    for brain in quantification_dicts.keys():\n",
    "        G.nodes[node][brain + \" axon\"] = 0\n",
    "        G.nodes[node][brain + \" total\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data\n",
    "i_test = 0\n",
    "print(f\"Max level: {max_level}\")\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])\n",
    "for brain, quantification_dict in quantification_dicts.items():\n",
    "    for key in quantification_dict.keys():\n",
    "        if key in G.nodes:\n",
    "            G.nodes[key][brain + \" axon\"] = G.nodes[key][brain + \" axon\"] + float(\n",
    "                quantification_dict[key][1]\n",
    "            )\n",
    "            G.nodes[key][brain + \" total\"] = G.nodes[key][brain + \" total\"] + float(\n",
    "                quantification_dict[key][0]\n",
    "            )\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])\n",
    "\n",
    "# add child data to parent data\n",
    "for brain in quantification_dicts.keys():\n",
    "    for lvl in range(max_level, 0, -1):\n",
    "        for node in G.nodes:\n",
    "            if G.nodes[node][\"level\"] == lvl:\n",
    "                parent = list(G.in_edges(node))[0][0]\n",
    "                G.nodes[parent][brain + \" axon\"] = (\n",
    "                    G.nodes[parent][brain + \" axon\"] + G.nodes[node][brain + \" axon\"]\n",
    "                )\n",
    "                G.nodes[parent][brain + \" total\"] = (\n",
    "                    G.nodes[parent][brain + \" total\"] + G.nodes[node][brain + \" total\"]\n",
    "                )\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" axon\"])\n",
    "print(G.nodes[997][list(quantification_dicts.keys())[i_test] + \" total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = {}\n",
    "\n",
    "for brain in quantification_dicts.keys():\n",
    "    total = 0\n",
    "    for node in G.nodes:\n",
    "        total += G.nodes[node][brain + \" axon\"]\n",
    "    totals[brain] = total\n",
    "\n",
    "axon_vols = []\n",
    "axon_denss = []\n",
    "axon_denss_norm = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "brain_ids = []\n",
    "for region in regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    # choose level here\n",
    "    if level == \"fine\":\n",
    "        children = list(G.successors(region))\n",
    "    elif level == \"coarse\":\n",
    "        children = [region]\n",
    "    else:\n",
    "        raise ValueError(f\"level must be coarse or fine, not {level}\")\n",
    "\n",
    "    for child in children:\n",
    "        for brain in quantification_dicts.keys():\n",
    "            drn_norm_factor = (\n",
    "                G.nodes[872][brain + \" axon\"] / G.nodes[872][brain + \" total\"]\n",
    "            )\n",
    "\n",
    "            if drn_norm_factor == 0:\n",
    "                print(f\"Warning: brain {brain} has no projection in DRN\")\n",
    "                drn_norm_factor = 1\n",
    "\n",
    "            axon_vol = G.nodes[child][brain + \" axon\"]\n",
    "            total_vol = G.nodes[child][brain + \" total\"]\n",
    "            if total_vol == 0 and axon_vol == 0:\n",
    "                axon_denss.append(0)\n",
    "                axon_denss_norm.append(0)\n",
    "            elif total_vol == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                dens = axon_vol / total_vol\n",
    "                axon_denss.append(dens * 100)\n",
    "                axon_denss_norm.append(dens / drn_norm_factor)\n",
    "\n",
    "            axon_vols.append(axon_vol / totals[brain] * 100)\n",
    "            gene.append(\n",
    "                brain2paths[brain][\"genotype\"]\n",
    "                + f\" (n={counts[brain2paths[brain]['genotype']]})\"\n",
    "            )\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "            region_name.append(G.nodes[region][\"name\"])\n",
    "            brain_ids.append(brain)\n",
    "\n",
    "for region_component_name in composite_regions.keys():\n",
    "    print(f\"Populating: \" + region_component_name)\n",
    "    region_components = composite_regions[region_component_name]\n",
    "    for brain in quantification_dicts.keys():\n",
    "        drn_norm_factor = G.nodes[872][brain + \" axon\"] / G.nodes[872][brain + \" total\"]\n",
    "        if drn_norm_factor == 0:\n",
    "            print(f\"Warning: brain {brain} has no projection in DRN\")\n",
    "            drn_norm_factor = 1\n",
    "\n",
    "        axon_vol = 0\n",
    "        total_vol = 0\n",
    "\n",
    "        for region_component in region_components:\n",
    "            axon_vol += G.nodes[region_component][brain + \" axon\"]\n",
    "            total_vol += G.nodes[region_component][brain + \" total\"]\n",
    "\n",
    "        if total_vol == 0 and axon_vol == 0:\n",
    "            axon_denss.append(0)\n",
    "            axon_denss_norm.append(0)\n",
    "        elif total_vol == 0:\n",
    "            raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "        else:\n",
    "            dens = axon_vol / total_vol\n",
    "            axon_denss.append(dens * 100)\n",
    "            axon_denss_norm.append(dens / drn_norm_factor)\n",
    "\n",
    "        axon_vols.append(axon_vol / totals[brain] * 100)\n",
    "        gene.append(\n",
    "            brain2paths[brain][\"genotype\"]\n",
    "            + f\" (n={counts[brain2paths[brain]['genotype']]})\"\n",
    "        )\n",
    "        subregion_name.append(region_component_name)\n",
    "        region_name.append(region_component_name)\n",
    "        brain_ids.append(brain)\n",
    "\n",
    "\n",
    "d = {\n",
    "    \"Percent Total Axon Volume (%)\": axon_vols,\n",
    "    \"Axon Density (%)\": axon_denss,\n",
    "    \"Normalized Axon Density\": axon_denss_norm,\n",
    "    \"Gene\": gene,\n",
    "    \"Subregion\": subregion_name,\n",
    "    \"Region\": region_name,\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(26, 13))\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "test = \"Mann-Whitney\"\n",
    "# test = \"t-test_ind\"\n",
    "correction = \"fdr_by\"\n",
    "\n",
    "# density\n",
    "fig_args = {\n",
    "    \"y\": \"Axon Density (%)\",\n",
    "    \"x\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "pairs = []\n",
    "unq_subregions = []\n",
    "for subregion in subregion_name:\n",
    "    if subregion not in unq_subregions:\n",
    "        unq_subregions.append(subregion)\n",
    "\n",
    "\n",
    "genes = df[\"Gene\"].unique()\n",
    "gene_pairs = [(a, b) for idx, a in enumerate(genes) for b in genes[idx + 1 :]]\n",
    "\n",
    "for gene_pair in gene_pairs:\n",
    "    for subregion in unq_subregions:\n",
    "        pairs.append(\n",
    "            (\n",
    "                (subregion, gene_pair[0]),\n",
    "                (subregion, gene_pair[1]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "annotator = Annotator(axes[0], pairs, **fig_args)\n",
    "fig_args = {\n",
    "    \"x\": \"Axon Density (%)\",\n",
    "    \"y\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "strpplot = sns.barplot(ax=axes[0], orient=\"h\", **fig_args)\n",
    "strpplot.set_xscale(\"log\")\n",
    "\n",
    "annotator.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=correction\n",
    ")\n",
    "annotator.new_plot(strpplot, orient=\"h\", plot=\"barplot\", **fig_args)\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "# percent total\n",
    "fig_args = {\n",
    "    \"y\": \"Percent Total Axon Volume (%)\",\n",
    "    \"x\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "pairs = []\n",
    "unq_subregions = []\n",
    "for subregion in subregion_name:\n",
    "    if subregion not in unq_subregions:\n",
    "        unq_subregions.append(subregion)\n",
    "\n",
    "\n",
    "for gene_pair in gene_pairs:\n",
    "    for subregion in unq_subregions:\n",
    "        pairs.append(\n",
    "            (\n",
    "                (subregion, gene_pair[0]),\n",
    "                (subregion, gene_pair[1]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "annotator = Annotator(axes[1], pairs, **fig_args)\n",
    "fig_args = {\n",
    "    \"x\": \"Percent Total Axon Volume (%)\",\n",
    "    \"y\": \"Subregion\",\n",
    "    \"hue\": \"Gene\",\n",
    "    \"data\": df,\n",
    "}\n",
    "\n",
    "strpplot = sns.barplot(ax=axes[1], orient=\"h\", **fig_args)\n",
    "strpplot.set_xscale(\"log\")\n",
    "\n",
    "annotator.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=correction\n",
    ")\n",
    "annotator.new_plot(strpplot, orient=\"h\", plot=\"barplot\", **fig_args)\n",
    "annotator.apply_and_annotate()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distributions with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "brain_ids = []\n",
    "genotypes = []\n",
    "\n",
    "for i, brain in enumerate(brains):\n",
    "    print(brain)\n",
    "    region_order = list(df.loc[df[\"Brain ID\"] == brain][\"Region\"])\n",
    "\n",
    "    if i == 0:\n",
    "        standard_region_order = region_order\n",
    "    elif standard_region_order != region_order:\n",
    "        raise ValueError(f\"Different region order for brain {brain}\")\n",
    "\n",
    "    distrib = list(df.loc[df[\"Brain ID\"] == brain][\"Percent Total Axon Volume (%)\"])\n",
    "    X.append(distrib)\n",
    "\n",
    "    brain_ids.append(brain)\n",
    "    genotypes.append(brains[brain])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2 = pca.fit_transform(X)\n",
    "\n",
    "df_pca = {\n",
    "    \"PC 1\": X_2[:, 0],\n",
    "    \"PC 2\": X_2[:, 1],\n",
    "    \"Genotype\": genotypes,\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df_pca = pd.DataFrame(data=df_pca)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "sns.scatterplot(data=df_pca, x=\"PC 1\", y=\"PC 2\", hue=\"Genotype\", ax=ax)\n",
    "\n",
    "\n",
    "for i in range(df_pca.shape[0]):\n",
    "    plt.text(\n",
    "        x=df_pca[\"PC 1\"][i] + 0.03,\n",
    "        y=df_pca[\"PC 2\"][i] + 0.03,\n",
    "        s=df_pca[\"Brain ID\"][i],\n",
    "        fontdict=dict(color=\"black\", size=20),\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Projection Distribution PCA with Explained Variance: {pca.explained_variance_ratio_}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Compare to Allen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen_regions = [\n",
    "    315,\n",
    "    698,\n",
    "    1089,\n",
    "    703,\n",
    "    477,\n",
    "    803,\n",
    "    549,\n",
    "    1097,\n",
    "    313,\n",
    "    771,\n",
    "    354,\n",
    "    512,\n",
    "]  # allen atlas region IDs to be shown https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "subregions_list = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    children = list(G.successors(region))\n",
    "    for child in children:\n",
    "        if child not in subregions_list:\n",
    "            subregions_list.append(child)\n",
    "\n",
    "        for brain in quantification_dicts.keys():\n",
    "            if (\n",
    "                G.nodes[child][brain + \" total\"] == 0\n",
    "                and G.nodes[child][brain + \" axon\"] == 0\n",
    "            ):\n",
    "                axon_denss.append(0)\n",
    "            elif G.nodes[child][brain + \" total\"] == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                axon_denss.append(\n",
    "                    G.nodes[child][brain + \" axon\"] / G.nodes[child][brain + \" total\"]\n",
    "                )\n",
    "\n",
    "            if brain in [\"B\", \"R\"]:\n",
    "                gene.append(brain)\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "\n",
    "    region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse(brainlit_path / \"brainlit\" / \"lsm_analysis\" / \"data\" / \"sert_exp.xml\")\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "        if region in subregions_list and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(f\"id: {region} hemi: {hemi}, density: {density}, name: {name}\")\n",
    "            subregion_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "\n",
    "\n",
    "d = {\"Axon Density\": axon_denss, \"Gene\": gene, \"Subregion\": subregion_name}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(20, 10))\n",
    "fig.suptitle(\"Detected Output Axons\")\n",
    "\n",
    "sns.barplot(x=\"Axon Density\", y=\"Subregion\", hue=\"Gene\", data=df)\n",
    "axes.set_title(\"Density\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "axon_vols = []\n",
    "gene = []\n",
    "region_name = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    for brain in quantification_dicts.keys():\n",
    "        if (\n",
    "            G.nodes[region][brain + \" total\"] == 0\n",
    "            and G.nodes[region][brain + \" axon\"] == 0\n",
    "        ):\n",
    "            axon_denss.append(0)\n",
    "        elif G.nodes[region][brain + \" total\"] == 0:\n",
    "            raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "        else:\n",
    "            axon_denss.append(\n",
    "                G.nodes[region][brain + \" axon\"] / G.nodes[region][brain + \" total\"]\n",
    "            )\n",
    "            axon_vols.append(\n",
    "                G.nodes[region][brain + \" axon\"]\n",
    "                * np.product([1.82, 1.82, 2])\n",
    "                * 10 ** (-9)\n",
    "            )\n",
    "\n",
    "        if brain in [\"B\", \"R\"]:\n",
    "            gene.append(\"Sample \" + brain)\n",
    "\n",
    "        region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse(brainlit_path / \"brainlit\" / \"lsm_analysis\" / \"data\" / \"sert_exp.xml\")\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "            elif item.tag == \"projection-volume\":\n",
    "                volume = float(item.text)\n",
    "        if region in allen_regions and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(\n",
    "                f\"id: {region} hemi: {hemi}, density: {density}, volume: {volume}, name: {name}\"\n",
    "            )\n",
    "            region_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "            axon_vols.append(volume)\n",
    "\n",
    "\n",
    "d = {\n",
    "    \"Axon Density\": axon_denss,\n",
    "    \"Axon Volume ($mm^3$)\": axon_vols,\n",
    "    \"Gene\": gene,\n",
    "    \"Region\": region_name,\n",
    "}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle(\"Comparing Axon Volumes to Allen Experiment\")\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "sns.barplot(\n",
    "    ax=axes[0],\n",
    "    x=\"Axon Density\",\n",
    "    y=\"Region\",\n",
    "    hue=\"Gene\",\n",
    "    order=list(\n",
    "        df[df[\"Gene\"] == \"Allen\"]\n",
    "        .sort_values(\"Axon Density\", ascending=False)\n",
    "        .loc[:, \"Region\"]\n",
    "    ),\n",
    "    data=df,\n",
    ")\n",
    "# axes[0].set_title(\"Density\")\n",
    "\n",
    "sns.barplot(\n",
    "    ax=axes[1],\n",
    "    x=\"Axon Volume ($mm^3$)\",\n",
    "    y=\"Region\",\n",
    "    hue=\"Gene\",\n",
    "    order=list(\n",
    "        df[df[\"Gene\"] == \"Allen\"]\n",
    "        .sort_values(\"Axon Density\", ascending=False)\n",
    "        .loc[:, \"Region\"]\n",
    "    ),\n",
    "    data=df,\n",
    ")\n",
    "# axes[1].set_title(\"Axon Volume\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n",
      "image_2channel\n"
     ]
    }
   ],
   "source": [
    "from brainlit.BrainLine.util import find_sample_names\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/\"\n",
    "\n",
    "brains = [\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"887\",\n",
    "    \"8589\",\n",
    "    \"8590\",\n",
    "    \"8590_v2\",\n",
    "    \"8604\",\n",
    "    \"8612\",\n",
    "    \"8613\",\n",
    "    \"8649\",\n",
    "    \"8650\",\n",
    "    \"8786\",\n",
    "    \"8788\",\n",
    "    \"8790\",\n",
    "    \"11537\",\n",
    "]\n",
    "\n",
    "for brain in brains:\n",
    "    brain_dir = base_dir + \"brain\" + brain\n",
    "    files = find_sample_names(brain_dir, dset=\"\", add_dir=True)\n",
    "    for file in files:\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            key = list(f.keys())[0]\n",
    "            print(key)\n",
    "        #     image = np.array(f.get(key))\n",
    "        # image = image[[1, 0, 2],:,:,:]\n",
    "        # with h5py.File(file, \"w\") as f:\n",
    "        #     dset = f.create_dataset(key, data=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 99, 99, 99)\n",
      "723\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train_0-image_2channel_Labels.h5\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    key = list(f.keys())[0]\n",
    "    image = np.array(f.get(key))\n",
    "    print(image.shape)\n",
    "    print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 99, 99, 99)\n",
      "723\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.load(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train_0-image_2channel_Labels.npy\"\n",
    ")\n",
    "print(image.shape)\n",
    "print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain4/train/train_3-image_2channel_Labels.npy\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fq/9t66hqz51y5ddnygddgjtsmc0000gn/T/ipykernel_10507/4075563596.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    445\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    446\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[0;32m~/Documents/mimlab/mouselight/docs_env/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "dir = (\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain4/train/\"\n",
    ")\n",
    "for file in os.listdir(dir):\n",
    "    if \"Labels\" in file:\n",
    "        file = dir + file\n",
    "        print(file)\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            key = list(f.keys())[0]\n",
    "            image = np.array(f.get(key))\n",
    "        print(np.sum(image))\n",
    "        # npy_file = file.split(\".\")[0] + \".npy\"\n",
    "        # np.save(npy_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train/train_31-image_2channel_Labels.h5\"\n",
    "with h5py.File(file, \"r\") as f:\n",
    "    key = list(f.keys())[0]\n",
    "    image = np.array(f.get(key))\n",
    "npy_file = file.split(\".\")[0] + \".npy\"\n",
    "np.save(npy_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = CloudVolume(\n",
    "    \"precomputed://https://dlab-colm.neurodata.io/2022_10_24/8788/axon_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_sub = vol[int(256*11/8):int(256*12/8),int(256*16/8):int(256*17/8), int(256*6:256*7/8)]\n",
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://s3://smartspim-precomputed-volumes/2022_03_10/8531/atlas_to_target\"\n",
    ")\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"segmentation\",\n",
    "    data_type=\"uint64\",  # Channel images might be 'uint8'\n",
    "    encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=atlas_vol.voxel_offset,\n",
    "    chunk_size=[32, 32, 32],  # units are voxels\n",
    "    volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol_mask = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/atlas_to_target\",\n",
    "    info=info,\n",
    "    compress=False,\n",
    ")\n",
    "vol_mask.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 256/256 [00:18<00:00, 13.70it/s]\n",
      "Uploading: 100%|██████████| 8/8 [00:00<00:00, 59.93it/s]\n"
     ]
    }
   ],
   "source": [
    "vol_mask[\n",
    "    int(256 * 11 / 8) : int(256 * 12 / 8),\n",
    "    int(256 * 16 / 8) : int(256 * 17 / 8),\n",
    "    256 * 6 : 256 * 7,\n",
    "] = atlas_vol[\n",
    "    int(256 * 11 / 8) : int(256 * 12 / 8),\n",
    "    int(256 * 16 / 8) : int(256 * 17 / 8),\n",
    "    256 * 6 : 256 * 7,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvol = np.load(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/axon_mask_transformed/subvol.npy\"\n",
    ")\n",
    "vol = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/axon_mask_transformed\",\n",
    "    compress=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 8/8 [00:00<00:00, 63.73it/s]\n"
     ]
    }
   ],
   "source": [
    "vol[30 * 32 : 32 * 32, 7 * 32 : 9 * 32, 16 * 32 : 18 * 32] = subvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
