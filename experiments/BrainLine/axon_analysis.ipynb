{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Axon Segmentation Analysis of Whole-Brain Light-Sheet Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.preprocessing import removeSmallCCs\n",
    "from brainlit.BrainLine.util import json_to_points, download_subvolumes\n",
    "from brainlit.BrainLine.parse_ara import *\n",
    "import xml.etree.ElementTree as ET\n",
    "from brainlit.BrainLine.imports import *\n",
    "from brainlit.BrainLine.apply_ilastik import (\n",
    "    ApplyIlastik,\n",
    "    ApplyIlastik_LargeImage,\n",
    "    plot_results,\n",
    ")\n",
    "from brainlit.BrainLine.analyze_results import (\n",
    "    AxonDistribution,\n",
    "    collect_regional_segmentation,\n",
    ")\n",
    "\n",
    "%gui qt5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Before Using this notebook:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install brainlit, and other packages that this notebook uses\n",
    "### 1b. Write images to s3 using CloudReg\n",
    "    - e.g. python -m cloudreg.scripts.create_precomputed_volumes --s3_input_paths /mnt/NAS/SmartSPIM_Data/2022_03_02/20220302_14_40_04_8529_destriped_DONE/Ex_561_Em_600_stitched --s3_output_paths  s3://smartspim-precomputed-volumes/2022_03_02/8529/Ch_561_v2  --voxel_size 1.83 1.83 2 --num_procs 24 --resample_iso False\n",
    "### 1c. Make point annotations in neuroglancer to identify subvolumes for validation (and possible training)\n",
    "    - instructions: https://neurodata.io/help/neuroglancer-pt-annotations/\n",
    "        ,\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"val\",\n",
    "    \"points\": []\n",
    "    }\n",
    "### 1d. Update axon_data.py file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brainlit_path = Path(os.path.abspath(\"\"))\n",
    "brainlit_path = brainlit_path.parents[1]\n",
    "print(f\"Path to brainlit: {brainlit_path}\")\n",
    "data_file = brainlit_path / \"experiments\" / \"BrainLine\" / \"data\" / \"axon_data.json\"\n",
    "\n",
    "with open(data_file) as f:\n",
    "    data = json.load(f)\n",
    "brain2paths = data[\"brain2paths\"]\n",
    "\n",
    "for id in brain2paths.keys():\n",
    "    if \"base\" in brain2paths[id].keys() and \"val_info\" in brain2paths[id].keys():\n",
    "        base = brain2paths[id][\"base\"]\n",
    "        if \"http\" in base:\n",
    "            print(f\"Sample {id}: http in basepath, which may cause write errors\")\n",
    "\n",
    "        try:\n",
    "            url = brain2paths[id][\"val_info\"][\"url\"]\n",
    "            layer = brain2paths[id][\"val_info\"][\"layer\"]\n",
    "            pts = json_to_points(url)[layer]\n",
    "        except:\n",
    "            print(f\"Sample {id}: Error with val_info\")\n",
    "\n",
    "        if \"train_info\" in brain2paths[id].keys():\n",
    "            try:\n",
    "                url = brain2paths[id][\"train_info\"][\"url\"]\n",
    "                layer = brain2paths[id][\"train_info\"][\"layer\"]\n",
    "                pts = json_to_points(url)[layer]\n",
    "            except:\n",
    "                print(f\"Sample {id}: Error with train_info\")\n",
    "    else:\n",
    "        print(f\"Sample {id}: Does not conform to desired format\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download benchmark data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibody_layer = \"Ch_647\"\n",
    "background_layer = \"Ch_561\"\n",
    "endogenous_layer = \"Ch_488\"\n",
    "\n",
    "brain = \"MS11\"  # brain ID\n",
    "axon_data_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/\"  # path to directory where training/validation data should be stored\n",
    "dataset_to_save = \"val\"  # train or val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvol_base = brain2paths[brain][\"base\"]\n",
    "layer_names = [antibody_layer, background_layer, endogenous_layer]\n",
    "\n",
    "for layer in [antibody_layer, background_layer, endogenous_layer]:\n",
    "    try:\n",
    "        CloudVolume(cvol_base + layer)\n",
    "    except:\n",
    "        print(f\"Sample {id}: Layer {layer} not found in {cvol_base}\")\n",
    "\n",
    "if brain not in brain2paths.keys():\n",
    "    raise ValueError(f\"brain {brain} not an entry in brain2paths in axon_data.py file\")\n",
    "\n",
    "if f\"{dataset_to_save}_info\" not in brain2paths[\n",
    "    brain\n",
    "].keys() or dataset_to_save not in [\"train\", \"val\"]:\n",
    "    raise ValueError(f\"{dataset_to_save}_info not in brain2paths[{brain}].keys()\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_subvolumes(\n",
    "    axon_data_dir,\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    dataset_to_save=dataset_to_save,\n",
    "    object_type=\"axon\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View downloaded data (optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8649/val_775_4829_2459.h5\"  # path to file for viewing\n",
    "scale = [1.8, 1.8, 2]  # voxel size in microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, \"r\") as f:\n",
    "    pred = f.get(\"image_2channel\")\n",
    "    image_bg = pred[0, :, :, :]\n",
    "    image_fg = pred[1, :, :, :]\n",
    "    image_endo = pred[2, :, :, :]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg, scale=scale)\n",
    "viewer.add_image(image_bg, scale=scale)\n",
    "viewer.add_image(image_endo, scale=scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Ilastik to validation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to do two things:\n",
    "- add annotations to the downloaded data (for me, partial labels on 3 of the z-slices using ilastik)\n",
    "- apply axon segmentation model to the downloaded data. Results should be located in the same directory at the subvolumes, with the addition of \"_Probabilities\" appended to the file names: you can do this programmatically (below), or you can use the ilastik GUI (which is sometimes faster)\n",
    "\n",
    "Note: make sure foreground/background labels are matched between the model and your annotations (for me, blue/1 =axon yellow/0=bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/axon_segmentation.ilp\"  # path to ilastik model to be used\n",
    "ilastik_path = (\n",
    "    \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"\n",
    ")\n",
    "brains = [brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyilastik = ApplyIlastik(\n",
    "    ilastk_path=ilastik_path,\n",
    "    project_path=project_path,\n",
    "    brains_path=axon_data_dir,\n",
    "    brains=brains,\n",
    ")\n",
    "applyilastik.process_subvols()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    data_dir=axon_data_dir, brain_ids=[brain], object_type=\"axon\", positive_channel=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If results above are not adequate improve the model and try again\n",
    "\n",
    "In my case, I identify more subvolumes from the sample at hand using the same process as for validation data, and add it as training data to the model and retrain.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(base_dir)\n",
    "files = [base_dir + f for f in files if \"val\" in f]\n",
    "files = [f for f in files if \"_Probabilities.h5\" in f]\n",
    "print(f\"{len(files)} total validation subvolumes\")\n",
    "\n",
    "\n",
    "for i, fname_prob in enumerate(files):\n",
    "    fname_im = fname_prob[:-17] + \".h5\"\n",
    "    f = h5py.File(fname_im, \"r\")\n",
    "    im = f.get(\"image_2channel\")\n",
    "    im_bg = im[0, :, :, :]\n",
    "    im_fg = im[1, :, :, :]\n",
    "    im_endo = im[2, :, :, :]\n",
    "\n",
    "    fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "    f = h5py.File(fname_lab, \"r\")\n",
    "    gt = f.get(\"exported_data\")\n",
    "    gt = gt[0, :, :, :]\n",
    "    pos_labels = gt == 2\n",
    "    neg_labels = gt == 1\n",
    "\n",
    "    f = h5py.File(fname_prob, \"r\")\n",
    "    seg = f.get(\"exported_data\")\n",
    "    seg = seg[1, :, :, :]\n",
    "    mask = seg > best_threshold\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "    false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "    true_labels = np.sum(pos_labels)\n",
    "    true_labels_neg = np.sum(neg_labels)\n",
    "\n",
    "    if true_labels == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = true_pos / true_labels\n",
    "\n",
    "    if true_pos + false_pos == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "\n",
    "    if precision < 0.8 or recall < 0.8:\n",
    "        print(f\"{i}) {fname_prob}: prec{precision} recall: {recall}\")\n",
    "        viewer = napari.Viewer(ndisplay=3)\n",
    "        viewer.add_image(im_fg, name=f\"fg {i}\")\n",
    "        viewer.add_image(im_bg, name=\"bg\")\n",
    "        viewer.add_image(im_endo, name=\"endo\")\n",
    "        viewer.add_labels(mask, name=\"mask\")\n",
    "        viewer.add_labels(pos_labels + 2 * neg_labels, name=\"pos labels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper figure for all validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brains = [\"8650\", \"8649\", \"8613\", \"8589\", \"8590\", \"8788\"]\n",
    "\n",
    "brain_ids = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "best_precisions = []\n",
    "best_recalls = []\n",
    "best_fscores = {}\n",
    "\n",
    "for brain_id in brains:\n",
    "    base_dir = (\n",
    "        \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain\"\n",
    "        + brain_id\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    spacing = 0.02\n",
    "    thresholds = np.arange(spacing, 1.0, spacing)\n",
    "    best_fscore = 0\n",
    "\n",
    "    files = os.listdir(base_dir)\n",
    "    files = [base_dir + f for f in files if \"val\" in f]\n",
    "    files = [f for f in files if \"_Probabilities.h5\" in f]\n",
    "    fiiles = [f for f in files if \"val\" in f]\n",
    "\n",
    "    print(f\"{len(files)} total validation subvolumes for brain {brain_id}\")\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        true_pos_total = 0\n",
    "        false_pos_total = 0\n",
    "        true_labels_total = 0\n",
    "        true_labels_total_neg = 0\n",
    "        for fname_prob in files:\n",
    "            fname_im = fname_prob[:-17] + \".h5\"\n",
    "            f = h5py.File(fname_im, \"r\")\n",
    "            im = f.get(\"image_2channel\")\n",
    "            im_bg = im[0, :, :, :]\n",
    "            im_fg = im[1, :, :, :]\n",
    "\n",
    "            fname_lab = fname_prob[:-17] + \"-image_2channel_Labels.h5\"\n",
    "            f = h5py.File(fname_lab, \"r\")\n",
    "            gt = f.get(\"exported_data\")\n",
    "            gt = gt[0, :, :, :]\n",
    "            pos_labels = gt == 2\n",
    "            neg_labels = gt == 1\n",
    "\n",
    "            f = h5py.File(fname_prob, \"r\")\n",
    "            seg = f.get(\"exported_data\")\n",
    "            seg = seg[1, :, :, :]\n",
    "            mask = seg > threshold\n",
    "\n",
    "            true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "            true_pos_total += true_pos\n",
    "            false_pos = np.sum(np.logical_and(mask, gt == 1))\n",
    "            false_pos_total += false_pos\n",
    "            true_labels = np.sum(pos_labels)\n",
    "            true_labels_total += true_labels\n",
    "            true_labels_neg = np.sum(neg_labels)\n",
    "            true_labels_total_neg += true_labels_neg\n",
    "\n",
    "        precision_total = true_pos_total / (true_pos_total + false_pos_total)\n",
    "        recall_total = true_pos_total / true_labels_total\n",
    "\n",
    "        precisions.append(precision_total)\n",
    "        recalls.append(recall_total)\n",
    "        brain_ids.append(brain_id)\n",
    "\n",
    "        fscore = 2 / (1 / precision_total + 1 / recall_total)\n",
    "\n",
    "        if fscore > best_fscore:\n",
    "            best_fscore = fscore\n",
    "            best_prec = precision_total\n",
    "            best_recall = recall_total\n",
    "            best_threshold = threshold\n",
    "    best_precisions.append(best_prec)\n",
    "    best_recalls.append(best_recall)\n",
    "    best_fscores[brain_id] = best_fscore\n",
    "for i, brain_id in enumerate(brain_ids):\n",
    "    brain_ids[i] = brain_id + f\" - Max F-score: {best_fscores[brain_id]:.2f}\"\n",
    "\n",
    "data = {\"Sample\": brain_ids, \"Recall\": recalls, \"Precision\": precisions}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "sns.set(font_scale=2)\n",
    "sns.lineplot(data=df, x=\"Recall\", y=\"Precision\", hue=\"Sample\")\n",
    "sns.scatterplot(x=best_recalls, y=best_precisions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make annotation layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axon segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"base\" in brain2paths[brain].keys():\n",
    "    dir = brain2paths[brain][\"base\"] + \"axon_mask\"\n",
    "else:\n",
    "    dir = brain2paths[brain][\"mask\"]\n",
    "\n",
    "try:\n",
    "    CloudVolume(dir)\n",
    "except:\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"segmentation\",\n",
    "        data_type=\"uint64\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=vol_bg.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=vol_bg.voxel_offset,  # x,y,z offset in voxels from the origin\n",
    "        # mesh            = 'mesh',\n",
    "        # Pick a convenient size for your underlying chunk representation\n",
    "        # Powers of two are recommended, doesn't need to cover image exactly\n",
    "        chunk_size=[128, 128, 2],  # units are voxels\n",
    "        volume_size=vol_bg.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(dir, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\"\n",
    ")\n",
    "for layer in [\n",
    "    antibody_layer,\n",
    "    background_layer,\n",
    "    \"axon_mask\",\n",
    "]:  # axon_mask is transformed into an image because nearest interpolation doesnt work well after downsampling\n",
    "    layer_path = brain2paths[brain][\"base\"] + layer + \"_transformed\"\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"image\",\n",
    "        data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=atlas_vol.voxel_offset,\n",
    "        chunk_size=[32, 32, 32],  # units are voxels\n",
    "        volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(layer_path, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply ilastik to whole image:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*\n",
    "\n",
    "You can use the notebook code below or the script using `axon_segment_image.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"test\"\n",
    "antibody_layer = \"antibody\"\n",
    "background_layer = \"background\"\n",
    "endogenous_layer = \"endogenous\"\n",
    "\n",
    "threshold = 0.12  # threshold to use for ilastik\n",
    "data_dir = (\n",
    "    str(Path.cwd().parents[0]) + \"/brain_temp/\"\n",
    ")  # data_dir = \"/data/tathey1/matt_wright/brain_temp/\"  # directory to store temporary subvolumes for segmentation\n",
    "\n",
    "# Ilastik will run in \"headless mode\", and the following paths are needed to do so:\n",
    "ilastik_path = \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"  # \"/data/tathey1/matt_wright/ilastik/ilastik-1.4.0rc5-Linux/run_ilastik.sh\"  # path to ilastik executable\n",
    "ilastik_project = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/axon_segmentation.ilp\"  # \"/data/tathey1/matt_wright/ilastik/model1/axon_segmentation.ilp\"  # path to ilastik project\n",
    "\n",
    "\n",
    "max_coords = [\n",
    "    3072,\n",
    "    4352,\n",
    "    1792,\n",
    "]  # max coords or -1 if you want to process everything along that dimension\n",
    "ncpu = 1  # 16  # number of cores to use for detection\n",
    "chunk_size = [256, 256, 256]  # [256, 256, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [antibody_layer, background_layer, endogenous_layer]\n",
    "alli = ApplyIlastik_LargeImage(\n",
    "    ilastik_path=ilastik_path,\n",
    "    ilastik_project=ilastik_project,\n",
    "    ncpu=ncpu,\n",
    "    object_type=\"axon\",\n",
    ")\n",
    "alli.apply_ilastik_parallel(\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    threshold=threshold,\n",
    "    data_dir=data_dir,\n",
    "    chunk_size=chunk_size,\n",
    "    max_coords=max_coords,\n",
    ")\n",
    "alli.collect_axon_results(brain_id=brain, ng_layer_name=\"127.0.0.1:9010\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Register volume and transform data to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. You need to find an initial affine alignment using cloudreg.scripts.registration.get_affine_matrix. For example: \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A link to the ARA parcellation is:\n",
    "\n",
    "`precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017`\n",
    "\n",
    "And some python commands to help with affine alignment is:\n",
    "\n",
    "```\n",
    "from cloudreg.scripts.registration import get_affine_matrix\n",
    "get_affine_matrix([1,1,1], [15,0,0], \"PIR\", \"RAI\", 1.15, \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Run registration using cloudreg.scripts.registration. For example:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.registration -input_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_28/MS10/Ch_561 --output_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_28/MS10/atlas_to_target --atlas_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_50um/average_50um --parcellation_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --atlas_orientation PIR -orientation RPI --rotation 0 0 0 --translation 0 0 0 --fixed_scale 1.07 -log_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_28/MS10/atlas_to_target --missing_data_correction True --grid_correction False --bias_correction True --regularization 5000.0 --iterations 3000 --registration_resolution 100\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Transform segmentation to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_10_26/11537/axon_mask --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_10_26/11537/axon_mask_transformed --affine_path /mnt/NAS/Neuroglancer\\ Data/2023_04_07/MS29_Ch_561_registration/downloop_1_A.mat  --velocity_path /mnt/NAS/Neuroglancer\\ Data/2023_04_07/MS29_Ch_561_registration/downloop_1_v.mat\n",
    "```\n",
    "\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_10_26/11537/axon_mask --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_10_26/11537/axon_mask_transformed --affine_path /cis/home/tathey/11537_Ch_561_registration/downloop_1_A.mat  --velocity_path /cis/home/tathey/11537_Ch_561_registration/downloop_1_v.mat\n",
    "\n",
    "This will write a layer to s3 with the transformed axon mask. The s3 path to this layer should be added to `axon_data.py` under the `axon_mask_transformed` key. Then the code below, or `axon_brainrender.py`, can be used to visualize the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Combine registration and segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_regional_segmentation(\n",
    "    brain_id=brain,\n",
    "    outdir=axon_data_dir,\n",
    "    max_coords=[\n",
    "        6029,\n",
    "        -1,\n",
    "        -1,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. View coronal heat maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_ids = [\n",
    "    # \"3\",\n",
    "    # \"4\",\n",
    "    \"8613\",\n",
    "    # \"8604\",\n",
    "    \"8650\",\n",
    "    \"8589\",\n",
    "    # \"8590\",\n",
    "    # \"8649\",\n",
    "    \"8788\",\n",
    "    \"8786\",\n",
    "    \"11537\",\n",
    "    \"8790\",\n",
    "    \"MS32\",\n",
    "    \"MS29\",\n",
    "    \"MS11\",\n",
    "    \"MS15\",\n",
    "]  # list of sample IDs to be shown\n",
    "\n",
    "brain_ids = [\n",
    "    # \"3\",\n",
    "    # \"4\",\n",
    "    \"8613\",\n",
    "    # \"8604\",\n",
    "    \"8650\",\n",
    "    \"8589\",\n",
    "    # \"8590\",\n",
    "    # \"8649\",\n",
    "    \"8788\",\n",
    "    \"8786\",\n",
    "    # \"11537\",\n",
    "    \"8790\",\n",
    "    \"MS32\",\n",
    "    \"MS29\",\n",
    "    \"MS11\",\n",
    "    \"MS15\",\n",
    "]  # list of sample IDs to be shown\n",
    "\n",
    "colors = {\n",
    "    \"tph2 gad2\": \"red\",\n",
    "    \"tph2 vglut3\": \"blue\",\n",
    "    \"gad2 vgat\": \"green\",\n",
    "}  # colors for different genotypes\n",
    "fold_on = False\n",
    "\n",
    "\n",
    "axon_data_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/wholebrain_results/\"\n",
    "\n",
    "ad = AxonDistribution(\n",
    "    brain_ids=brain_ids, regional_distribution_dir=axon_data_dir, data_file=data_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in np.arange(200, 1300, 200):\n",
    "    ad.napari_coronal_section(z=z, subtype_colors=colors, fold_on=fold_on)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Display bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    688,  # cerebral cortex\n",
    "    95,  # agranular insular area\n",
    "    714,  # orbital area\n",
    "    698,  # olfactory areas\n",
    "    1089,  # hippocampal formation\n",
    "    # 583, # claustrum\n",
    "    477,  # striatum\n",
    "    # 803, # pallidum\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    # 703, #cortical subplate\n",
    "    1097,  # hypothalamus\n",
    "    157,  # periventricular zone\n",
    "    515,  # medial preoptic nucleus\n",
    "    290,  # hypothalamic lateral zone\n",
    "    331,  # mammillary body\n",
    "    797,  # zona incerta\n",
    "    549,  # thalamus\n",
    "    186,  # lateral habenula\n",
    "    519,  # cerebellar nuclei\n",
    "    846,  # dentate nucleus\n",
    "    726,  # dentate gyrus\n",
    "    313,  # midbrain\n",
    "    157,  # inferior colliculus\n",
    "    1052,  # pedunculopontine\n",
    "    128,  # midbrain reticular nucleus\n",
    "    214,  # red nucleus\n",
    "    1065,  # hindbrain\n",
    "    867,  # parabrachial nucleus\n",
    "    701,  # vestibular nuclei\n",
    "    972,  # prelimbic\n",
    "    44,  # infralimbic\n",
    "]  # allen atlas region IDs to be shown\n",
    "# see: https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3\n",
    "\n",
    "composite_regions = {\n",
    "    \"Amygdalar Nuclei\": [131, 295, 319, 780],\n",
    "    \"Substantia Nigra\": [615, 374, 374],\n",
    "    \"Superior Colliculus\": [294, 302],\n",
    "}  # Custom composite allen regions where key is region name and value is list of allen regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.region_barchart(\n",
    "    regions=regions, composite_regions=composite_regions, normalize_region=872\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distributions with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "brain_ids = []\n",
    "genotypes = []\n",
    "\n",
    "for i, brain in enumerate(brains):\n",
    "    print(brain)\n",
    "    region_order = list(df.loc[df[\"Brain ID\"] == brain][\"Region\"])\n",
    "\n",
    "    if i == 0:\n",
    "        standard_region_order = region_order\n",
    "    elif standard_region_order != region_order:\n",
    "        raise ValueError(f\"Different region order for brain {brain}\")\n",
    "\n",
    "    distrib = list(df.loc[df[\"Brain ID\"] == brain][\"Percent Total Axon Volume (%)\"])\n",
    "    X.append(distrib)\n",
    "\n",
    "    brain_ids.append(brain)\n",
    "    genotypes.append(brains[brain])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2 = pca.fit_transform(X)\n",
    "\n",
    "df_pca = {\n",
    "    \"PC 1\": X_2[:, 0],\n",
    "    \"PC 2\": X_2[:, 1],\n",
    "    \"Genotype\": genotypes,\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df_pca = pd.DataFrame(data=df_pca)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "sns.scatterplot(data=df_pca, x=\"PC 1\", y=\"PC 2\", hue=\"Genotype\", ax=ax)\n",
    "\n",
    "\n",
    "for i in range(df_pca.shape[0]):\n",
    "    plt.text(\n",
    "        x=df_pca[\"PC 1\"][i] + 0.03,\n",
    "        y=df_pca[\"PC 2\"][i] + 0.03,\n",
    "        s=df_pca[\"Brain ID\"][i],\n",
    "        fontdict=dict(color=\"black\", size=20),\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Projection Distribution PCA with Explained Variance: {pca.explained_variance_ratio_}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Compare to Allen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen_regions = [\n",
    "    315,\n",
    "    698,\n",
    "    1089,\n",
    "    703,\n",
    "    477,\n",
    "    803,\n",
    "    549,\n",
    "    1097,\n",
    "    313,\n",
    "    771,\n",
    "    354,\n",
    "    512,\n",
    "]  # allen atlas region IDs to be shown https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "subregions_list = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    children = list(G.successors(region))\n",
    "    for child in children:\n",
    "        if child not in subregions_list:\n",
    "            subregions_list.append(child)\n",
    "\n",
    "        for brain in quantification_dicts.keys():\n",
    "            if (\n",
    "                G.nodes[child][brain + \" total\"] == 0\n",
    "                and G.nodes[child][brain + \" axon\"] == 0\n",
    "            ):\n",
    "                axon_denss.append(0)\n",
    "            elif G.nodes[child][brain + \" total\"] == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                axon_denss.append(\n",
    "                    G.nodes[child][brain + \" axon\"] / G.nodes[child][brain + \" total\"]\n",
    "                )\n",
    "\n",
    "            if brain in [\"B\", \"R\"]:\n",
    "                gene.append(brain)\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "\n",
    "    region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse(brainlit_path / \"brainlit\" / \"lsm_analysis\" / \"data\" / \"sert_exp.xml\")\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "        if region in subregions_list and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(f\"id: {region} hemi: {hemi}, density: {density}, name: {name}\")\n",
    "            subregion_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "\n",
    "\n",
    "d = {\"Axon Density\": axon_denss, \"Gene\": gene, \"Subregion\": subregion_name}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(20, 10))\n",
    "fig.suptitle(\"Detected Output Axons\")\n",
    "\n",
    "sns.barplot(x=\"Axon Density\", y=\"Subregion\", hue=\"Gene\", data=df)\n",
    "axes.set_title(\"Density\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "axon_vols = []\n",
    "gene = []\n",
    "region_name = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    for brain in quantification_dicts.keys():\n",
    "        if (\n",
    "            G.nodes[region][brain + \" total\"] == 0\n",
    "            and G.nodes[region][brain + \" axon\"] == 0\n",
    "        ):\n",
    "            axon_denss.append(0)\n",
    "        elif G.nodes[region][brain + \" total\"] == 0:\n",
    "            raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "        else:\n",
    "            axon_denss.append(\n",
    "                G.nodes[region][brain + \" axon\"] / G.nodes[region][brain + \" total\"]\n",
    "            )\n",
    "            axon_vols.append(\n",
    "                G.nodes[region][brain + \" axon\"]\n",
    "                * np.product([1.82, 1.82, 2])\n",
    "                * 10 ** (-9)\n",
    "            )\n",
    "\n",
    "        if brain in [\"B\", \"R\"]:\n",
    "            gene.append(\"Sample \" + brain)\n",
    "\n",
    "        region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse(brainlit_path / \"brainlit\" / \"lsm_analysis\" / \"data\" / \"sert_exp.xml\")\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "            elif item.tag == \"projection-volume\":\n",
    "                volume = float(item.text)\n",
    "        if region in allen_regions and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(\n",
    "                f\"id: {region} hemi: {hemi}, density: {density}, volume: {volume}, name: {name}\"\n",
    "            )\n",
    "            region_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "            axon_vols.append(volume)\n",
    "\n",
    "\n",
    "d = {\n",
    "    \"Axon Density\": axon_denss,\n",
    "    \"Axon Volume ($mm^3$)\": axon_vols,\n",
    "    \"Gene\": gene,\n",
    "    \"Region\": region_name,\n",
    "}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle(\"Comparing Axon Volumes to Allen Experiment\")\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "sns.barplot(\n",
    "    ax=axes[0],\n",
    "    x=\"Axon Density\",\n",
    "    y=\"Region\",\n",
    "    hue=\"Gene\",\n",
    "    order=list(\n",
    "        df[df[\"Gene\"] == \"Allen\"]\n",
    "        .sort_values(\"Axon Density\", ascending=False)\n",
    "        .loc[:, \"Region\"]\n",
    "    ),\n",
    "    data=df,\n",
    ")\n",
    "# axes[0].set_title(\"Density\")\n",
    "\n",
    "sns.barplot(\n",
    "    ax=axes[1],\n",
    "    x=\"Axon Volume ($mm^3$)\",\n",
    "    y=\"Region\",\n",
    "    hue=\"Gene\",\n",
    "    order=list(\n",
    "        df[df[\"Gene\"] == \"Allen\"]\n",
    "        .sort_values(\"Axon Density\", ascending=False)\n",
    "        .loc[:, \"Region\"]\n",
    "    ),\n",
    "    data=df,\n",
    ")\n",
    "# axes[1].set_title(\"Axon Volume\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.BrainLine.util import find_sample_names\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/\"\n",
    "\n",
    "brains = [\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"887\",\n",
    "    \"8589\",\n",
    "    \"8590\",\n",
    "    \"8590_v2\",\n",
    "    \"8604\",\n",
    "    \"8612\",\n",
    "    \"8613\",\n",
    "    \"8649\",\n",
    "    \"8650\",\n",
    "    \"8786\",\n",
    "    \"8788\",\n",
    "    \"8790\",\n",
    "    \"11537\",\n",
    "]\n",
    "\n",
    "for brain in brains:\n",
    "    brain_dir = base_dir + \"brain\" + brain\n",
    "    files = find_sample_names(brain_dir, dset=\"\", add_dir=True)\n",
    "    for file in files:\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            key = list(f.keys())[0]\n",
    "            print(key)\n",
    "        #     image = np.array(f.get(key))\n",
    "        # image = image[[1, 0, 2],:,:,:]\n",
    "        # with h5py.File(file, \"w\") as f:\n",
    "        #     dset = f.create_dataset(key, data=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train_0-image_2channel_Labels.h5\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    key = list(f.keys())[0]\n",
    "    image = np.array(f.get(key))\n",
    "    print(image.shape)\n",
    "    print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.load(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train_0-image_2channel_Labels.npy\"\n",
    ")\n",
    "print(image.shape)\n",
    "print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = (\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain4/train/\"\n",
    ")\n",
    "for file in os.listdir(dir):\n",
    "    if \"Labels\" in file:\n",
    "        file = dir + file\n",
    "        print(file)\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            key = list(f.keys())[0]\n",
    "            image = np.array(f.get(key))\n",
    "        print(np.sum(image))\n",
    "        # npy_file = file.split(\".\")[0] + \".npy\"\n",
    "        # np.save(npy_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train/train_31-image_2channel_Labels.h5\"\n",
    "with h5py.File(file, \"r\") as f:\n",
    "    key = list(f.keys())[0]\n",
    "    image = np.array(f.get(key))\n",
    "npy_file = file.split(\".\")[0] + \".npy\"\n",
    "np.save(npy_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = CloudVolume(\n",
    "    \"precomputed://https://dlab-colm.neurodata.io/2022_10_24/8788/axon_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_sub = vol[int(256*11/8):int(256*12/8),int(256*16/8):int(256*17/8), int(256*6:256*7/8)]\n",
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://s3://smartspim-precomputed-volumes/2022_03_10/8531/atlas_to_target\"\n",
    ")\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"segmentation\",\n",
    "    data_type=\"uint64\",  # Channel images might be 'uint8'\n",
    "    encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=atlas_vol.voxel_offset,\n",
    "    chunk_size=[32, 32, 32],  # units are voxels\n",
    "    volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol_mask = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/atlas_to_target\",\n",
    "    info=info,\n",
    "    compress=False,\n",
    ")\n",
    "vol_mask.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_mask[\n",
    "    int(256 * 11 / 8) : int(256 * 12 / 8),\n",
    "    int(256 * 16 / 8) : int(256 * 17 / 8),\n",
    "    256 * 6 : 256 * 7,\n",
    "] = atlas_vol[\n",
    "    int(256 * 11 / 8) : int(256 * 12 / 8),\n",
    "    int(256 * 16 / 8) : int(256 * 17 / 8),\n",
    "    256 * 6 : 256 * 7,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvol = np.load(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/axon_mask_transformed/subvol.npy\"\n",
    ")\n",
    "vol = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/axon_mask_transformed\",\n",
    "    compress=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[30 * 32 : 32 * 32, 7 * 32 : 9 * 32, 16 * 32 : 18 * 32] = subvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
