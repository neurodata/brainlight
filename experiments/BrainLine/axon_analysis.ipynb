{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Axon Segmentation Analysis of Whole-Brain Light-Sheet Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.preprocessing import removeSmallCCs\n",
    "from brainlit.BrainLine.util import json_to_points, download_subvolumes\n",
    "from brainlit.BrainLine.parse_ara import *\n",
    "import xml.etree.ElementTree as ET\n",
    "from brainlit.BrainLine.imports import *\n",
    "from brainlit.BrainLine.apply_ilastik import (\n",
    "    ApplyIlastik,\n",
    "    ApplyIlastik_LargeImage,\n",
    "    plot_results,\n",
    "    examine_threshold,\n",
    ")\n",
    "from brainlit.BrainLine.analyze_results import (\n",
    "    AxonDistribution,\n",
    "    collect_regional_segmentation,\n",
    ")\n",
    "from scipy.special import rel_entr\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "from statannotations.Annotator import Annotator\n",
    "from statannotations.stats.StatTest import StatTest\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "%gui qt5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Before Using this notebook:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install brainlit, and other packages that this notebook uses\n",
    "### 1b. Write images to s3 using CloudReg\n",
    "    - e.g. python -m cloudreg.scripts.create_precomputed_volumes --s3_input_paths /mnt/NAS/SmartSPIM_Data/2022_03_02/20220302_14_40_04_8529_destriped_DONE/Ex_561_Em_600_stitched --s3_output_paths  s3://smartspim-precomputed-volumes/2022_03_02/8529/Ch_561_v2  --voxel_size 1.83 1.83 2 --num_procs 24 --resample_iso False\n",
    "### 1c. Make point annotations in neuroglancer to identify subvolumes for validation (and possible training)\n",
    "    - instructions: https://neurodata.io/help/neuroglancer-pt-annotations/\n",
    "        ,\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"val\",\n",
    "    \"points\": []\n",
    "    }\n",
    "### 1d. Update axon_data.py file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to brainlit: /home/user/brainlit\n"
     ]
    }
   ],
   "source": [
    "brainlit_path = Path(os.path.abspath(\"\"))\n",
    "brainlit_path = brainlit_path.parents[1]\n",
    "print(f\"Path to brainlit: {brainlit_path}\")\n",
    "data_file = brainlit_path / \"experiments\" / \"BrainLine\" / \"data\" / \"axon_data.json\"\n",
    "\n",
    "with open(data_file) as f:\n",
    "    data = json.load(f)\n",
    "brain2paths = data[\"brain2paths\"]\n",
    "\n",
    "\n",
    "brain = \"MS14\"  # brain ID\n",
    "axon_data_dir = \"/home/user/brainlit/experiments/BrainLine/data/validation-and-models/axon/\"  # path to directory where training/validation data should be stored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download benchmark data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibody_layer = \"Ch_647\"\n",
    "background_layer = \"Ch_561\"\n",
    "endogenous_layer = \"Ch_488\"\n",
    "\n",
    "dataset_to_save = \"val\"  # train or val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvol_base = brain2paths[brain][\"base\"]\n",
    "layer_names = [antibody_layer, background_layer, endogenous_layer]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_subvolumes(\n",
    "    axon_data_dir,\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    dataset_to_save=dataset_to_save,\n",
    "    data_file=data_file,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View downloaded data (optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain8649/val_775_4829_2459.h5\"  # path to file for viewing\n",
    "scale = [1.8, 1.8, 2]  # voxel size in microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, \"r\") as f:\n",
    "    pred = f.get(\"image_2channel\")\n",
    "    image_bg = pred[0, :, :, :]\n",
    "    image_fg = pred[1, :, :, :]\n",
    "    image_endo = pred[2, :, :, :]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg, scale=scale)\n",
    "viewer.add_image(image_bg, scale=scale)\n",
    "viewer.add_image(image_endo, scale=scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Ilastik to validation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to do two things:\n",
    "- add annotations to the downloaded data (for me, partial labels on 3 of the z-slices using ilastik)\n",
    "- apply axon segmentation model to the downloaded data. Results should be located in the same directory at the subvolumes, with the addition of \"_Probabilities\" appended to the file names: you can do this programmatically (below), or you can use the ilastik GUI (which is sometimes faster)\n",
    "\n",
    "Note: make sure foreground/background labels are matched between the model and your annotations (for me, blue/1 =axon yellow/0=bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = f\"/home/user/brainlit/experiments/BrainLine/data/validation-and-models/axon/axon_segmentation.ilp\"  # path to ilastik model to be used\n",
    "ilastik_path = (\n",
    "    \"/home/user/Documents/ilastik-1.4.0-Linux/run_ilastik.sh\"\n",
    ")\n",
    "brains = [brain]\n",
    "# brains = [\"8650\", \"8613\", \"8589\", \"8788\", \"8786\", \"8790\", \"MS32\", \"MS29\", \"MS11\", \"MS15\", \"11537\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyilastik = ApplyIlastik(\n",
    "    ilastik_path=ilastik_path,\n",
    "    project_path=project_path,\n",
    "    brains_path=axon_data_dir,\n",
    "    brains=brains,\n",
    ")\n",
    "applyilastik.process_subvols(ncpu=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    data_dir=axon_data_dir, brain_ids=[brain], object_type=\"axon\", positive_channel=1\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If results above are not adequate improve the model and try again\n",
    "\n",
    "In my case, I identify more subvolumes from the sample at hand using the same process as for validation data, and add it as training data to the model and retrain.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_threshold(\n",
    "    data_dir=axon_data_dir,\n",
    "    brain_id=brain,\n",
    "    threshold=0.36,\n",
    "    object_type=\"axon\",\n",
    "    positive_channel=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper figure for all validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_ids = [\n",
    "    \"8650\",\n",
    "    \"8613\",\n",
    "    \"8589\",\n",
    "    \"8788\",\n",
    "    \"8786\",\n",
    "    \"8790\",\n",
    "    \"MS32\",\n",
    "    \"MS29\",\n",
    "    \"MS11\",\n",
    "    \"MS15\",\n",
    "    \"11537\",\n",
    "]\n",
    "\n",
    "plot_results(\n",
    "    data_dir=axon_data_dir,\n",
    "    brain_ids=brain_ids,\n",
    "    object_type=\"axon\",\n",
    "    positive_channel=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make annotation layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axon segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"base\" in brain2paths[brain].keys():\n",
    "    dir = brain2paths[brain][\"base\"] + \"axon_mask\"\n",
    "else:\n",
    "    dir = brain2paths[brain][\"mask\"]\n",
    "\n",
    "try:\n",
    "    CloudVolume(dir)\n",
    "except:\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"segmentation\",\n",
    "        data_type=\"uint64\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=vol_bg.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=vol_bg.voxel_offset,  # x,y,z offset in voxels from the origin\n",
    "        # mesh            = 'mesh',\n",
    "        # Pick a convenient size for your underlying chunk representation\n",
    "        # Powers of two are recommended, doesn't need to cover image exactly\n",
    "        chunk_size=[128, 128, 2],  # units are voxels\n",
    "        volume_size=vol_bg.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(dir, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\"\n",
    ")\n",
    "for layer in [\n",
    "    antibody_layer,\n",
    "    background_layer,\n",
    "    \"axon_mask\",\n",
    "]:  # axon_mask is transformed into an image because nearest interpolation doesnt work well after downsampling\n",
    "    layer_path = brain2paths[brain][\"base\"] + layer + \"_transformed\"\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"image\",\n",
    "        data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=atlas_vol.voxel_offset,\n",
    "        chunk_size=[32, 32, 32],  # units are voxels\n",
    "        volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(layer_path, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply ilastik to whole image:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*\n",
    "\n",
    "You can use the notebook code below or the script using `axon_segment_image.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"test\"\n",
    "antibody_layer = \"antibody\"\n",
    "background_layer = \"background\"\n",
    "endogenous_layer = \"endogenous\"\n",
    "\n",
    "threshold = 0.12  # threshold to use for ilastik\n",
    "data_dir = (\n",
    "    str(Path.cwd().parents[0]) + \"/brain_temp/\"\n",
    ")  # data_dir = \"/data/tathey1/matt_wright/brain_temp/\"  # directory to store temporary subvolumes for segmentation\n",
    "\n",
    "# Ilastik will run in \"headless mode\", and the following paths are needed to do so:\n",
    "ilastik_path = \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"  # \"/data/tathey1/matt_wright/ilastik/ilastik-1.4.0rc5-Linux/run_ilastik.sh\"  # path to ilastik executable\n",
    "ilastik_project = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/axon_segmentation.ilp\"  # \"/data/tathey1/matt_wright/ilastik/model1/axon_segmentation.ilp\"  # path to ilastik project\n",
    "\n",
    "\n",
    "max_coords = [\n",
    "    3072,\n",
    "    4352,\n",
    "    1792,\n",
    "]  # max coords or -1 if you want to process everything along that dimension\n",
    "ncpu = 1  # 16  # number of cores to use for detection\n",
    "chunk_size = [256, 256, 256]  # [256, 256, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [antibody_layer, background_layer, endogenous_layer]\n",
    "alli = ApplyIlastik_LargeImage(\n",
    "    ilastik_path=ilastik_path,\n",
    "    ilastik_project=ilastik_project,\n",
    "    ncpu=ncpu,\n",
    "    object_type=\"axon\",\n",
    ")\n",
    "alli.apply_ilastik_parallel(\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    threshold=threshold,\n",
    "    data_dir=data_dir,\n",
    "    chunk_size=chunk_size,\n",
    "    max_coords=max_coords,\n",
    ")\n",
    "alli.collect_axon_results(brain_id=brain, ng_layer_name=\"127.0.0.1:9010\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Register volume and transform data to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. You need to find an initial affine alignment using cloudreg.scripts.registration.get_affine_matrix. For example: \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A link to the ARA parcellation is:\n",
    "\n",
    "`precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017`\n",
    "\n",
    "And some python commands to help with affine alignment is:\n",
    "\n",
    "```\n",
    "from cloudreg.scripts.registration import get_affine_matrix\n",
    "get_affine_matrix([1,1,1], [15,0,0], \"PIR\", \"RAI\", 1.15, \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Run registration using cloudreg.scripts.registration. For example:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.registration -input_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_10/MS12/Ch_561 --output_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_10/MS12/atlas_to_target --atlas_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_50um/average_50um --parcellation_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --atlas_orientation PIR -orientation RPI --rotation 0 0 0 --translation 0 0 0 --fixed_scale 1.05 -log_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_10/MS12/atlas_to_target --missing_data_correction True --grid_correction False --bias_correction True --regularization 5000.0 --iterations 3000 --registration_resolution 100\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Transform segmentation to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cornell Analysis computer:\n",
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_05_23/MS9/axon_mask --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_05_23/MS9/axon_mask_transformed --affine_path /mnt/NAS/Neuroglancer\\ Data/2023_04_07/MS29_Ch_561_registration/downloop_1_A.mat  --velocity_path /mnt/NAS/Neuroglancer\\ Data/2023_04_07/MS29_Ch_561_registration/downloop_1_v.mat\n",
    "```\n",
    "\n",
    "CIS:\n",
    "``````\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_10_26/11537/axon_mask --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2022_10_26/11537/axon_mask_transformed --affine_path /cis/home/tathey/11537_Ch_561_registration/downloop_1_A.mat  --velocity_path /cis/home/tathey/11537_Ch_561_registration/downloop_1_v.mat\n",
    "``````\n",
    "\n",
    "This will write a layer to s3 with the transformed axon mask. The s3 path to this layer should be added to `axon_data.py` under the `axon_mask_transformed` key. Then the code below, or `axon_brainrender.py`, can be used to visualize the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Combine registration and segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_regional_segmentation(\n",
    "    brain_id=brain,\n",
    "    outdir=axon_data_dir,\n",
    "    max_coords=[\n",
    "        6029,\n",
    "        -1,\n",
    "        -1,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. View coronal heat maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_ids = [\n",
    "    # \"3\",\n",
    "    # \"4\",\n",
    "    \"8613\",\n",
    "    # \"8604\",\n",
    "    \"8650\",\n",
    "    \"8589\",\n",
    "    # \"8590\",\n",
    "    # \"8649\",\n",
    "    \"8788\",\n",
    "    \"8786\",\n",
    "    \"11537\",\n",
    "    \"8790\",\n",
    "    \"MS32\",\n",
    "    \"MS29\",\n",
    "    \"MS11\",\n",
    "    \"MS15\",\n",
    "    \"MS12\",  # registration not found\n",
    "    \"MS33\",\n",
    "    \"MS9\",\n",
    "]  # list of sample IDs to be shown\n",
    "\n",
    "\n",
    "\n",
    "colors = {\n",
    "    \"tph2 gad2\": \"green\",\n",
    "    \"tph2 vglut3\": \"blue\",\n",
    "    \"gad2 vgat\": \"red\",\n",
    "}  # colors for different genotypes\n",
    "fold_on = True\n",
    "ontology_file = (\n",
    "    brainlit_path / \"brainlit\" / \"BrainLine\" / \"data\" / \"ara_structure_ontology.json\"\n",
    ")\n",
    "ontology_fixes = (\n",
    "    brainlit_path / \"brainlit\" / \"BrainLine\" / \"data\" / \"open-nd-ara-fixes.json\"\n",
    ")\n",
    "\n",
    "axon_data_dir = \"/home/user/brainlit/experiments/BrainLine/data/wholebrain-results/axon/\"\n",
    "\n",
    "# For brainrender\n",
    "# brain_ids = [\"8613\"]\n",
    "# colors = {\"tph2 vglut3\": \"blue\"}\n",
    "\n",
    "# brain_ids = [\"8650\"]\n",
    "# colors = {\"tph2 gad2\": \"green\"}\n",
    "\n",
    "# brain_ids = [\"MS15\"]\n",
    "# colors = {\"gad2 vgat\": \"purple\"}\n",
    "\n",
    "\n",
    "ad = AxonDistribution(\n",
    "    brain_ids=brain_ids,\n",
    "    regional_distribution_dir=axon_data_dir,\n",
    "    data_file=data_file,\n",
    "    ontology_file=ontology_file,\n",
    "    fixes_file=ontology_fixes,\n",
    ")\n",
    "\n",
    "custom_regions = [688, 1097, 549, 354, 512, 477, 313]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coronal sections in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:  66%|██████▌   | 24926/37800 [02:27<01:25, 149.83it/s]A"
     ]
    }
   ],
   "source": [
    "ad.napari_coronal_section(z=100, subtype_colors=colors, fold_on=fold_on, custom_regions = custom_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Relabeling slice: 100%|██████████| 4/4 [00:00<00:00, 988.00it/s]\n",
      "Processing labels: 100%|██████████| 13/13 [00:00<00:00, 102.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 180.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 185.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 186.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 188.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 183.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.49it/s]\n",
      "Relabeling slice: 100%|██████████| 21/21 [00:00<00:00, 1342.01it/s]\n",
      "Processing labels: 100%|██████████| 13/13 [00:00<00:00, 97.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 187.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 188.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 183.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 185.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 182.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 188.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 187.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 192.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.85it/s]\n",
      "Relabeling slice: 100%|██████████| 46/46 [00:00<00:00, 1484.66it/s]\n",
      "Processing labels: 100%|██████████| 6/6 [00:00<00:00, 102.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 172.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 188.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 169.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 188.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 171.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 193.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 183.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 192.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 193.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 186.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 183.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 192.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.48it/s]\n",
      "Relabeling slice: 100%|██████████| 67/67 [00:00<00:00, 1474.26it/s]\n",
      "Processing labels: 100%|██████████| 18/18 [00:00<00:00, 98.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 169.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 166.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 166.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 181.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 170.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 189.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 183.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 192.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 175.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 187.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 177.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 186.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 192.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.06it/s]\n",
      "Relabeling slice: 100%|██████████| 104/104 [00:00<00:00, 1514.37it/s]\n",
      "Processing labels: 100%|██████████| 22/22 [00:00<00:00, 98.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 170.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 182.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 165.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 183.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 173.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 194.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 191.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 176.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 176.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 185.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 191.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 183.85it/s]\n",
      "Relabeling slice: 100%|██████████| 135/135 [00:00<00:00, 1504.52it/s]\n",
      "Processing labels: 100%|██████████| 25/25 [00:00<00:00, 96.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 171.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 179.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 165.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 176.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 176.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 186.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 181.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 180.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 178.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.10it/s]\n",
      "Relabeling slice: 100%|██████████| 159/159 [00:00<00:00, 1549.02it/s]\n",
      "Processing labels: 100%|██████████| 56/56 [00:00<00:00, 97.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 174.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 175.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 170.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 177.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 177.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 184.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 183.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 179.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 175.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.28it/s]\n",
      "Relabeling slice: 100%|██████████| 163/163 [00:00<00:00, 1539.10it/s]\n",
      "Processing labels: 100%|██████████| 35/35 [00:00<00:00, 96.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 174.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 177.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 175.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 178.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 176.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 186.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 185.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 183.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 180.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 188.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.59it/s]\n",
      "Relabeling slice: 100%|██████████| 124/124 [00:00<00:00, 1550.10it/s]\n",
      "Processing labels: 100%|██████████| 19/19 [00:00<00:00, 98.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 176.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 177.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 179.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 178.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 177.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 188.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 183.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 182.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 179.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.53it/s]\n",
      "Relabeling slice: 100%|██████████| 80/80 [00:00<00:00, 1546.57it/s]\n",
      "Processing labels: 100%|██████████| 45/45 [00:00<00:00, 99.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 174.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 179.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 174.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 176.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:10<00:00, 175.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 183.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 189.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 184.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 180.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 184.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 192.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 191.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1800/1800 [00:09<00:00, 190.55it/s]\n",
      "Relabeling slice: 100%|██████████| 56/56 [00:00<00:00, 1509.27it/s]\n",
      "Processing labels: 100%|██████████| 35/35 [00:00<00:00, 98.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 171.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 182.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 170.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 181.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 176.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 193.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 183.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 191.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 181.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 187.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 188.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 194.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 185.25it/s]\n",
      "Relabeling slice: 100%|██████████| 49/49 [00:00<00:00, 1521.97it/s]\n",
      "Processing labels: 100%|██████████| 31/31 [00:00<00:00, 99.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 175.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 174.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:05<00:00, 179.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 192.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 192.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 183.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 191.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 189.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 193.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 900/900 [00:04<00:00, 184.90it/s]\n",
      "100%|██████████| 12/12 [27:02<00:00, 135.21s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 17:31:04.459: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:31:18.922: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:31:33.145: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:31:47.615: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:32:03.530: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:32:17.742: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:32:32.294: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:32:47.741: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:33:02.775: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:33:17.784: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:33:31.184: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 17:33:44.621: GtkDialog mapped without a transient parent. This is discouraged.\n"
     ]
    }
   ],
   "source": [
    "dir = \"/home/user/misc_tommy/figures/axon_coronal/\"\n",
    "z_size = 1300\n",
    "\n",
    "for z in tqdm(np.arange(100, z_size, 100)):\n",
    "    fname = dir + f\"axon_{z}.tif\"\n",
    "    v = ad.napari_coronal_section(z=z, subtype_colors=colors, fold_on=fold_on, custom_regions=custom_regions)\n",
    "    #im = v.screenshot(canvas_only=False)\n",
    "    #io.imsave(fname, im)\n",
    "    #break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brainrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading transformed_mask from brain: MS15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 37800/37800 [03:27<00:00, 182.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 800, 1320)\n",
      "(1140, 800, 1320)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Saving new screenshot at brainrender_screenshot_20241211_154317.png\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Saving new screenshot at brainrender_screenshot_20241211_154317.png\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ad.brainrender_axons(subtype_colors=colors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Display bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_coarse = [688, 1097, 549, 354, 512, 477, 1089, 313]  # midbrain\n",
    "\n",
    "\n",
    "regions_fine = [\n",
    "    95,  # agranular insular area\n",
    "    714,  # orbital area\n",
    "    972,  # prelimbic\n",
    "    44,  # infralimbic\n",
    "    186,  # lateral habenula\n",
    "    149,  # paraventricular nucleus of thalamus (part of polymodal assoc cortex)\n",
    "    864,  # sensorimotor thalamus\n",
    "    519,  # cerebellar nuclei\n",
    "    528,  # cerebellar cortex\n",
    "    290,  # hypothalamic lateral zone\n",
    "    141,  # periventricular region (preoptic nuclei)\n",
    "    946,  # posterior hypothalamic nucleus\n",
    "    797,  # zona incerta\n",
    "    331,  # mammillary body\n",
    "    364,  # parasubthalamic nucleus\n",
    "    38,  # paraventricular hypothalamic nucleus\n",
    "    223,  # arcuate hypothalamic nucleus\n",
    "    80,  # anterior hypothal nucleus\n",
    "    830,  # dorsomedial hypothal nuc.\n",
    "    693,  # ventromedial hypothal nuc.\n",
    "    470,  # subthalamic n\n",
    "    286,  # suprachiasmatic n\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    536,  # central amygdala\n",
    "    323,  # midbrain - motor\n",
    "    339,  # midbrain - sensory\n",
    "    348,  # midbrain - behavioral state\n",
    "]\n",
    "\n",
    "regions = [\n",
    "    500,  # somatomotor\n",
    "    453,  # somatosensory\n",
    "    972,  # prelimbic\n",
    "    44,  # infralimbic\n",
    "    477,\n",
    "    1089,\n",
    "    1097,  # hypothalamus\n",
    "    549,  # thalamus\n",
    "    186,  # lateral habenula\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    313,  # midbrain\n",
    "    512,  # cerebellum\n",
    "    771,  # pons\n",
    "    354,  # medulla\n",
    "]  # allen atlas region IDs to be shown\n",
    "# see: https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3\n",
    "\n",
    "composite_regions = {\n",
    "    \"Amygdala\": [131, 295, 319, 536, 780],\n",
    "    # \"Substantia Nigra\": [615, 374, 374],\n",
    "    # \"Superior Colliculus\": [294, 302],\n",
    "}  # Custom composite allen regions where key is region name and value is list of allen regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are regions mutually exclusive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_coarse_part\n",
    "for r_src in regions:\n",
    "    print(sd.region_graph.nodes[r_src][\"name\"])\n",
    "    for r_targ in regions:\n",
    "        if r_targ == r_src:\n",
    "            continue\n",
    "        elif nx.has_path(sd.region_graph, r_src, r_targ):\n",
    "            print(f\"{r_src} is parent of {r_targ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "DG = ad.region_graph\n",
    "\n",
    "for region in regions:\n",
    "    for subtype in colors.keys():\n",
    "        data = []\n",
    "        for brain in brain_ids:\n",
    "            if brain2paths[brain][\"subtype\"] == subtype:\n",
    "                total = DG.nodes[997][f\"{brain} axon\"]\n",
    "                data.append(np.log(DG.nodes[region][f\"{brain} axon\"] / total))\n",
    "                #data.append(DG.nodes[region][f\"{brain} axon\"] / total)\n",
    "\n",
    "        if len(data) > 2:\n",
    "            _, p = shapiro(data)\n",
    "            if p < 0.05:\n",
    "                plt.hist(data)\n",
    "                plt.title(f\"{subtype} - {DG.nodes[region]['name']}: p={p}\")\n",
    "                plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brain_id = []\n",
    "data_region = []\n",
    "data_subtype = []\n",
    "data_log_vol = []\n",
    "\n",
    "\n",
    "\n",
    "for brain in brain_ids:\n",
    "    for region in regions:\n",
    "        subtype = brain2paths[brain][\"subtype\"]\n",
    "        total = DG.nodes[997][f\"{brain} axon\"]\n",
    "        log_frac = np.log(DG.nodes[region][f\"{brain} axon\"] / total)\n",
    "\n",
    "        data_brain_id.append(brain)\n",
    "        data_region.append(region)\n",
    "        data_subtype.append(subtype)\n",
    "        data_log_vol.append(log_frac)\n",
    "\n",
    "data = {\"Brain\": data_brain_id, \"Region\": data_region, \"Subtype\": data_subtype, \"LAVF\": data_log_vol}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "model = ols('LAVF ~ C(Region) + C(Subtype) + C(Region):C(Subtype)', data=df).fit()\n",
    "sm.stats.anova_lm(model, typ=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_ttest_ind(group_data1, group_data2, verbose=1, **stats_params):\n",
    "    group_data1_log = np.log(group_data1)\n",
    "    group_data2_log = np.log(group_data2)\n",
    "\n",
    "    return ttest_ind(group_data1_log, group_data2_log, **stats_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = StatTest(\n",
    "    _log_ttest_ind, test_long_name=\"Log t-test_ind\", test_short_name=\"log-t\"\n",
    ")\n",
    "#test = \"Mann-Whitney\"\n",
    "#test = \"t-test_ind\"\n",
    "\n",
    "region_names = []\n",
    "pcts = []\n",
    "total_vols = []\n",
    "reg_vols = []\n",
    "ids = []\n",
    "subtypes = []\n",
    "subtype_counts = {}\n",
    "\n",
    "for brain_id in ad.brain_ids:\n",
    "    subtype = ad.brain2paths[brain_id][\"subtype\"]\n",
    "    total_vol = ad.region_graph.nodes[997][f\"{brain_id} axon\"]\n",
    "\n",
    "    if subtype in subtype_counts.keys():\n",
    "        subtype_counts[subtype] = subtype_counts[subtype] + 1\n",
    "    else:\n",
    "        subtype_counts[subtype] = 1\n",
    "\n",
    "    for region in regions:\n",
    "        reg_vol = ad.region_graph.nodes[region][f\"{brain_id} axon\"]\n",
    "        pct = (\n",
    "            reg_vol / total_vol\n",
    "            * 100\n",
    "        )\n",
    "\n",
    "        reg_vols.append(reg_vol)\n",
    "        total_vols.append(total_vol)\n",
    "        pcts.append(pct)\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(ad.region_graph.nodes[region][\"name\"])\n",
    "    for composite_region in composite_regions.keys():\n",
    "        composite_region_regions = composite_regions[composite_region]\n",
    "        reg_vol = 0\n",
    "        for region in composite_region_regions:\n",
    "            reg_vol += ad.region_graph.nodes[region][f\"{brain_id} axon\"]\n",
    "\n",
    "        reg_vols.append(reg_vol)\n",
    "        total_vols.append(total_vol)\n",
    "        pcts.append(reg_vol / total_vol * 100)\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(composite_region)\n",
    "\n",
    "\n",
    "# append n to subtypes\n",
    "color_palette = {}\n",
    "for i, subtype in enumerate(subtypes):\n",
    "    new_key = subtype + f\" (n={subtype_counts[subtype]})\"\n",
    "    subtypes[i] = new_key\n",
    "    color_palette[new_key] = colors[subtype] \n",
    "\n",
    "data = {\n",
    "    \"Region\": region_names,\n",
    "    \"Brain ID\": ids,\n",
    "    \"Subtype\": subtypes,\n",
    "    \"Axon Volume (pixels)\": reg_vols,\n",
    "    \"Total Axon Volume (pixels)\": total_vols,\n",
    "    \"Percent of Total Axon Volume (%)\": pcts,\n",
    "}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "diffs = []\n",
    "for region_name in df[\"Region\"].unique():\n",
    "    diff = (\n",
    "        df[(df[\"Region\"] == region_name) & (df[\"Subtype\"] == \"tph2 gad2\")][\n",
    "            \"Percent of Total Axon Volume (%)\"\n",
    "        ].mean()\n",
    "        - df[(df[\"Region\"] == region_name) & (df[\"Subtype\"] == \"tph2 vglut3\")][\n",
    "            \"Percent of Total Axon Volume (%)\"\n",
    "        ].mean()\n",
    "    )\n",
    "    diffs.append((region_name, diff))\n",
    "\n",
    "\n",
    "def second(e):\n",
    "    return e[1]\n",
    "\n",
    "\n",
    "diffs.sort(key=second, reverse=False)\n",
    "order = [e[0] for e in diffs]\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7), dpi=300)\n",
    "fig_args = {\n",
    "    \"y\": \"Percent of Total Axon Volume (%)\",\n",
    "    \"x\": \"Region\",\n",
    "    \"hue\": \"Subtype\",\n",
    "    \"data\": df,\n",
    "    \"dodge\": True,\n",
    "}\n",
    "bplot = sns.stripplot(ax=ax, color='black', order=order, **fig_args)\n",
    "# fig_args[\"boxprops\"] = {\"facecolor\": \"none\"}\n",
    "# bplot = sns.boxplot(ax=ax, order=order, **fig_args)\n",
    "bplot = sns.barplot(ax=ax, palette=color_palette, **fig_args)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles[3:], labels=labels[3:])\n",
    "\n",
    "bplot.set_yscale(\"log\")\n",
    "tick_labels = bplot.get_xticklabels()\n",
    "tick_labels[9].set_text(\"BNST\")\n",
    "bplot.set_xticklabels(labels=tick_labels, rotation=30)\n",
    "\n",
    "# annotator\n",
    "fig_args[\"x\"] = \"Region\"\n",
    "fig_args[\"y\"] = \"Percent of Total Axon Volume (%)\"\n",
    "pairs = []\n",
    "unq_subtypes = np.unique(subtypes)\n",
    "for region in regions + [\"Amygdala\"]:\n",
    "    if region == \"Amygdala\":\n",
    "        region_name = region\n",
    "    else:\n",
    "        region_name = ad.region_graph.nodes[region][\"name\"]\n",
    "\n",
    "    for i, subtype1 in enumerate(unq_subtypes):\n",
    "        for subtype2 in unq_subtypes[i + 1 :]:\n",
    "            pairs.append(((region_name, subtype1), (region_name, subtype2)))\n",
    "annot = Annotator(ax, pairs, **fig_args)\n",
    "annot.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=\"BH\"\n",
    ")\n",
    "fig_args[\"x\"] = \"Region\"\n",
    "fig_args[\"y\"] = \"Percent of Total Axon Volume (%)\"\n",
    "annot.new_plot(bplot, orient=\"v\", plot=\"boxplot\", **fig_args)\n",
    "annot.apply_and_annotate()\n",
    "\n",
    "# markers = [\"o\", \"v\", \"^\", \"<\", \">\", \"s\", \"p\", \"*\", \"+\", \"x\", \"D\"]\n",
    "# jitters = {\"tph2 vglut3\": -0.26, \"tph2 gad2\": 0, \"gad2 vgat\": 0.26}\n",
    "# id2marker = {id: markers[idx] for idx, id in enumerate(brain_ids)}\n",
    "# for idx, line in df.iterrows():\n",
    "#     st = line[\"Subtype\"].split(\"(\")[0][:-1]\n",
    "\n",
    "#     x = line[\"Percent of Total Axon Volume (%)\"]\n",
    "#     y = order.index(line[\"Region\"]) + jitters[st]\n",
    "#     c = colors[st]\n",
    "#     marker = id2marker[line[\"Brain ID\"]]\n",
    "#     ax.scatter([x], [y], c=c, marker=marker)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('/home/user/misc_tommy/figures/axon_barplot/barplot.svg')\n",
    "\n",
    "\n",
    "#df.to_csv(\"/home/user/misc_tommy/figures/axon_barplot/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = StatTest(\n",
    "    _log_ttest_ind, test_long_name=\"Log t-test_ind\", test_short_name=\"log-t\"\n",
    ")\n",
    "#test = \"Mann-Whitney\"\n",
    "#test = \"t-test_ind\"\n",
    "\n",
    "region_names = []\n",
    "pcts = []\n",
    "total_vols = []\n",
    "reg_vols = []\n",
    "ids = []\n",
    "subtypes = []\n",
    "subtype_counts = {}\n",
    "\n",
    "for brain_id in ad.brain_ids:\n",
    "    subtype = ad.brain2paths[brain_id][\"subtype\"]\n",
    "    total_vol = ad.region_graph.nodes[997][f\"{brain_id} axon\"]\n",
    "\n",
    "    if subtype in subtype_counts.keys():\n",
    "        subtype_counts[subtype] = subtype_counts[subtype] + 1\n",
    "    else:\n",
    "        subtype_counts[subtype] = 1\n",
    "\n",
    "    for region in regions:\n",
    "        reg_vol = ad.region_graph.nodes[region][f\"{brain_id} axon\"]\n",
    "        pct = (\n",
    "            reg_vol / total_vol\n",
    "            * 100\n",
    "        )\n",
    "\n",
    "        reg_vols.append(reg_vol)\n",
    "        total_vols.append(total_vol)\n",
    "        pcts.append(pct)\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(ad.region_graph.nodes[region][\"name\"])\n",
    "    for composite_region in composite_regions.keys():\n",
    "        composite_region_regions = composite_regions[composite_region]\n",
    "        reg_vol = 0\n",
    "        for region in composite_region_regions:\n",
    "            reg_vol += ad.region_graph.nodes[region][f\"{brain_id} axon\"]\n",
    "\n",
    "        reg_vols.append(reg_vol)\n",
    "        total_vols.append(total_vol)\n",
    "        pcts.append(reg_vol / total_vol * 100)\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(composite_region)\n",
    "\n",
    "\n",
    "# append n to subtypes\n",
    "for i, subtype in enumerate(subtypes):\n",
    "    subtypes[i] = subtype + f\" (n={subtype_counts[subtype]})\"\n",
    "\n",
    "data = {\n",
    "    \"Region\": region_names,\n",
    "    \"Brain ID\": ids,\n",
    "    \"Subtype\": subtypes,\n",
    "    \"Axon Volume (pixels)\": reg_vols,\n",
    "    \"Total Axon Volume (pixels)\": total_vols,\n",
    "    \"Percent of Total Axon Volume (%)\": pcts,\n",
    "}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "diffs = []\n",
    "for region_name in df[\"Region\"].unique():\n",
    "    diff = (\n",
    "        df[(df[\"Region\"] == region_name) & (df[\"Subtype\"] == \"tph2 gad2\")][\n",
    "            \"Percent of Total Axon Volume (%)\"\n",
    "        ].mean()\n",
    "        - df[(df[\"Region\"] == region_name) & (df[\"Subtype\"] == \"tph2 vglut3\")][\n",
    "            \"Percent of Total Axon Volume (%)\"\n",
    "        ].mean()\n",
    "    )\n",
    "    diffs.append((region_name, diff))\n",
    "\n",
    "\n",
    "def second(e):\n",
    "    return e[1]\n",
    "\n",
    "\n",
    "diffs.sort(key=second, reverse=False)\n",
    "order = [e[0] for e in diffs]\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7), dpi=300)\n",
    "fig_args = {\n",
    "    \"y\": \"Percent of Total Axon Volume (%)\",\n",
    "    \"x\": \"Region\",\n",
    "    \"hue\": \"Subtype\",\n",
    "    \"data\": df,\n",
    "    \"dodge\": True,\n",
    "}\n",
    "bplot = sns.stripplot(ax=ax, legend=False, order=order, **fig_args)\n",
    "fig_args[\"boxprops\"] = {\"facecolor\": \"none\"}\n",
    "bplot = sns.boxplot(ax=ax, order=order, **fig_args)\n",
    "bplot.set_yscale(\"log\")\n",
    "tick_labels = bplot.get_xticklabels()\n",
    "tick_labels[9].set_text(\"BNST\")\n",
    "bplot.set_xticklabels(labels=tick_labels, rotation=30)\n",
    "\n",
    "# annotator\n",
    "fig_args[\"x\"] = \"Region\"\n",
    "fig_args[\"y\"] = \"Percent of Total Axon Volume (%)\"\n",
    "pairs = []\n",
    "unq_subtypes = np.unique(subtypes)\n",
    "for region in regions + [\"Amygdala\"]:\n",
    "    if region == \"Amygdala\":\n",
    "        region_name = region\n",
    "    else:\n",
    "        region_name = ad.region_graph.nodes[region][\"name\"]\n",
    "\n",
    "    for i, subtype1 in enumerate(unq_subtypes):\n",
    "        for subtype2 in unq_subtypes[i + 1 :]:\n",
    "            pairs.append(((region_name, subtype1), (region_name, subtype2)))\n",
    "annot = Annotator(ax, pairs, **fig_args)\n",
    "annot.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=\"BH\"\n",
    ")\n",
    "# fig_args[\"y\"] = \"Region\"\n",
    "# fig_args[\"x\"] = \"Percent of Total Axon Volume (%)\"\n",
    "annot.new_plot(bplot, orient=\"v\", plot=\"boxplot\", **fig_args)\n",
    "annot.apply_and_annotate()\n",
    "\n",
    "# markers = [\"o\", \"v\", \"^\", \"<\", \">\", \"s\", \"p\", \"*\", \"+\", \"x\", \"D\"]\n",
    "# jitters = {\"tph2 vglut3\": -0.26, \"tph2 gad2\": 0, \"gad2 vgat\": 0.26}\n",
    "# id2marker = {id: markers[idx] for idx, id in enumerate(brain_ids)}\n",
    "# for idx, line in df.iterrows():\n",
    "#     st = line[\"Subtype\"].split(\"(\")[0][:-1]\n",
    "\n",
    "#     x = line[\"Percent of Total Axon Volume (%)\"]\n",
    "#     y = order.index(line[\"Region\"]) + jitters[st]\n",
    "#     c = colors[st]\n",
    "#     marker = id2marker[line[\"Brain ID\"]]\n",
    "#     ax.scatter([x], [y], c=c, marker=marker)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"/home/user/misc_tommy/figures/axon_barplot/vertical.svg\")\n",
    "plt.show()\n",
    "\n",
    "#df.to_csv(\"/home/user/misc_tommy/figures/axon_barplot/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compositional data analysis\n",
    "- means and variance\n",
    "- PCA\n",
    "- permutation test on distances between centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ilr(vector):\n",
    "    y = np.zeros((len(vector) - 1,))\n",
    "    for im1, _ in enumerate(vector[:-1]):\n",
    "        i = im1 + 1\n",
    "        c = 1 / np.sqrt(i * (i + 1))\n",
    "        l = np.sum(np.log(vector[:i])) - i * np.log(vector[i])\n",
    "        y[im1] = c * l\n",
    "    return y\n",
    "\n",
    "\n",
    "def closure(vector, k=1):\n",
    "    c = [k * v / np.sum(vector) for v in vector]\n",
    "    return c\n",
    "\n",
    "\n",
    "def perturb(x, y):\n",
    "    return [i * j for i, j in zip(x, y)]\n",
    "\n",
    "\n",
    "def power(x, a):\n",
    "    return [i**a for i in x]\n",
    "\n",
    "\n",
    "def ilr_inv(vector):\n",
    "    for im1, y in enumerate(vector):\n",
    "        i = im1 + 1\n",
    "        ei = np.ones((len(vector) + 1))\n",
    "        ei[:i] = np.exp(1 / np.sqrt(i * (i + 1)))\n",
    "        ei[i] = np.exp(-np.sqrt(i / (i + 1)))\n",
    "        ei = closure(ei)\n",
    "        if im1 == 0:\n",
    "            x = closure(power(ei, y))\n",
    "        else:\n",
    "            x = closure(perturb(x, power(ei, y)))\n",
    "    return closure(x)\n",
    "\n",
    "\n",
    "def a_dot(x, y):\n",
    "    D = len(x)\n",
    "    assert len(y) == D\n",
    "    sum = 0\n",
    "    for j in range(D):\n",
    "        for i in range(j):\n",
    "            sum += np.log(x[i] / x[j]) * np.log(y[i] / y[j])\n",
    "    return sum / D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtypes = df[\"Subtype\"].unique()\n",
    "ids = df[\"Brain ID\"].unique()\n",
    "regions = df[\"Region\"].unique()\n",
    "\n",
    "ilrs = {}\n",
    "ids_names = {}\n",
    "\n",
    "for subtype in subtypes:\n",
    "    ys = []\n",
    "    ids_name = []\n",
    "    for id in ids:\n",
    "        if df[df[\"Brain ID\"] == id].iloc[0][\"Subtype\"] == subtype:\n",
    "            x = df[df[\"Brain ID\"] == id][\"Percent of Total Axon Volume (%)\"].tolist()\n",
    "            y = ilr(x)\n",
    "            ys.append(y)\n",
    "            ids_name.append(id)\n",
    "    ilrs[subtype] = ys\n",
    "    ids_names[subtype] = ids_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subtypes = []\n",
    "df_regions = []\n",
    "df_means = []\n",
    "\n",
    "\n",
    "for subtype in ilrs.keys():\n",
    "    mean = ilr_inv(np.mean(ilrs[subtype], axis=0))\n",
    "\n",
    "    for region, mean in zip(regions, mean):\n",
    "        df_regions.append(region)\n",
    "        df_means.append(mean)\n",
    "        df_subtypes.append(subtype)\n",
    "\n",
    "data = {\"Mean\": df_means, \"Subtype\": df_subtypes, \"Region\": df_regions}\n",
    "\n",
    "sns.barplot(x=\"Mean\", y=\"Region\", hue=\"Subtype\", data=pd.DataFrame(data=data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "data_subtypes = []\n",
    "data_ids = []\n",
    "\n",
    "for subtype in ilrs.keys():\n",
    "    X += ilrs[subtype]\n",
    "    data_subtypes += len(ilrs[subtype]) * [subtype]\n",
    "    data_ids += ids_names[subtype]\n",
    "X = np.array(X)\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "X_new = pca.fit_transform(X)\n",
    "vars = pca.explained_variance_ratio_\n",
    "pc1_lbl = f\"PC 1 ({vars[0]:.2f})\"\n",
    "pc2_lbl = f\"PC 2 ({vars[1]:.2f})\"\n",
    "data = {\n",
    "    pc1_lbl: X_new[:, 0],\n",
    "    pc2_lbl: X_new[:, 1],\n",
    "    \"Subtype\": data_subtypes,\n",
    "    \"ID\": data_ids,\n",
    "}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "ax = sns.scatterplot(x=pc1_lbl, y=pc2_lbl, hue=\"Subtype\", data=df)\n",
    "for i, row in df.iterrows():\n",
    "    ax.text(row[pc1_lbl], row[pc2_lbl], row[\"ID\"])\n",
    "\n",
    "plt.savefig(\"/Users/thomasathey/Desktop/test.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many more samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, ttest_ind\n",
    "\n",
    "for region in df.Region.unique():\n",
    "    for i, subtype1 in enumerate(df.Subtype.unique()):\n",
    "        for j, subtype2 in enumerate(df.Subtype.unique()[i + 1 :]):\n",
    "            l1 = df[(df[\"Region\"] == region) & (df[\"Subtype\"] == subtype1)][\n",
    "                \"Percent of Total Axon Volume (%)\"\n",
    "            ].tolist()\n",
    "            l2 = df[(df[\"Region\"] == region) & (df[\"Subtype\"] == subtype2)][\n",
    "                \"Percent of Total Axon Volume (%)\"\n",
    "            ].tolist()\n",
    "\n",
    "            _, p = _log_ttest_ind(l1, l2)\n",
    "            for i in range(10):\n",
    "                if p > 0.0047:\n",
    "                    if len(l1) > len(l2):\n",
    "                        l2.append(np.median(l2))\n",
    "                    else:\n",
    "                        l1.append(np.median(l1))\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                _, p = _log_ttest_ind(l1, l2)\n",
    "            print(f\"{region}: {subtype1} vs {subtype2}: need {i} more added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.region_barchart(\n",
    "    regions=regions_coarse, composite_regions=composite_regions, normalize_region=872\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_graph.nodes[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain2paths = ad.brain2paths\n",
    "region_graph = ad.region_graph\n",
    "\n",
    "data_mat = np.zeros((len(brain_ids), len(regions_coarse)))\n",
    "\n",
    "\n",
    "for bn, brain_id in enumerate(brain_ids):\n",
    "    for rn, region in enumerate(regions_coarse):\n",
    "        data_mat[bn, rn] = (\n",
    "            region_graph.nodes[region][brain_id + \" axon\"]\n",
    "            / region_graph.nodes[997][brain_id + \" axon\"]\n",
    "        )\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2 = pca.fit_transform(data_mat)\n",
    "\n",
    "df_pca = {\n",
    "    \"PC 1\": X_2[:, 0],\n",
    "    \"PC 2\": X_2[:, 1],\n",
    "    \"Genotype\": [brain2paths[brain_id][\"subtype\"] for brain_id in brain_ids],\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df_pca = pd.DataFrame(data=df_pca)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(data=df_pca, x=\"PC 1\", y=\"PC 2\", hue=\"Genotype\", ax=ax)\n",
    "\n",
    "\n",
    "for i in range(df_pca.shape[0]):\n",
    "    sign = 2 * (df_pca[\"PC 2\"][i] > 0) - 1\n",
    "    plt.text(\n",
    "        x=df_pca[\"PC 1\"][i] + 0.01,\n",
    "        y=df_pca[\"PC 2\"][i] + sign * 0.001,\n",
    "        s=df_pca[\"Brain ID\"][i],\n",
    "        fontdict=dict(color=\"black\", size=7),\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Input Distribution PCA with Explained Variance: {pca.explained_variance_ratio_}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    688,  # cerebral cortex\n",
    "    477,  # striatum\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    1097,  # hypothalamus\n",
    "    549,  # thalamus\n",
    "    519,  # cerebellar nuclei\n",
    "    313,  # midbrain\n",
    "    1065,  # hindbrain\n",
    "]  # allen atlas region IDs to be shown\n",
    "\n",
    "regions = [\n",
    "    95,  # agranular insular area\n",
    "    714,  # orbital area\n",
    "    698,  # olfactory areas\n",
    "    1089,  # hippocampal formation\n",
    "    477,  # striatum\n",
    "    803,  # pallidum\n",
    "    703,  # cortical subplate\n",
    "    157,  # periventricular zone\n",
    "    515,  # medial preoptic nucleus\n",
    "    290,  # hypothalamic lateral zone\n",
    "    331,  # mammillary body\n",
    "    549,  # thalamus\n",
    "    519,  # cerebellar nuclei\n",
    "    157,  # inferior colliculus\n",
    "    1052,  # pedunculopontine\n",
    "    128,  # midbrain reticular nucleus\n",
    "    214,  # red nucleus\n",
    "    867,  # parabrachial nucleus\n",
    "    701,  # vestibular nuclei\n",
    "    972,  # prelimbic\n",
    "    44,  # infralimbic\n",
    "]  # allen atlas region IDs to be shown\n",
    "\n",
    "regions_coarse_part = [\n",
    "    688,  # cerebral cortex\n",
    "    477,  # striatum\n",
    "    803,  # pallidum\n",
    "    157,  # periventricular zone\n",
    "    290,  # hypothalamic lateral zone\n",
    "    467,  # hypothalamic medial zone\n",
    "    549,  # thalamus\n",
    "    512,  # cerebellum\n",
    "    157,  # inferior colliculus\n",
    "    1052,  # pedunculopontine\n",
    "    128,  # midbrain reticular nucleus\n",
    "    214,  # red nucleus\n",
    "    867,  # parabrachial nucleus\n",
    "    370,  # medulla motor related\n",
    "]  # allen atlas region IDs to be shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_coarse_part\n",
    "\n",
    "for r_src in regions:\n",
    "    for r_targ in regions:\n",
    "        if r_targ == r_src:\n",
    "            continue\n",
    "        elif nx.has_path(ad.region_graph, r_src, r_targ):\n",
    "            print(f\"{r_src} is parent of {r_targ}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Div permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(brain_id, regions, sd):\n",
    "    bkey = f\"{brain_id} axon\"\n",
    "    total = ad.region_graph.nodes[997][bkey]\n",
    "    dist = []\n",
    "    for region in regions:\n",
    "        dist.append(ad.region_graph.nodes[region][bkey])\n",
    "    dist.append(total - np.sum(dist))\n",
    "\n",
    "    return np.divide(dist, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3)\n",
    "\n",
    "for i, (stype1, stype2) in enumerate(\n",
    "    zip(\n",
    "        [\"tph2 gad2\", \"tph2 gad2\", \"tph2 vglut3\"],\n",
    "        [\"tph2 vglut3\", \"gad2 vgat\", \"gad2 vgat\"],\n",
    "    )\n",
    "):\n",
    "    ax = axs[i]\n",
    "    brain_ids_stypes = []\n",
    "    sz = 0\n",
    "    dists = []\n",
    "\n",
    "    for brain in brain_ids:\n",
    "        if ad.brain2paths[brain][\"subtype\"] == stype1:\n",
    "            dist = get_dist(brain, regions, ad)\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "            sz += 1\n",
    "    av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    dists = []\n",
    "    for brain in brain_ids:\n",
    "        if ad.brain2paths[brain][\"subtype\"] == stype2:\n",
    "            dist = get_dist(brain, regions, ad)\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "    av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    kl_div_true = np.sum(rel_entr(av_dist1, av_dist2)) + np.sum(\n",
    "        rel_entr(av_dist2, av_dist1)\n",
    "    )\n",
    "    if not np.isfinite(kl_div_true) or kl_div_true < 0:\n",
    "        print(av_dist1)\n",
    "        print(av_dist2)\n",
    "    kl_divs = []\n",
    "\n",
    "    for combo in tqdm(combinations(brain_ids_stypes, sz)):\n",
    "        dists = []\n",
    "        for brain in combo:\n",
    "            dist = get_dist(brain, regions, ad)\n",
    "            dists.append(dist)\n",
    "        av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        dists = []\n",
    "        for brain in brain_ids:\n",
    "            if brain not in combo:\n",
    "                if (\n",
    "                    ad.brain2paths[brain][\"subtype\"] == stype1\n",
    "                    or ad.brain2paths[brain][\"subtype\"] == stype2\n",
    "                ):\n",
    "                    dist = get_dist(brain, regions, ad)\n",
    "                    dists.append(dist)\n",
    "        av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        kl_div_c = np.sum(rel_entr(av_dist1, av_dist2)) + np.sum(\n",
    "            rel_entr(av_dist2, av_dist1)\n",
    "        )\n",
    "\n",
    "        if not np.isfinite(kl_div_c) or kl_div_c < 0:\n",
    "            print(av_dist1)\n",
    "            print(av_dist2)\n",
    "        kl_divs.append(kl_div_c)\n",
    "\n",
    "    p = np.sum(kl_divs >= kl_div_true) / len(kl_divs)\n",
    "    ax.hist(kl_divs)\n",
    "    ax.plot([kl_div_true, kl_div_true], [0, 15], c=\"r\", label=f\"pval={p:.2f}\")\n",
    "    ax.set_title(f\"{stype1} vs {stype2} w/{len(kl_divs)} permutations\")\n",
    "    ax.set_xlabel(\"Symmetric KL Divergence\")\n",
    "    ax.set_xlabel(\"Count\")\n",
    "    ax.legend()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(25)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distributions with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "brain_ids = []\n",
    "genotypes = []\n",
    "\n",
    "for i, brain in enumerate(brains):\n",
    "    print(brain)\n",
    "    region_order = list(df.loc[df[\"Brain ID\"] == brain][\"Region\"])\n",
    "\n",
    "    if i == 0:\n",
    "        standard_region_order = region_order\n",
    "    elif standard_region_order != region_order:\n",
    "        raise ValueError(f\"Different region order for brain {brain}\")\n",
    "\n",
    "    distrib = list(df.loc[df[\"Brain ID\"] == brain][\"Percent Total Axon Volume (%)\"])\n",
    "    X.append(distrib)\n",
    "\n",
    "    brain_ids.append(brain)\n",
    "    genotypes.append(brains[brain])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2 = pca.fit_transform(X)\n",
    "\n",
    "df_pca = {\n",
    "    \"PC 1\": X_2[:, 0],\n",
    "    \"PC 2\": X_2[:, 1],\n",
    "    \"Genotype\": genotypes,\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df_pca = pd.DataFrame(data=df_pca)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "sns.scatterplot(data=df_pca, x=\"PC 1\", y=\"PC 2\", hue=\"Genotype\", ax=ax)\n",
    "\n",
    "\n",
    "for i in range(df_pca.shape[0]):\n",
    "    plt.text(\n",
    "        x=df_pca[\"PC 1\"][i] + 0.03,\n",
    "        y=df_pca[\"PC 2\"][i] + 0.03,\n",
    "        s=df_pca[\"Brain ID\"][i],\n",
    "        fontdict=dict(color=\"black\", size=20),\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Projection Distribution PCA with Explained Variance: {pca.explained_variance_ratio_}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Compare to Allen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen_regions = [\n",
    "    315,\n",
    "    698,\n",
    "    1089,\n",
    "    703,\n",
    "    477,\n",
    "    803,\n",
    "    549,\n",
    "    1097,\n",
    "    313,\n",
    "    771,\n",
    "    354,\n",
    "    512,\n",
    "]  # allen atlas region IDs to be shown https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "gene = []\n",
    "subregion_name = []\n",
    "region_name = []\n",
    "subregions_list = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    children = list(G.successors(region))\n",
    "    for child in children:\n",
    "        if child not in subregions_list:\n",
    "            subregions_list.append(child)\n",
    "\n",
    "        for brain in quantification_dicts.keys():\n",
    "            if (\n",
    "                G.nodes[child][brain + \" total\"] == 0\n",
    "                and G.nodes[child][brain + \" axon\"] == 0\n",
    "            ):\n",
    "                axon_denss.append(0)\n",
    "            elif G.nodes[child][brain + \" total\"] == 0:\n",
    "                raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "            else:\n",
    "                axon_denss.append(\n",
    "                    G.nodes[child][brain + \" axon\"] / G.nodes[child][brain + \" total\"]\n",
    "                )\n",
    "\n",
    "            if brain in [\"B\", \"R\"]:\n",
    "                gene.append(brain)\n",
    "            subregion_name.append(G.nodes[child][\"name\"])\n",
    "\n",
    "    region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse(brainlit_path / \"brainlit\" / \"lsm_analysis\" / \"data\" / \"sert_exp.xml\")\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "        if region in subregions_list and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(f\"id: {region} hemi: {hemi}, density: {density}, name: {name}\")\n",
    "            subregion_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "\n",
    "\n",
    "d = {\"Axon Density\": axon_denss, \"Gene\": gene, \"Subregion\": subregion_name}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(20, 10))\n",
    "fig.suptitle(\"Detected Output Axons\")\n",
    "\n",
    "sns.barplot(x=\"Axon Density\", y=\"Subregion\", hue=\"Gene\", data=df)\n",
    "axes.set_title(\"Density\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axon_denss = []\n",
    "axon_vols = []\n",
    "gene = []\n",
    "region_name = []\n",
    "for region in allen_regions:\n",
    "    print(f\"Populating: \" + G.nodes[region][\"name\"])\n",
    "    for brain in quantification_dicts.keys():\n",
    "        if (\n",
    "            G.nodes[region][brain + \" total\"] == 0\n",
    "            and G.nodes[region][brain + \" axon\"] == 0\n",
    "        ):\n",
    "            axon_denss.append(0)\n",
    "        elif G.nodes[region][brain + \" total\"] == 0:\n",
    "            raise ValueError(\"positive axon volume in zero volume region?\")\n",
    "        else:\n",
    "            axon_denss.append(\n",
    "                G.nodes[region][brain + \" axon\"] / G.nodes[region][brain + \" total\"]\n",
    "            )\n",
    "            axon_vols.append(\n",
    "                G.nodes[region][brain + \" axon\"]\n",
    "                * np.product([1.82, 1.82, 2])\n",
    "                * 10 ** (-9)\n",
    "            )\n",
    "\n",
    "        if brain in [\"B\", \"R\"]:\n",
    "            gene.append(\"Sample \" + brain)\n",
    "\n",
    "        region_name.append(G.nodes[region][\"name\"])\n",
    "\n",
    "tree = ET.parse(brainlit_path / \"brainlit\" / \"lsm_analysis\" / \"data\" / \"sert_exp.xml\")\n",
    "root = tree.getroot()\n",
    "root.tag\n",
    "for child in root:\n",
    "    for i, entry in enumerate(child):\n",
    "        for item in entry:\n",
    "            if item.tag == \"structure-id\":\n",
    "                region = int(item.text)\n",
    "            elif item.tag == \"hemisphere-id\":\n",
    "                hemi = int(item.text)\n",
    "            elif item.tag == \"is-injection\":\n",
    "                inject = item.text\n",
    "            elif item.tag == \"projection-density\":\n",
    "                density = float(item.text)\n",
    "            elif item.tag == \"projection-volume\":\n",
    "                volume = float(item.text)\n",
    "        if region in allen_regions and hemi == 3 and inject == \"false\":\n",
    "            name = G.nodes[region][\"name\"]\n",
    "            print(\n",
    "                f\"id: {region} hemi: {hemi}, density: {density}, volume: {volume}, name: {name}\"\n",
    "            )\n",
    "            region_name.append(name)\n",
    "            gene.append(\"Allen\")\n",
    "            axon_denss.append(density)\n",
    "            axon_vols.append(volume)\n",
    "\n",
    "\n",
    "d = {\n",
    "    \"Axon Density\": axon_denss,\n",
    "    \"Axon Volume ($mm^3$)\": axon_vols,\n",
    "    \"Gene\": gene,\n",
    "    \"Region\": region_name,\n",
    "}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle(\"Comparing Axon Volumes to Allen Experiment\")\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "sns.barplot(\n",
    "    ax=axes[0],\n",
    "    x=\"Axon Density\",\n",
    "    y=\"Region\",\n",
    "    hue=\"Gene\",\n",
    "    order=list(\n",
    "        df[df[\"Gene\"] == \"Allen\"]\n",
    "        .sort_values(\"Axon Density\", ascending=False)\n",
    "        .loc[:, \"Region\"]\n",
    "    ),\n",
    "    data=df,\n",
    ")\n",
    "# axes[0].set_title(\"Density\")\n",
    "\n",
    "sns.barplot(\n",
    "    ax=axes[1],\n",
    "    x=\"Axon Volume ($mm^3$)\",\n",
    "    y=\"Region\",\n",
    "    hue=\"Gene\",\n",
    "    order=list(\n",
    "        df[df[\"Gene\"] == \"Allen\"]\n",
    "        .sort_values(\"Axon Density\", ascending=False)\n",
    "        .loc[:, \"Region\"]\n",
    "    ),\n",
    "    data=df,\n",
    ")\n",
    "# axes[1].set_title(\"Axon Volume\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.BrainLine.util import find_sample_names\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/\"\n",
    "\n",
    "brains = [\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"887\",\n",
    "    \"8589\",\n",
    "    \"8590\",\n",
    "    \"8590_v2\",\n",
    "    \"8604\",\n",
    "    \"8612\",\n",
    "    \"8613\",\n",
    "    \"8649\",\n",
    "    \"8650\",\n",
    "    \"8786\",\n",
    "    \"8788\",\n",
    "    \"8790\",\n",
    "    \"11537\",\n",
    "]\n",
    "\n",
    "for brain in brains:\n",
    "    brain_dir = base_dir + \"brain\" + brain\n",
    "    files = find_sample_names(brain_dir, dset=\"\", add_dir=True)\n",
    "    for file in files:\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            key = list(f.keys())[0]\n",
    "            print(key)\n",
    "        #     image = np.array(f.get(key))\n",
    "        # image = image[[1, 0, 2],:,:,:]\n",
    "        # with h5py.File(file, \"w\") as f:\n",
    "        #     dset = f.create_dataset(key, data=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train_0-image_2channel_Labels.h5\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    key = list(f.keys())[0]\n",
    "    image = np.array(f.get(key))\n",
    "    print(image.shape)\n",
    "    print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.load(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train_0-image_2channel_Labels.npy\"\n",
    ")\n",
    "print(image.shape)\n",
    "print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = (\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain4/train/\"\n",
    ")\n",
    "for file in os.listdir(dir):\n",
    "    if \"Labels\" in file:\n",
    "        file = dir + file\n",
    "        print(file)\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            key = list(f.keys())[0]\n",
    "            image = np.array(f.get(key))\n",
    "        print(np.sum(image))\n",
    "        # npy_file = file.split(\".\")[0] + \".npy\"\n",
    "        # np.save(npy_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_axon/brain3/train/train_31-image_2channel_Labels.h5\"\n",
    "with h5py.File(file, \"r\") as f:\n",
    "    key = list(f.keys())[0]\n",
    "    image = np.array(f.get(key))\n",
    "npy_file = file.split(\".\")[0] + \".npy\"\n",
    "np.save(npy_file, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = CloudVolume(\n",
    "    \"precomputed://https://dlab-colm.neurodata.io/2022_10_24/8788/axon_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_sub = vol[int(256*11/8):int(256*12/8),int(256*16/8):int(256*17/8), int(256*6:256*7/8)]\n",
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://s3://smartspim-precomputed-volumes/2022_03_10/8531/atlas_to_target\"\n",
    ")\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"segmentation\",\n",
    "    data_type=\"uint64\",  # Channel images might be 'uint8'\n",
    "    encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=atlas_vol.voxel_offset,\n",
    "    chunk_size=[32, 32, 32],  # units are voxels\n",
    "    volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol_mask = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/atlas_to_target\",\n",
    "    info=info,\n",
    "    compress=False,\n",
    ")\n",
    "vol_mask.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_mask[\n",
    "    int(256 * 11 / 8) : int(256 * 12 / 8),\n",
    "    int(256 * 16 / 8) : int(256 * 17 / 8),\n",
    "    256 * 6 : 256 * 7,\n",
    "] = atlas_vol[\n",
    "    int(256 * 11 / 8) : int(256 * 12 / 8),\n",
    "    int(256 * 16 / 8) : int(256 * 17 / 8),\n",
    "    256 * 6 : 256 * 7,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvol = np.load(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/axon_mask_transformed/subvol.npy\"\n",
    ")\n",
    "vol = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/axon_mask_transformed\",\n",
    "    compress=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[30 * 32 : 32 * 32, 7 * 32 : 9 * 32, 16 * 32 : 18 * 32] = subvol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "\n",
    "vol = CloudVolume(\n",
    "    \"precomputed://s3://smartspim-precomputed-volumes/2023_05_24/MS29/Ch_561\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
