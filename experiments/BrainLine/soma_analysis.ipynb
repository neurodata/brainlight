{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soma Detection Analysis of Whole-Brain Light-Sheet Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.preprocessing import removeSmallCCs\n",
    "from brainlit.BrainLine.analyze_results import SomaDistribution\n",
    "from brainlit.BrainLine.util import (\n",
    "    json_to_points,\n",
    "    download_subvolumes,\n",
    ")\n",
    "from brainlit.BrainLine.apply_ilastik import (\n",
    "    ApplyIlastik,\n",
    "    ApplyIlastik_LargeImage,\n",
    "    plot_results,\n",
    "    examine_threshold,\n",
    ")\n",
    "from brainlit.BrainLine.parse_ara import *\n",
    "import xml.etree.ElementTree as ET\n",
    "from cloudreg.scripts.transform_points import NGLink\n",
    "from brainlit.BrainLine.imports import *\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.special import rel_entr\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "\n",
    "%gui qt5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Before Using this notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install brainlit, and other packages that this notebook uses\n",
    "### 1b. Write images to s3 using CloudReg\n",
    "    - e.g. python -m cloudreg.scripts.create_precomputed_volumes --s3_input_paths /mnt/NAS/SmartSPIM_Data/2022_03_02/20220302_14_40_04_8529_destriped_DONE/Ex_561_Em_600_stitched --s3_output_paths  s3://smartspim-precomputed-volumes/2022_03_02/8529/Ch_561_v2  --voxel_size 1.83 1.83 2 --num_procs 24 --resample_iso False\n",
    "### 1c. Make point annotations in neuroglancer to identify subvolumes for validation (and possible training)\n",
    "    - instructions: https://neurodata.io/help/neuroglancer-pt-annotations/\n",
    "    ,\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"soma_val\",\n",
    "    \"points\": []\n",
    "    },\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"nonsoma_val\",\n",
    "    \"points\":[]\n",
    "    }\n",
    "### 1d. Update soma_data.py file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brainlit_path = Path(os.path.abspath(\"\"))\n",
    "brainlit_path = brainlit_path.parents[1]\n",
    "print(f\"Path to brainlit: {brainlit_path}\")\n",
    "data_file = brainlit_path / \"experiments\" / \"BrainLine\" / \"data\" / \"soma_data.json\"\n",
    "\n",
    "with open(data_file) as f:\n",
    "    data = json.load(f)\n",
    "brain2paths = data[\"brain2paths\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download benchmark data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"MS22\"  # brain ID\n",
    "soma_data_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/\"  # path to directory where training/validation data should be stored\n",
    "dataset_to_save = \"val\"  # train or val\n",
    "\n",
    "antibody_layer = \"Ch_647\"\n",
    "background_layer = \"Ch_561\"\n",
    "endogenous_layer = \"Ch_488\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvol_base = brain2paths[brain][\"base\"]\n",
    "layer_names = [antibody_layer, background_layer, endogenous_layer]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_subvolumes(\n",
    "    soma_data_dir,\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    dataset_to_save=dataset_to_save,\n",
    "    data_file=data_file,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View downloaded data (optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/brainr2/val/891_4202_1717_pos.h5\"  # path to file for viewing\n",
    "scale = [1.8, 1.8, 2]  # voxel size in microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, \"r\") as f:\n",
    "    pred = f.get(\"image_3channel\")\n",
    "    image_fg = pred[0, :, :, :]\n",
    "    image_bg = pred[1, :, :, :]\n",
    "    image_endo = pred[2, :, :, :]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg, scale=scale)\n",
    "viewer.add_image(image_bg, scale=scale)\n",
    "viewer.add_image(image_endo, scale=scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply ilastik to validation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do this programmatically (below), or you can use the ilastik GUI (which is sometimes faster)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"_rabies_pix_3ch\"\n",
    "project_path = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/matt_soma{model}.ilp\"  # path to ilastik model to be used\n",
    "ilastik_path = (\n",
    "    \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"\n",
    ")\n",
    "brains_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/\"\n",
    "brains = [brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyilastik = ApplyIlastik(\n",
    "    ilastik_path=ilastik_path,\n",
    "    project_path=project_path,\n",
    "    brains_path=brains_path,\n",
    "    brains=brains,\n",
    ")\n",
    "applyilastik.process_subvols(ncpu=6)\n",
    "# applyilastik.move_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs (if relevant)\\*\n",
    "- identify files that have two somas in variable below. Since voxel coordinates are likely to be unique across samples, the file names below do not include sample IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles = [\n",
    "    \"3972_1636_1575_pos_Probabilities.h5\",\n",
    "    \"2867_4336_1296_pos_Probabilities.h5\",\n",
    "    \"2607_1845_1309_pos_Probabilities.h5\",\n",
    "    \"2101_3397_1747_pos_Probabilities.h5\",\n",
    "    \"2011_3452_1911_pos_Probabilities.h5\",\n",
    "    \"2113_3353_1727_pos_Probabilities.h5\",\n",
    "    \"1968_3472_1784_pos_Probabilities.h5\",\n",
    "    \"2589_5825_1626_pos_Probabilities.h5\",\n",
    "    \"2138_4233_2329_pos_Probabilities.h5\",\n",
    "]  # 8446"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    data_dir=soma_data_dir,\n",
    "    brain_ids=brains,\n",
    "    object_type=\"soma\",\n",
    "    positive_channel=0,\n",
    "    doubles=doubles,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_threshold(\n",
    "    data_dir=soma_data_dir,\n",
    "    brain_id=brain,\n",
    "    threshold=0.72,\n",
    "    object_type=\"soma\",\n",
    "    positive_channel=0,\n",
    "    doubles=doubles,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper figure for all validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_ids = [\n",
    "    \"8607\",\n",
    "    \"8606\",\n",
    "    \"8477\",\n",
    "    \"8531\",\n",
    "    \"8608\",\n",
    "    \"8529\",\n",
    "    \"r1\",\n",
    "    \"r2\",\n",
    "    \"8446\",\n",
    "    \"8454\",\n",
    "    \"887\",\n",
    "    \"MPRRabies\",\n",
    "    \"969\",\n",
    "    \"910\",\n",
    "]\n",
    "\n",
    "plot_results(\n",
    "    data_dir=soma_data_dir,\n",
    "    brain_ids=brain_ids,\n",
    "    object_type=\"soma\",\n",
    "    positive_channel=0,\n",
    "    doubles=doubles,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Annotation layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\"\n",
    ")\n",
    "for layer in [\n",
    "    antibody_layer,\n",
    "    background_layer,\n",
    "]:  # axon_mask is transformed into an image because nearest interpolation doesnt work well after downsampling\n",
    "    layer_path = brain2paths[brain][\"base\"] + layer + \"_transformed\"\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"image\",\n",
    "        data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=atlas_vol.voxel_offset,\n",
    "        chunk_size=[32, 32, 32],  # units are voxels\n",
    "        volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(layer_path, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply ilastik to whole image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*\n",
    "You can use the notebook code below or the script using `soma_detect_image.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"test\"\n",
    "antibody_layer = \"antibody\"\n",
    "background_layer = \"background\"\n",
    "endogenous_layer = \"endogenous\"\n",
    "\n",
    "threshold = 0.28  # threshold to use for ilastik\n",
    "data_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainr_temp/\"  # \"/data/tathey1/matt_wright/brainr_temp/\"  # directory to store temporary subvolumes for segmentation\n",
    "results_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainr_results/\"  # directory to store coordinates of soma detections\n",
    "\n",
    "# Ilastik will run in \"headless mode\", and the following paths are needed to do so:\n",
    "ilastik_path = \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"  # \"/data/tathey1/matt_wright/ilastik/ilastik-1.4.0rc5-Linux/run_ilastik.sh\"  # path to ilastik executable\n",
    "ilastik_project = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/matt_soma_rabies_pix_3ch.ilp\"  # \"/data/tathey1/matt_wright/ilastik/soma_model/matt_soma_rabies_pix_3ch.ilp\"  # path to ilastik project\n",
    "\n",
    "max_coords = [3072, 4352, 1792]  # -1 if you want to process the whole dimension\n",
    "ncpu = 1  # 16  # number of cores to use for detection\n",
    "chunk_size = [256, 256, 256]  # [256, 256, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [antibody_layer, background_layer, endogenous_layer]\n",
    "\n",
    "ilastik_largeimage = ApplyIlastik_LargeImage(\n",
    "    ilastik_path=ilastik_path,\n",
    "    ilastik_project=ilastik_project,\n",
    "    results_dir=results_dir,\n",
    "    ncpu=1,\n",
    ")\n",
    "ilastik_largeimage.apply_ilastik_parallel(\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    threshold=threshold,\n",
    "    data_dir=data_dir,\n",
    "    chunk_size=chunk_size,\n",
    "    max_coords=max_coords,\n",
    ")\n",
    "ilastik_largeimage.collect_results(brain_id=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Register volume and transform data to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. You need to find an initial affine alignment using cloudreg.scripts.registration.get_affine_matrix. For example: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A link to the ARA parcellation is:\n",
    "\n",
    "`precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017`\n",
    "\n",
    "And some python commands to help with affine alignment is:\n",
    "\n",
    "```\n",
    "from cloudreg.scripts.registration import get_affine_matrix\n",
    "get_affine_matrix([1,1,1], [0,0,0], \"PIR\", \"RPI\", 1.15, \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Run registration using cloudreg.scripts.registration. For example:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.registration -input_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_25/MS22/Ch_561 --output_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_25/MS22/atlas_to_target --atlas_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_50um/average_50um --parcellation_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --atlas_orientation PIR -orientation RAI --rotation 0 0 5 --translation 0 0 0 --fixed_scale 1.05 -log_s3_path precomputed://s3://smartspim-precomputed-volumes/2023_04_25/MS22/atlas_to_target --missing_data_correction True --grid_correction False --bias_correction True --regularization 5000.0 --iterations 3000 --registration_resolution 100\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Transform data to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soma coordinates\n",
    "\n",
    "```\n",
    "python -m cloudreg.scripts.transform_points --target_viz_link \"https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=Fy1xF8FlJM7BcQ\" --atlas_viz_link \"https://ara.viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=HvyNDGaPsd1wyg\" --affine_path /mnt/NAS/Neuroglancer\\ Data/2023_04_25/MS22/MS22_Ch_561_registration/downloop_1_A.mat  --velocity_path /mnt/NAS/Neuroglancer\\ Data/2023_04_25/MS22/MS22_Ch_561_registration/downloop_1_v.mat --transformation_direction \"atlas\"\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "python -m cloudreg.scripts.transform_points --target_viz_link https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=05Fhxt5VBT-_1A --atlas_viz_link https://ara.viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=HvyNDGaPsd1wyg --affine_path /cis/home/tathey/MPRRabies_Ch_561_registration/downloop_1_A.mat   --velocity_path /cis/home/tathey/MPRRabies_Ch_561_registration/downloop_1_v.mat  --transformation_direction atlas\n",
    "```\n",
    "\n",
    "This will produce a neuroglancer link with the transformed soma coordinates, which should be added to `soma_data.py` under the `somas_atlas_url` key. Then the code below, or `soma_brainrender.py`, can be used to visualize the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image\n",
    "\n",
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_03_15/969/Ch_561 --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_03_15/969/Ch_561_transformed --affine_path /cis/home/tathey/887_Ch_561_registration/downloop_1_A.mat  --velocity_path /cis/home/tathey/887_Ch_561_registration/downloop_1_v.mat\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_03_15/969/Ch_561 --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_03_15/969/Ch_561_transformed --affine_path /mnt/NAS/Neuroglancer\\ Data/969_Ch_561_registration/downloop_1_A.mat  --velocity_path /mnt/NAS/Neuroglancer\\ Data/969_Ch_561_registration/downloop_1_v.mat\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. View results in brain space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_ids = [\n",
    "    \"8557\",\n",
    "    \"8555\",\n",
    "    \"8607\",\n",
    "    \"8606\",\n",
    "    # \"8477\",\n",
    "    # \"8531\",\n",
    "    \"8608\",\n",
    "    # \"8529\",\n",
    "    # \"8454\",\n",
    "    \"MPRRabies\",\n",
    "    \"969\",\n",
    "    \"892\",\n",
    "    \"MS37\",\n",
    "    \"MS36\",\n",
    "    \"MS25\",\n",
    "    \"MS23\",\n",
    "    \"MS22\",\n",
    "]\n",
    "\n",
    "colors = {\n",
    "    \"tph2 vglut3\": \"blue\",\n",
    "    \"tph2 gad2\": \"red\",\n",
    "    \"gad2 vgat\": \"green\",\n",
    "}  # colors for different genotypes\n",
    "symbols = [\"o\", \"+\", \"^\", \"vbar\", \"diamond\"]\n",
    "fold_on = False\n",
    "ontology_file = brainlit_path / \"BrainLine\" \"data\" / \"ara_structure_ontology.json\"\n",
    "\n",
    "sd = SomaDistribution(\n",
    "    brain_ids=brain_ids, data_file=data_file, ontology_file=ontology_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = 1320\n",
    "for z in tqdm(np.arange(0, z_size, 50)):\n",
    "    sd.napari_coronal_section(\n",
    "        z=z, subtype_colors=colors, symbols=symbols, fold_on=fold_on\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/matt-coronals/\"\n",
    "z_size = 1320\n",
    "\n",
    "for z in tqdm(np.arange(50, z_size, 50)):\n",
    "    fname = dir + f\"{brain}_{z}.tif\"\n",
    "    v = sd.napari_coronal_section(\n",
    "        z=z, subtype_colors=colors, symbols=symbols, fold_on=False\n",
    "    )\n",
    "    im = v.screenshot(canvas_only=False)\n",
    "    io.imsave(fname, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.brainrender_somas(subtype_colors=colors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Display bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    688,  # cerebral cortex\n",
    "    95,  # agranular insular area\n",
    "    714,  # orbital area\n",
    "    698,  # olfactory areas\n",
    "    1089,  # hippocampal formation\n",
    "    # 583, # claustrum\n",
    "    477,  # striatum\n",
    "    # 803, # pallidum\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    # 703, #cortical subplate\n",
    "    1097,  # hypothalamus\n",
    "    157,  # periventricular zone\n",
    "    515,  # medial preoptic nucleus\n",
    "    290,  # hypothalamic lateral zone\n",
    "    331,  # mammillary body\n",
    "    797,  # zona incerta\n",
    "    549,  # thalamus\n",
    "    186,  # lateral habenula\n",
    "    519,  # cerebellar nuclei\n",
    "    846,  # dentate nucleus\n",
    "    # 726,  # dentate gyrus\n",
    "    313,  # midbrain\n",
    "    157,  # inferior colliculus\n",
    "    1052,  # pedunculopontine\n",
    "    128,  # midbrain reticular nucleus\n",
    "    214,  # red nucleus\n",
    "    1065,  # hindbrain\n",
    "    867,  # parabrachial nucleus\n",
    "    701,  # vestibular nuclei\n",
    "    972,  # prelimbic\n",
    "    44,  # infralimbic\n",
    "]  # allen atlas region IDs to be shown\n",
    "# see: https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3\n",
    "\n",
    "composite_regions = {\n",
    "    \"Amygdalar Nuclei\": [131, 295, 319, 780],\n",
    "    \"Substantia Nigra\": [615, 374, 374],\n",
    "    \"Superior Colliculus\": [294, 302],\n",
    "}  # Custom composite allen regions where key is region name and value is list of allen regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.region_barchart(regions, composite_regions=composite_regions, normalize_region=872)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    688,  # cerebral cortex\n",
    "    477,  # striatum\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    1097,  # hypothalamus\n",
    "    549,  # thalamus\n",
    "    519,  # cerebellar nuclei\n",
    "    313,  # midbrain\n",
    "    1065,  # hindbrain\n",
    "]  # allen atlas region IDs to be shown\n",
    "\n",
    "# regions = [\n",
    "#     688,  # cerebral cortex\n",
    "#     # 95,  # agranular insular area\n",
    "#     # 714,  # orbital area\n",
    "#     # 698,  # olfactory areas\n",
    "#     # 1089,  # hippocampal formation\n",
    "#     # 583, # claustrum\n",
    "#     477,  # striatum\n",
    "#     # 803, # pallidum\n",
    "#     351,  # bed nuclei of stria terminalis\n",
    "#     # 703, #cortical subplate\n",
    "#     157,  # periventricular zone\n",
    "#     515,  # medial preoptic nucleus\n",
    "#     290,  # hypothalamic lateral zone\n",
    "#     331,  # mammillary body\n",
    "#     549,  # thalamus\n",
    "#     519,  # cerebellar nuclei\n",
    "#     # 726,  # dentate gyrus\n",
    "#     157,  # inferior colliculus\n",
    "#     1052,  # pedunculopontine\n",
    "#     128,  # midbrain reticular nucleus\n",
    "#     214,  # red nucleus\n",
    "#     1065,  # hindbrain\n",
    "# ]  # allen atlas region IDs to be shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_src in regions:\n",
    "    for r_targ in regions:\n",
    "        if r_targ == r_src:\n",
    "            continue\n",
    "        elif nx.has_path(sd.region_graph, r_src, r_targ):\n",
    "            print(f\"{r_src} is parent of {r_targ}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Div permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(brain_id, regions, sd):\n",
    "    total = sd.region_graph.nodes[997][brain_id]\n",
    "    dist = []\n",
    "    for region in regions:\n",
    "        dist.append(sd.region_graph.nodes[region][brain_id])\n",
    "    dist.append(total - np.sum(dist))\n",
    "\n",
    "    return np.divide(dist, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3)\n",
    "\n",
    "for i, (stype1, stype2) in enumerate(\n",
    "    zip(\n",
    "        [\"tph2 gad2\", \"tph2 gad2\", \"tph2 vglut3\"],\n",
    "        [\"tph2 vglut3\", \"gad2 vgat\", \"gad2 vgat\"],\n",
    "    )\n",
    "):\n",
    "    ax = axs[i]\n",
    "    brain_ids_stypes = []\n",
    "    sz = 0\n",
    "    dists = []\n",
    "\n",
    "    for brain in brain_ids:\n",
    "        if sd.brain2paths[brain][\"subtype\"] == stype1:\n",
    "            dist = get_dist(brain, regions, sd)\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "            sz += 1\n",
    "    av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    dists = []\n",
    "    for brain in brain_ids:\n",
    "        if sd.brain2paths[brain][\"subtype\"] == stype2:\n",
    "            dist = get_dist(brain, regions, sd)\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "    av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    kl_div_true = np.sum(rel_entr(av_dist1, av_dist2)) + np.sum(\n",
    "        rel_entr(av_dist2, av_dist1)\n",
    "    )\n",
    "    if not np.isfinite(kl_div_true) or kl_div_true < 0:\n",
    "        print(av_dist1)\n",
    "        print(av_dist2)\n",
    "    kl_divs = []\n",
    "\n",
    "    for combo in tqdm(combinations(brain_ids_stypes, sz)):\n",
    "        dists = []\n",
    "        for brain in combo:\n",
    "            dist = get_dist(brain, regions, sd)\n",
    "            dists.append(dist)\n",
    "        av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        dists = []\n",
    "        for brain in brain_ids:\n",
    "            if brain not in combo:\n",
    "                if (\n",
    "                    sd.brain2paths[brain][\"subtype\"] == stype1\n",
    "                    or sd.brain2paths[brain][\"subtype\"] == stype2\n",
    "                ):\n",
    "                    dist = get_dist(brain, regions, sd)\n",
    "                    dists.append(dist)\n",
    "        av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        kl_div_c = np.sum(rel_entr(av_dist1, av_dist2)) + np.sum(\n",
    "            rel_entr(av_dist2, av_dist1)\n",
    "        )\n",
    "\n",
    "        if not np.isfinite(kl_div_c) or kl_div_c < 0:\n",
    "            print(av_dist1)\n",
    "            print(av_dist2)\n",
    "        kl_divs.append(kl_div_c)\n",
    "\n",
    "    p = np.sum(kl_divs > kl_div_true) / len(kl_divs)\n",
    "    ax.hist(kl_divs)\n",
    "    ax.plot([kl_div_true, kl_div_true], [0, 15], c=\"r\", label=f\"pval={p:.2f}\")\n",
    "    ax.set_title(f\"{stype1} vs {stype2} w/{len(kl_divs)} permutations\")\n",
    "    ax.legend()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-sq test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {}\n",
    "for subtype in colors.keys():\n",
    "    column = []\n",
    "    for region in regions:\n",
    "        cell = 0\n",
    "        for brain_id in brain_ids:\n",
    "            if sd.brain2paths[brain_id][\"subtype\"] == subtype:\n",
    "                cell += sd.region_graph.nodes[region][brain_id]\n",
    "\n",
    "        column.append(cell)\n",
    "    table[subtype] = column\n",
    "\n",
    "for subtype1 in table.keys():\n",
    "    for subtype2 in table.keys():\n",
    "        if subtype1 != subtype2:\n",
    "            _, p, _, _ = chi2_contingency([table[subtype1], table[subtype2]])\n",
    "            print(f\"{subtype1} vs {subtype2} - {p}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hemisphere plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = []\n",
    "region_data = []\n",
    "left_count_data = []\n",
    "right_count_data = []\n",
    "gtypes = []\n",
    "\n",
    "for region in regions:\n",
    "    for brain in brain_ids:\n",
    "        sample_data.append(brain)\n",
    "        region_data.append(region)\n",
    "        left_count_data.append(sd.region_graph_l.nodes[region][brain])\n",
    "        right_count_data.append(sd.region_graph_r.nodes[region][brain])\n",
    "        gtypes.append(sd.brain2paths[brain][\"subtype\"])\n",
    "data = {\n",
    "    \"Sample\": sample_data,\n",
    "    \"Region\": region_data,\n",
    "    \"Somas Left\": left_count_data,\n",
    "    \"Somas Right\": right_count_data,\n",
    "    \"Subtype\": gtypes,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "fig, axs = plt.subplots(3, 9)\n",
    "\n",
    "for region, ax in zip(regions, axs.flatten()):\n",
    "    for gtype in df[\"Subtype\"].unique():\n",
    "        df_r = df[df[\"Region\"] == region]\n",
    "        df_r = df_r[df_r[\"Subtype\"] == gtype]\n",
    "        graph = sns.regplot(data=df_r, x=\"Somas Left\", y=\"Somas Right\", ax=ax)\n",
    "        r, p = pearsonr(df_r[\"Somas Left\"], df_r[\"Somas Right\"])\n",
    "        txt = f'{sd.region_graph.nodes[region][\"name\"]}*: '  # f'{sd.region_graph.nodes[region][\"name\"]}: r={r:.2f}, p={p:.2f}'\n",
    "        if p < 0.05:\n",
    "            txt = txt + gtype\n",
    "    ax.title.set_text(txt)\n",
    "\n",
    "\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(35)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare distributions with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "brain_ids = []\n",
    "genotypes = []\n",
    "\n",
    "for i, brain in enumerate(brains):\n",
    "    print(brain)\n",
    "    region_order = list(df.loc[df[\"Brain ID\"] == brain][\"Region\"])\n",
    "\n",
    "    if i == 0:\n",
    "        standard_region_order = region_order\n",
    "    elif standard_region_order != region_order:\n",
    "        raise ValueError(f\"Different region order for brain {brain}\")\n",
    "\n",
    "    distrib = list(df.loc[df[\"Brain ID\"] == brain][\"Percent of Total Somas (%)\"])\n",
    "    X.append(distrib)\n",
    "\n",
    "    brain_ids.append(brain)\n",
    "    genotypes.append(brains[brain])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2 = pca.fit_transform(X)\n",
    "\n",
    "df_pca = {\n",
    "    \"PC 1\": X_2[:, 0],\n",
    "    \"PC 2\": X_2[:, 1],\n",
    "    \"Genotype\": genotypes,\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df_pca = pd.DataFrame(data=df_pca)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "sns.scatterplot(data=df_pca, x=\"PC 1\", y=\"PC 2\", hue=\"Genotype\", ax=ax)\n",
    "\n",
    "\n",
    "for i in range(df_pca.shape[0]):\n",
    "    plt.text(\n",
    "        x=df_pca[\"PC 1\"][i] + 0.03,\n",
    "        y=df_pca[\"PC 2\"][i] + 0.03,\n",
    "        s=df_pca[\"Brain ID\"][i],\n",
    "        fontdict=dict(color=\"black\", size=20),\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Input Distribution PCA with Explained Variance: {pca.explained_variance_ratio_}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create local volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = CloudVolume(\n",
    "    \"precomputed://s3://smartspim-precomputed-volumes/2022_03_10/8531/Ch_647_iso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvol = vol[256 * 11 : 256 * 12, 256 * 16 : 256 * 17, 256 * 6 : 256 * 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"image\",\n",
    "    data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "    encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution=vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=vol.voxel_offset,\n",
    "    chunk_size=vol.chunk_size,  # units are voxels\n",
    "    volume_size=vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    ")\n",
    "\n",
    "vol_ex = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example\",\n",
    "    info=info,\n",
    "    compress=False,\n",
    ")\n",
    "vol_ex.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_ex[256 * 11 : 256 * 12, 256 * 16 : 256 * 17, 256 * 6 : 256 * 7] = subvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/endogenous\",\n",
    "    fill_missing=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post detections to ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_id = \"8606\"\n",
    "all_somas_pth = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/wholebrain_results/all_somas_{brain_id}.txt\"\n",
    "\n",
    "from brainlit.BrainLine.data.soma_data import brain2paths\n",
    "from cloudreg.scripts.transform_points import NGLink\n",
    "from cloudreg.scripts.visualization import create_viz_link_from_json\n",
    "\n",
    "coords = []\n",
    "coords_target_space = []\n",
    "file1 = open(all_somas_pth, \"r\")\n",
    "lines = file1.readlines()\n",
    "for line in tqdm(lines, desc=\"parsing coordinates\", leave=False):\n",
    "    if line != \"\\n\":\n",
    "        line = \" \".join(line.split())\n",
    "        elements = line.split(\",\")\n",
    "        coord = [elements[0][1:], elements[1], elements[2][:-1]]\n",
    "\n",
    "        coords.append([float(e.strip()) for e in coord])\n",
    "\n",
    "coords = coords[15000:]\n",
    "print(f\"{len(coords)} detections\")\n",
    "\n",
    "ng_link = brain2paths[brain_id][\"val_info\"][\"url\"]\n",
    "viz_link = NGLink(ng_link.split(\"json_url=\")[-1])\n",
    "ngl_json = viz_link._json\n",
    "\n",
    "ngl_json[\"layers\"] = [\n",
    "    layer for layer in ngl_json[\"layers\"] if layer[\"type\"] != \"annotation\"\n",
    "]\n",
    "\n",
    "ngl_json[\"layers\"].append(\n",
    "    {\"type\": \"annotation\", \"points\": coords, \"name\": \"detected_somas\"}\n",
    ")\n",
    "viz_link = create_viz_link_from_json(\n",
    "    ngl_json, neuroglancer_link=\"https://viz.neurodata.io/?json_url=\"\n",
    ")\n",
    "print(f\"Viz link with detections: {viz_link}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('docs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
