{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soma Detection Analysis of Whole-Brain Light-Sheet Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.preprocessing import removeSmallCCs\n",
    "from brainlit.BrainLine.analyze_results import SomaDistribution\n",
    "from brainlit.BrainLine.util import (\n",
    "    json_to_points,\n",
    "    download_subvolumes,\n",
    "    dir_to_atlas_pts,\n",
    ")\n",
    "from brainlit.BrainLine.apply_ilastik import (\n",
    "    ApplyIlastik,\n",
    "    ApplyIlastik_LargeImage,\n",
    "    plot_results,\n",
    "    examine_threshold,\n",
    ")\n",
    "from brainlit.BrainLine.parse_ara import *\n",
    "import xml.etree.ElementTree as ET\n",
    "from cloudreg.scripts.transform_points import NGLink\n",
    "from brainlit.BrainLine.imports import *\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.special import rel_entr\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import random\n",
    "from statannotations.Annotator import Annotator\n",
    "from statannotations.stats.StatTest import StatTest\n",
    "from scipy.stats import ttest_ind\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "%gui qt5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install brainlit, and other packages that this notebook uses\n",
    "### 1b. Write images to s3 using CloudReg\n",
    "    - e.g. python -m cloudreg.scripts.create_precomputed_volumes --input_parent_dir /mnt/NAS/SmartSPIM_Data/2024_01_04/20240104_13_27_03_5573N_destriped_DONE/ --s3_output_parent_dir  s3://smartspim-precomputed-volumes/2024_01_04/5573N/  --local_output_parent_dir \"precomputed://file:///mnt/data/Neuroglancer_Data/2024_01_04/5573N/\" --voxel_size 1.83 1.83 2 --num_procs 36 --resample_iso False\n",
    "### 1c. Make point annotations in neuroglancer to identify subvolumes for validation (and possible training)\n",
    "[instructions](https://neurodata.io/help/neuroglancer-pt-annotations/). JSON state layer snippet:\n",
    "\n",
    "    ,\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"soma_val\",\n",
    "    \"points\": []\n",
    "    },\n",
    "    {\n",
    "    \"type\":\"pointAnnotation\",\n",
    "    \"name\": \"nonsoma_val\",\n",
    "    \"points\":[]\n",
    "    }\n",
    "### 1d. Add brain sample to soma_data.py file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Before Using this notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to brainlit: {brainlit_path}\n"
     ]
    }
   ],
   "source": [
    "brainlit_path = Path(os.path.abspath(\"\"))\n",
    "brainlit_path = brainlit_path.parents[1]\n",
    "print(\"Path to brainlit: {brainlit_path}\")\n",
    "data_file = brainlit_path / \"experiments\" / \"BrainLine\" / \"data\" / \"soma_data.json\"\n",
    "\n",
    "with open(data_file) as f:\n",
    "    data = json.load(f)\n",
    "brain2paths = data[\"brain2paths\"]\n",
    "\n",
    "brain = \"028L\"  # brain ID\n",
    "soma_data_dir = \"/home/user/brainlit/experiments/BrainLine/data/validation-and-models/soma/\"  # path to directory where training/validation data should be stored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download benchmark data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_save = \"val\"  # train or val\n",
    "\n",
    "# \"zero\" to fill the layer with zeros\n",
    "antibody_layer = \"Ch_647\"  # \"Ch_647\"\n",
    "background_layer = \"Ch_561\"\n",
    "endogenous_layer = \"Ch_488\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvol_base = brain2paths[brain][\"base_s3\"]\n",
    "layer_names = [antibody_layer, background_layer, endogenous_layer]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_subvolumes(\n",
    "    soma_data_dir,\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    dataset_to_save=dataset_to_save,\n",
    "    data_file=data_file,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View downloaded data (optional)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/home/user/brainlit/experiments/BrainLine/data/validation-and-models/soma/brain5573N/val/1504_3412_787_pos.h5\"  # path to file for viewing\n",
    "scale = [1.8, 1.8, 2]  # voxel size in microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, \"r\") as f:\n",
    "    pred = f.get(\"image_3channel\")\n",
    "    image_fg = pred[0, :, :, :]\n",
    "    image_bg = pred[1, :, :, :]\n",
    "    image_endo = pred[2, :, :, :]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg, scale=scale)\n",
    "viewer.add_image(image_bg, scale=scale)\n",
    "viewer.add_image(image_endo, scale=scale)\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply ilastik to validation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do this programmatically (below), or you can use the ilastik GUI (which is sometimes faster)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = str(\n",
    "    brainlit_path\n",
    "    / Path(\"experiments/BrainLine/data/validation-and-models/soma/matt_soma_rabies_pix_3ch.ilp\")\n",
    ")  # path to ilastik model to be used\n",
    "dset = \"val\"\n",
    "ilastik_path = \"/home/user/Documents/ilastik-1.4.0-Linux/run_ilastik.sh\"  # path to ilastik executable (see here: https://www.ilastik.org/documentation/basics/headless.html)\n",
    "\n",
    "brains_path = \"/home/user/brainlit/experiments/BrainLine/data/validation-and-models/soma/\"\n",
    "brains = [brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyilastik = ApplyIlastik(\n",
    "    ilastik_path=ilastik_path,\n",
    "    project_path=project_path,\n",
    "    brains_path=brains_path,\n",
    "    brains=brains,\n",
    ")\n",
    "applyilastik.process_subvols(dset=dset, ncpu=1)\n",
    "# applyilastik.move_results()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs (if relevant)\\*\n",
    "- identify files that have two somas in variable below. Since voxel coordinates are likely to be unique across samples, the file names below do not include sample IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles = [\n",
    "    \"3972_1636_1575_pos\",\n",
    "    \"2867_4336_1296_pos\",\n",
    "    \"2607_1845_1309_pos\",\n",
    "    \"2101_3397_1747_pos\",\n",
    "    \"2011_3452_1911_pos\",\n",
    "    \"2113_3353_1727_pos\",\n",
    "    \"1968_3472_1784_pos\",\n",
    "    \"2589_5825_1626_pos\",\n",
    "    \"2138_4233_2329_pos\",\n",
    "    \"2545_6206_1551_pos\",\n",
    "    \"2568_6047_1553_pos\",\n",
    "    \"2547_6082_1541_pos\",\n",
    "    \"3010_5734_1340_pos\",\n",
    "    \"5458_5532_2463_pos\",\n",
    "    \"3669_4378_1341_pos\",\n",
    "    \"2855_4063_1834_pos\",\n",
    "    \"4579_6656_2509_pos\",\n",
    "    \"4298_4721_1771_pos\",\n",
    "    \"2861_3982_1340_pos\",\n",
    "    \"3135_4026_1340_pos\",\n",
    "    \"2922_5626_1542_pos\",\n",
    "    \"3470_6606_2090_pos\",\n",
    "    \"1642_5758_1668_pos\",\n",
    "    \"650_5279_1686_pos\",\n",
    "    \"1414_2947_1669_pos\",\n",
    "    \"2164_6714_1636_pos\"\n",
    "]  # move 2545?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    data_dir=soma_data_dir,\n",
    "    brain_ids=brains,\n",
    "    object_type=\"soma\",\n",
    "    positive_channel=0,\n",
    "    dset=dset,\n",
    "    doubles=doubles,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_threshold(\n",
    "    data_dir=soma_data_dir,\n",
    "    brain_id=brain,\n",
    "    threshold=0.56,\n",
    "    object_type=\"soma\",\n",
    "    positive_channel=0,\n",
    "    dset=dset,\n",
    "    doubles=doubles,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper figure for all validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_ids = [\n",
    "    \"8607\",\n",
    "    \"8606\",\n",
    "    \"8477\",\n",
    "    \"8531\",\n",
    "    \"8608\",\n",
    "    \"8529\",\n",
    "    \"r1\",\n",
    "    \"r2\",\n",
    "    \"8446\",\n",
    "    \"8454\",\n",
    "    \"887\",\n",
    "    \"MPRRabies\",\n",
    "    \"969\",\n",
    "    \"910\",\n",
    "]\n",
    "\n",
    "plot_results(\n",
    "    data_dir=soma_data_dir,\n",
    "    brain_ids=brain_ids,\n",
    "    object_type=\"soma\",\n",
    "    positive_channel=0,\n",
    "    doubles=doubles,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Annotation layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = \"base_local\"\n",
    "\n",
    "atlas_vol = CloudVolume(\n",
    "    \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\"\n",
    ")\n",
    "for layer in [\n",
    "    antibody_layer,\n",
    "    background_layer,\n",
    "    endogenous_layer,\n",
    "]:  # axon_mask is transformed into an image because nearest interpolation doesnt work well after downsampling\n",
    "    layer_path = brain2paths[brain][destination_path] + layer + \"_transformed\"\n",
    "    info = CloudVolume.create_new_info(\n",
    "        num_channels=1,\n",
    "        layer_type=\"image\",\n",
    "        data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "        encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "        resolution=atlas_vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "        voxel_offset=atlas_vol.voxel_offset,\n",
    "        chunk_size=[32, 32, 32],  # units are voxels\n",
    "        volume_size=atlas_vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    "    )\n",
    "    vol_mask = CloudVolume(layer_path, info=info)\n",
    "    vol_mask.commit_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply ilastik to whole image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Inputs \\*\n",
    "You can use the notebook code below or the script using `soma_detect_image.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"test\"\n",
    "antibody_layer = \"antibody\"\n",
    "background_layer = \"background\"\n",
    "endogenous_layer = \"endogenous\"\n",
    "\n",
    "threshold = 0.28  # threshold to use for ilastik\n",
    "data_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainr_temp/\"  # \"/data/tathey1/matt_wright/brainr_temp/\"  # directory to store temporary subvolumes for segmentation\n",
    "results_dir = \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainr_results/\"  # directory to store coordinates of soma detections\n",
    "\n",
    "# Ilastik will run in \"headless mode\", and the following paths are needed to do so:\n",
    "ilastik_path = \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"  # \"/data/tathey1/matt_wright/ilastik/ilastik-1.4.0rc5-Linux/run_ilastik.sh\"  # path to ilastik executable\n",
    "ilastik_project = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/matt_soma_rabies_pix_3ch.ilp\"  # \"/data/tathey1/matt_wright/ilastik/soma_model/matt_soma_rabies_pix_3ch.ilp\"  # path to ilastik project\n",
    "\n",
    "max_coords = [3072, 4352, 1792]  # -1 if you want to process the whole dimension\n",
    "ncpu = 1  # 16  # number of cores to use for detection\n",
    "chunk_size = [256, 256, 256]  # [256, 256, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [antibody_layer, background_layer, endogenous_layer]\n",
    "\n",
    "ilastik_largeimage = ApplyIlastik_LargeImage(\n",
    "    ilastik_path=ilastik_path,\n",
    "    ilastik_project=ilastik_project,\n",
    "    results_dir=results_dir,\n",
    "    ncpu=1,\n",
    ")\n",
    "ilastik_largeimage.apply_ilastik_parallel(\n",
    "    brain_id=brain,\n",
    "    layer_names=layer_names,\n",
    "    threshold=threshold,\n",
    "    data_dir=data_dir,\n",
    "    chunk_size=chunk_size,\n",
    "    max_coords=max_coords,\n",
    ")\n",
    "ilastik_largeimage.collect_results(brain_id=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A link to the ARA parcellation is:\n",
    "\n",
    "`precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017`\n",
    "\n",
    "And some python commands to help with affine alignment is:\n",
    "\n",
    "```\n",
    "from cloudreg.scripts.registration import get_affine_matrix\n",
    "\n",
    "get_affine_matrix([1,1,1], [0,0,0], \"PIR\", \"RPI\", 1.15, \"precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Register volume and transform data to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. You need to find an initial affine alignment using cloudreg.scripts.registration.get_affine_matrix. For example: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Run registration using cloudreg.scripts.registration. For example:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python -m cloudreg.scripts.registration -input_s3_path precomputed://s3://smartspim-precomputed-volumes/2024_01_04/5573N/Ch_561 --output_s3_path precomputed://s3://smartspim-precomputed-volumes/2024_01_04/5573N/atlas_to_target --atlas_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_50um/average_50um --parcellation_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --atlas_orientation PIR -orientation RPI --rotation 0 0 0 --translation 0 0 0 --fixed_scale 1.1 -log_s3_path precomputed://s3://smartspim-precomputed-volumes/2024_01_04/5573N/atlas_to_target --missing_data_correction True --grid_correction False --bias_correction True --regularization 5000.0 --iterations 3000 --registration_resolution 100\n",
    "\n",
    "python -m cloudreg.scripts.registration -input_s3_path precomputed://file:///mnt/data/Neuroglancer\\ Data/2024_06_10/028L/Ch_561/ --output_s3_path precomputed://file:///mnt/data/Neuroglancer\\ Data/2024_06_10/028L/ --atlas_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_50um/average_50um --parcellation_s3_path https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --atlas_orientation PIR -orientation RAI --rotation 0 0 0 --translation 0 0 0 --fixed_scale 1.0 -log_s3_path precomputed://file:///mnt/data/Neuroglancer\\ Data/2024_06_10/028L/atlas_to_target --missing_data_correction True --grid_correction False --bias_correction True --regularization 5000.0 --iterations 3000 --registration_resolution 100\n",
    "``"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Transform data to atlas space using CloudReg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soma coordinates\n",
    "\n",
    "ng link\n",
    "```\n",
    "python -m cloudreg.scripts.transform_points --target_viz_link \"https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=MENqxx5mL5nhew\" --atlas_viz_link \"https://ara.viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=HvyNDGaPsd1wyg\" --affine_path /home/user/028L_Ch_561_registration/downloop_1_A.mat --velocity_path /home/user/028L_Ch_561_registration/downloop_1_v.mat --transformation_direction \"atlas\"\n",
    "`````\n",
    "\n",
    "This will produce a neuroglancer link with the transformed soma coordinates, which should be added to `soma_data.py` under the `somas_atlas_url` key. Then the code below, or `soma_brainrender.py`, can be used to visualize the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image\n",
    "\n",
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_03_15/969/Ch_561 --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2023_03_15/969/Ch_561_transformed --affine_path /cis/home/tathey/8557_Ch_561_registration/downloop_1_A.mat  --velocity_path /cis/home/tathey/8557_Ch_561_registration/downloop_1_v.mat\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://file:///mnt/data/Neuroglancer_Data/2024_01_18_2024/21260B/Ch_647 --transformed_layer_source precomputed://file:///mnt/data/Neuroglancer_Data/2024_01_18/21260B/Ch_647_transformed --affine_path /home/user/21260B_Ch_561_registration/downloop_1_A.mat  --velocity_path /home/user/21260B_Ch_561_registration/downloop_1_v.mat\n",
    "```\n",
    "\n",
    "```\n",
    "python -m cloudreg.scripts.transform_data --target_layer_source precomputed://https://open-neurodata.s3.amazonaws.com/ara_2016/sagittal_10um/annotation_10um_2017 --transformed_layer_source precomputed://s3://smartspim-precomputed-volumes/2021_10_06/8557/atlas_to_target --affine_path /cis/home/tathey/8557_Ch_561_registration/downloop_1_A.mat  --velocity_path /cis/home/tathey/8557_Ch_561_registration/downloop_1_v.mat\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. View results in brain space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\*Inputs\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain 21268N: Collecting atlas space soma points from file: /home/user/brainlit/experiments/BrainLine/data/wholebrain-results/soma/atlas_somas_21268N/transformed_points0.json\n",
      "Brain 21268N: Collecting atlas space soma points from file: /home/user/brainlit/experiments/BrainLine/data/wholebrain-results/soma/atlas_somas_21268N/transformed_points1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding soma regions of brains: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "Finding soma regions of brains: 100%|██████████| 1/1 [00:00<00:00, 25.72it/s]\n",
      "Finding soma regions of brains: 100%|██████████| 1/1 [00:00<00:00, 24.09it/s]\n"
     ]
    }
   ],
   "source": [
    "brain_ids = [\n",
    "    \"8557\",  # before aug 2022,\n",
    "    \"8555\",  # before aug 2022\n",
    "    \"8607\",  # before aug 2022\n",
    "    \"8606\",  # before aug 2022\n",
    "    # \"8477\",\n",
    "    # \"8531\",\n",
    "    \"8608\",  # before aug 2022\n",
    "    # \"8529\",\n",
    "    # \"8454\",\n",
    "    \"MPRRabies\",\n",
    "    \"969\",\n",
    "    \"892\",\n",
    "    \"MS37\",\n",
    "    \"MS36\",\n",
    "    \"MS25_v2\",\n",
    "    \"MS23\",\n",
    "    \"MS22\",\n",
    "    \"MS50_v2\",\n",
    "    \"MS39\",\n",
    "    \"MS21\",\n",
    "    \"1252B\",\n",
    "    \"8030R\",\n",
    "    \"5573N\",\n",
    "    \"21260L\",\n",
    "    \"21260B\",\n",
    "    \"21260R\",\n",
    "    \"21268N\",\n",
    "    \"38035L\",\n",
    "    \"274L\",\n",
    "    \"257R\",\n",
    "    \"028L\"\n",
    "]\n",
    "\n",
    "brain_ids = [\"21268N\"] # \"21260R\", \"028L\"\n",
    "\n",
    "colors = {\n",
    "    \"tph2 vglut3\": \"blue\",\n",
    "    \"tph2 gad2\": \"red\",\n",
    "    \"gad2 vgat\": \"green\",\n",
    "}  # colors for different genotypes\n",
    "symbols = [\n",
    "    \"arrow\",\n",
    "    \"clobber\",\n",
    "    \"cross\",\n",
    "    \"diamond\",\n",
    "    \"disc\",\n",
    "    \"hbar\",\n",
    "    \"ring\",\n",
    "    \"square\",\n",
    "    \"star\",\n",
    "    \"tailed_arrow\",\n",
    "    \"triangle_down\",\n",
    "    \"triangle_up\",\n",
    "    \"vbar\",\n",
    "    \"x\",\n",
    "]\n",
    "fold_on = False\n",
    "ontology_file = (\n",
    "    brainlit_path / \"brainlit\" / \"BrainLine\" / \"data\" / \"ara_structure_ontology.json\"\n",
    ")\n",
    "ontology_fixes = (\n",
    "    brainlit_path / \"brainlit\" / \"BrainLine\" / \"data\" / \"open-nd-ara-fixes.json\"\n",
    ")\n",
    "\n",
    "sd = SomaDistribution(\n",
    "    brain_ids=brain_ids,\n",
    "    data_file=data_file,\n",
    "    ontology_file=ontology_file,\n",
    "    fixes_file=ontology_fixes,\n",
    "    bootstrap=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "custom_regions = [688, 1097, 549, 354, 512, 477, 313]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show detections in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Relabeling slice: 100%|██████████| 135/135 [00:00<00:00, 1539.45it/s]\n",
      "Processing labels: 100%|██████████| 25/25 [00:00<00:00, 96.11it/s]\n",
      "Processing brains in z=600: 100%|██████████| 27/27 [00:01<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 08:32:48.671: GtkDialog mapped without a transient parent. This is discouraged.\n",
      "Gtk-Message: 08:33:19.953: GtkDialog mapped without a transient parent. This is discouraged.\n"
     ]
    }
   ],
   "source": [
    "v = sd.napari_coronal_section(z=600, subtype_colors=colors, symbols=symbols, fold_on=True, custom_regions=custom_regions)\n",
    "v.layers[\"Heatmap\"].contrast_limits=(0, 0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/matt-coronals/\"\n",
    "z_size = 1320\n",
    "\n",
    "for z in tqdm(np.arange(100, 500, 100)):\n",
    "    fname = dir + f\"{brain}_{z}.tif\"\n",
    "    v = sd.napari_coronal_section(\n",
    "        z=z, subtype_colors=colors, symbols=symbols, fold_on=True, custom_regions=custom_regions\n",
    "    )\n",
    "    v.layers[\"Heatmap\"].contrast_limits=(0, 0.0005)\n",
    "    # im = v.screenshot(canvas_only=False)\n",
    "    # io.imsave(fname, im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brainrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping IndexError exception while plotting points in brainrender: index 270 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 264 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 264 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 265 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 274 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 264 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 274 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 271 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 265 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 332 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 272 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 266 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 271 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 275 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 293 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 292 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 267 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 275 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 269 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 290 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 267 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 270 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 280 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 273 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 268 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 168 is out of bounds for axis 1 with size 160\n",
      "Skipping IndexError exception while plotting points in brainrender: index 265 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 269 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 275 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 294 is out of bounds for axis 0 with size 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping IndexError exception while plotting points in brainrender: index 299 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 264 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 271 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 285 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 297 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 268 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 286 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 264 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 161 is out of bounds for axis 1 with size 160\n",
      "Skipping IndexError exception while plotting points in brainrender: index 276 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 273 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 283 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 291 is out of bounds for axis 0 with size 264\n",
      "Skipping IndexError exception while plotting points in brainrender: index 307 is out of bounds for axis 0 with size 264\n",
      "21268N - 2512 points\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Saving new screenshot at brainrender_screenshot_20241110_083501.png\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Saving new screenshot at brainrender_screenshot_20241110_083501.png\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd.brainrender_somas(subtype_colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write filtered files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/wholebrain_results/\"\n",
    ")\n",
    "for brain_id in brain_ids:\n",
    "    dir_name = results_dir / f\"atlas_somas_{brain_id}\"\n",
    "    outname = dir_name / f\"atlas_interior_somas_{brain_id}.txt\"\n",
    "    atlas_file = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/ara/ara_10um.tif\"\n",
    "\n",
    "    dir_to_atlas_pts(dir_name, outname, atlas_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCorr test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.dcorr_test(subtype1=\"tph2 gad2\", subtype2=\"tph2 vglut3\", bin_size=[250, 250, 250])\n",
    "sd.dcorr_test(subtype1=\"tph2 gad2\", subtype2=\"gad2 vgat\", bin_size=[250, 250, 250])\n",
    "sd.dcorr_test(subtype1=\"gad2 vgat\", subtype2=\"tph2 vglut3\", bin_size=[250, 250, 250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Perm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain2paths = sd.brain2paths\n",
    "\n",
    "if \"filepath\" in brain2paths[\"atlas\"].keys():\n",
    "    vol_atlas = io.imread(brain2paths[\"atlas\"][\"filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "from skimage import measure\n",
    "\n",
    "group0 = \"tph2 gad2\"\n",
    "group1 = \"tph2 vglut3\"\n",
    "\n",
    "thresh = 0.2\n",
    "block_sz = 250  # microns\n",
    "props_shp = np.multiply(vol_atlas.shape, 10 / block_sz).astype(\"int\")\n",
    "\n",
    "\n",
    "def partition_somas(id):\n",
    "    props_mm = np.zeros(props_shp)\n",
    "    points = sd.atlas_points[id]\n",
    "    points = np.round(points * 10 / block_sz).astype(\"int\")\n",
    "    for pt in points:\n",
    "        if np.all(pt < props_shp):\n",
    "            props_mm[pt[0], pt[1], pt[2]] += 1\n",
    "\n",
    "    props_mm /= points.shape[0]\n",
    "    return props_mm\n",
    "\n",
    "\n",
    "ids = []\n",
    "groups = []\n",
    "props_mms = {}\n",
    "\n",
    "for brain_id in sd.brain_ids:\n",
    "    if sd.brain2paths[brain_id][\"subtype\"] == group0:\n",
    "        ids.append(brain_id)\n",
    "        groups.append(0)\n",
    "        props_mms[brain_id] = partition_somas(brain_id)\n",
    "    if sd.brain2paths[brain_id][\"subtype\"] == group1:\n",
    "        ids.append(brain_id)\n",
    "        groups.append(1)\n",
    "        props_mms[brain_id] = partition_somas(brain_id)\n",
    "\n",
    "combos = list(combinations(ids, np.sum(groups)))\n",
    "\n",
    "\n",
    "def compute_stat(combo, return_stats=False, verbose=False):\n",
    "    t_stats = np.zeros(props_shp)\n",
    "    for ix, iy, iz in np.ndindex(t_stats.shape):\n",
    "        sample0 = []\n",
    "        sample1 = []\n",
    "        for id in ids:\n",
    "            if id in combo:\n",
    "                sample1.append(props_mms[id][ix, iy, iz])\n",
    "            else:\n",
    "                sample0.append(props_mms[id][ix, iy, iz])\n",
    "        result = ttest_ind(sample0, sample1)\n",
    "        if result.pvalue < thresh and np.isfinite(result.statistic):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"{(ix, iy, iz)}: {np.mean(sample0):.2e} vs {np.mean(sample1):.2e} stat: {result.statistic : .2e}\"\n",
    "                )\n",
    "            t_stats[ix, iy, iz] = result.statistic\n",
    "\n",
    "    t_stats_pos = np.copy(t_stats)\n",
    "    t_stats_pos[t_stats_pos <= 0] = 0\n",
    "    t_stats_neg = np.copy(t_stats)\n",
    "    t_stats_neg[t_stats_neg >= 0] = 0\n",
    "    t_stats_neg *= -1\n",
    "\n",
    "    sums = []\n",
    "    for t_stats_side in [t_stats_pos, t_stats_neg]:\n",
    "        labels, num = measure.label(t_stats_side > 0, return_num=True)\n",
    "        for label in range(num):\n",
    "            sums.append(np.sum(t_stats_side[labels == label]))\n",
    "\n",
    "    if len(sums) == 0:\n",
    "        stat = 0\n",
    "    else:\n",
    "        stat = np.amax(sums)\n",
    "\n",
    "    if return_stats:\n",
    "        return stat, t_stats\n",
    "    else:\n",
    "        return stat\n",
    "\n",
    "\n",
    "stats = []\n",
    "\n",
    "stats = Parallel(n_jobs=4)(delayed(compute_stat)(combo) for combo in tqdm(combos))\n",
    "# for combo in tqdm(combos):\n",
    "#     stats.append(compute_stat(combo))\n",
    "\n",
    "combo_obs = [id for id, group in zip(ids, groups) if group == 1]\n",
    "stat_obs, t_stats = compute_stat(combo_obs, return_stats=True, verbose=False)\n",
    "\n",
    "pval = np.sum(stats > stat_obs) / len(stats)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(stats)\n",
    "ax.plot([stat_obs, stat_obs], [0, 20], c=\"r\", label=f\"pval={pval:.2f}\")\n",
    "ax.set_title(\n",
    "    f\"{group0} vs {group1} w/{len(combos)} permutations, blocksz: {block_sz} thresh {thresh}\"\n",
    ")\n",
    "ax.legend()\n",
    "\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brain in props_mms.keys():\n",
    "    data = props_mms[brain]\n",
    "    print(np.sum(data == 0) / data.size)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.hist(data.flatten())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1000\n",
    "\n",
    "slice = np.squeeze(vol_atlas[z, :, :])\n",
    "newslice, borders, half_width = sd._slicetolabels(slice, fold_on=False)\n",
    "\n",
    "v = napari.Viewer()\n",
    "v.add_image(\n",
    "    t_stats[int(z * 10 / block_sz), :, :], scale=[block_sz, block_sz], name=f\"t-stat\"\n",
    ")\n",
    "\n",
    "props_mms_0 = np.zeros(props_shp[1:])\n",
    "props_mms_1 = np.zeros(props_shp[1:])\n",
    "\n",
    "for id, group in zip(ids, groups):\n",
    "    if group == 0:\n",
    "        props_mms_0 += props_mms[id][int(z * 10 / block_sz), :, :]\n",
    "    else:\n",
    "        props_mms_1 += props_mms[id][int(z * 10 / block_sz), :, :]\n",
    "\n",
    "props_mms_0 /= len(ids) - np.sum(groups)\n",
    "props_mms_1 /= np.sum(groups)\n",
    "\n",
    "v.add_image(\n",
    "    props_mms_0 - props_mms_1, scale=[block_sz, block_sz], name=f\"group 0 - group1 av\"\n",
    ")\n",
    "v.add_labels(borders * 2, scale=[10, 10], name=f\"atlas z={z}\")\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Display bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_coarse_part = [  # 8 regions from Weissbound et al., 2014\n",
    "    688,  # cerebral cortex\n",
    "    1097,\n",
    "    549,\n",
    "    354,\n",
    "    512,\n",
    "    477,\n",
    "]\n",
    "\n",
    "regions_coarse_part = [\n",
    "    688,  # cerebral cortex\n",
    "    477,  # striatum\n",
    "    803,  # pallidum\n",
    "    157,  # periventricular zone\n",
    "    290,  # hypothalamic lateral zone\n",
    "    467,  # hypothalamic medial zone\n",
    "    549,  # thalamus\n",
    "    512,  # cerebellum\n",
    "    157,  # inferior colliculus\n",
    "    1052,  # pedunculopontine\n",
    "    128,  # midbrain reticular nucleus\n",
    "    214,  # red nucleus\n",
    "    867,  # parabrachial nucleus\n",
    "    370,  # medulla motor related\n",
    "]  # allen atlas region IDs to be shown\n",
    "\n",
    "regions_coarse = [688, 1097, 549, 354, 512, 477, 1089, 313]  # midbrain\n",
    "\n",
    "regions_fine = [\n",
    "    95,  # agranular insular area\n",
    "    500,  # somatomotor\n",
    "    714,  # orbital area\n",
    "    972,  # prelimbic\n",
    "    453,  # somatosensory\n",
    "    44,  # infralimbic\n",
    "    186,  # lateral habenula\n",
    "    149,  # paraventricular nucleus of thalamus (part of polymodal assoc cortex)\n",
    "    864,  # sensorimotor thalamus\n",
    "    519,  # cerebellar nuclei\n",
    "    528,  # cerebellar cortex\n",
    "    290,  # hypothalamic lateral zone\n",
    "    141,  # periventricular region (preoptic nuclei)\n",
    "    946,  # posterior hypothalamic nucleus\n",
    "    797,  # zona incerta\n",
    "    331,  # mammillary body\n",
    "    364,  # parasubthalamic nucleus\n",
    "    38,  # paraventricular hypothalamic \"nucleus\n",
    "    223,  # arcuate hypothalamic nucleus\n",
    "    80,  # anterior hypothal nucleus\n",
    "    830,  # dorsomedial hypothal nuc.\n",
    "    693,  # ventromedial hypothal nuc.\n",
    "    470,  # subthalamic n\n",
    "    286,  # suprachiasmatic n\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    536,  # central amygdala\n",
    "    323,  # midbrain - motor\n",
    "    339,  # midbrain - sensory\n",
    "    348,  # midbrain - behavioral state\n",
    "]\n",
    "\n",
    "regions = [\n",
    "    500,  # somatomotor\n",
    "    453,  # somatosensory\n",
    "    972,  # prelimbic\n",
    "    44,  # infralimbic\n",
    "    477,\n",
    "    1089,\n",
    "    1097,  # hypothalamus\n",
    "    549,  # thalamus\n",
    "    186,  # lateral habenula\n",
    "    351,  # bed nuclei of stria terminalis\n",
    "    313,  # midbrain\n",
    "    512,  # cerebellum\n",
    "    771,  # pons\n",
    "    354,  # medulla\n",
    "]  # allen atlas region IDs to be shown\n",
    "# see: https://connectivity.brain-map.org/projection/experiment/480074702?imageId=480075280&initImage=TWO_PHOTON&x=17028&y=11704&z=3\n",
    "\n",
    "composite_regions = {\n",
    "    \"Amygdala\": [\n",
    "        131,\n",
    "        295,\n",
    "        319,\n",
    "        536,\n",
    "        780,\n",
    "    ],  # lateral, basolateral, basomedial, posterior\n",
    "    # \"Cortex (other)\": [184, 1057, 677, 31, 254, 22, 541, 922, 895], # frontal pole, gustatory, visceral, auditory, visual, anterior cingulate, retrosplenial, posterior parietal, temporal association, perirhinal, ectorhinal\n",
    "    # \"Substantia Nigra\": [615, 374, 374],\n",
    "    # \"Superior Colliculus\": [294, 302],\n",
    "}  # Custom composite allen regions where key is region name and value is list of allen regions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_ttest_ind(group_data1, group_data2, verbose=1, **stats_params):\n",
    "    group_data1_log = np.log(group_data1)\n",
    "    group_data2_log = np.log(group_data2)\n",
    "\n",
    "    return ttest_ind(group_data1_log, group_data2_log, **stats_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = StatTest(\n",
    "    _log_ttest_ind, test_long_name=\"Log t-test_ind\", test_short_name=\"log-t\"\n",
    ")\n",
    "test = \"Mann-Whitney\"\n",
    "# test = \"t-test_ind\"\n",
    "dep_var = \"Percent of Total Inputs (%)\"\n",
    "pad = 0\n",
    "\n",
    "region_names = []\n",
    "pcts = []\n",
    "counts = []\n",
    "ids = []\n",
    "subtypes = []\n",
    "subtype_counts = {}\n",
    "\n",
    "for brain_id in sd.brain_ids:\n",
    "    subtype = sd.brain2paths[brain_id][\"subtype\"]\n",
    "    if subtype in subtype_counts.keys():\n",
    "        subtype_counts[subtype] = subtype_counts[subtype] + 1\n",
    "    else:\n",
    "        subtype_counts[subtype] = 1\n",
    "\n",
    "    for region in regions:\n",
    "        count = np.amax([pad, sd.region_graph.nodes[region][brain_id]])\n",
    "        pct = count / sd.region_graph.nodes[997][brain_id] * 100\n",
    "        if pct == 0:\n",
    "            print(\n",
    "                f\"0 somas in region: {sd.region_graph.nodes[region]['name']} ({region}) for sample {brain_id} in group {subtype}\"\n",
    "            )\n",
    "        pcts.append(pct)\n",
    "        counts.append(sd.region_graph.nodes[region][brain_id])\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(sd.region_graph.nodes[region][\"name\"])\n",
    "    for composite_region in composite_regions.keys():\n",
    "        composite_region_regions = composite_regions[composite_region]\n",
    "        total = 0\n",
    "        for region in composite_region_regions:\n",
    "            total += sd.region_graph.nodes[region][brain_id]\n",
    "        pcts.append(total / sd.region_graph.nodes[997][brain_id] * 100)\n",
    "        counts.append(total)\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(composite_region)\n",
    "\n",
    "# append n to subtypes\n",
    "for i, subtype in enumerate(subtypes):\n",
    "    subtypes[i] = subtype + f\" (n={subtype_counts[subtype]})\"\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"Region\": region_names,\n",
    "    \"Brain ID\": ids,\n",
    "    \"Subtype\": subtypes,\n",
    "    \"Percent of Total Inputs (%)\": pcts,\n",
    "    \"Total Somas\": counts,\n",
    "}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "# bplot = sns.stripplot(x = \"Total Somas\", y = \"Region\", hue=\"Brain ID\", data=df)\n",
    "# bplot.set_xscale(\"log\")\n",
    "# plt.show()\n",
    "\n",
    "diffs = []\n",
    "for region_name in df[\"Region\"].unique():\n",
    "    diff = (\n",
    "        df[\n",
    "            (df[\"Region\"] == region_name)\n",
    "            & (df[\"Subtype\"] == f\"tph2 gad2 (n={subtype_counts['tph2 gad2']})\")\n",
    "        ][dep_var].mean()\n",
    "        - df[\n",
    "            (df[\"Region\"] == region_name)\n",
    "            & (df[\"Subtype\"] == f\"tph2 vglut3 (n={subtype_counts['tph2 vglut3']})\")\n",
    "        ][dep_var].mean()\n",
    "    )\n",
    "    diffs.append((region_name, diff))\n",
    "\n",
    "\n",
    "def second(e):\n",
    "    return e[1]\n",
    "\n",
    "\n",
    "diffs.sort(key=second, reverse=False)\n",
    "order = [e[0] for e in diffs]\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 8.6), dpi=300)\n",
    "fig_args = {\n",
    "    \"x\": dep_var,\n",
    "    \"y\": \"Region\",\n",
    "    \"hue\": \"Subtype\",\n",
    "    \"data\": df,\n",
    "    \"dodge\": True,\n",
    "    \"order\": order,\n",
    "}\n",
    "bplot = sns.stripplot(ax=ax, legend=False, **fig_args)\n",
    "fig_args[\"boxprops\"] = {\"facecolor\": \"none\"}\n",
    "bplot = sns.boxplot(ax=ax, **fig_args)\n",
    "\n",
    "bplot.set_xscale(\"log\")\n",
    "xtick_labels = bplot.get_yticklabels()\n",
    "bplot.set_yticklabels(labels=xtick_labels, rotation=30)\n",
    "\n",
    "# annotator\n",
    "fig_args[\"x\"] = \"Region\"\n",
    "fig_args[\"y\"] = dep_var\n",
    "pairs = []\n",
    "unq_subtypes = np.unique(subtypes)\n",
    "for region in regions + [\"Amygdala\"]:\n",
    "    if region == \"Amygdala\":\n",
    "        region_name = region\n",
    "    else:\n",
    "        region_name = sd.region_graph.nodes[region][\"name\"]\n",
    "\n",
    "    for i, subtype1 in enumerate(unq_subtypes):\n",
    "        for subtype2 in unq_subtypes[i + 1 :]:\n",
    "            pairs.append(((region_name, subtype1), (region_name, subtype2)))\n",
    "annot = Annotator(ax, pairs, **fig_args)\n",
    "annot.configure(\n",
    "    test=test, text_format=\"star\", loc=\"outside\", comparisons_correction=\"BH\"\n",
    ")\n",
    "fig_args[\"y\"] = \"Region\"\n",
    "fig_args[\"x\"] = dep_var\n",
    "annot.new_plot(bplot, orient=\"h\", plot=\"boxplot\", **fig_args)\n",
    "annot.apply_and_annotate()\n",
    "\n",
    "\n",
    "# markers = [\"o\", \"v\", \"^\", \"<\", \">\", \"s\", \"p\", \"*\", \"+\", \"x\", \"D\", \"h\", \"H\", \"o\", \"o\", \"o\", \"o\", \"o\", \"o\"]\n",
    "# jitters = {\"tph2 vglut3\": -0.26, \"tph2 gad2\": 0, \"gad2 vgat\": 0.26}\n",
    "# id2marker = {id: markers[idx] for idx, id in enumerate(brain_ids)}\n",
    "# for idx, line in df.iterrows():\n",
    "#     st = line[\"Subtype\"].split(\"(\")[0][:-1]\n",
    "\n",
    "#     x = line[\"Percent of Total Inputs (%)\"]\n",
    "#     y = order.index(line[\"Region\"]) + jitters[st]\n",
    "#     c = colors[st]\n",
    "#     marker = id2marker[line[\"Brain ID\"]]\n",
    "#     ax.scatter([x], [y], c=c, marker=marker)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig('/home/user/brainlit/experiments/BrainLine/images/soma-mw.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are regions mutually exclusive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regions = regions_coarse_part\n",
    "for r_src in regions:\n",
    "    # print(sd.region_graph.nodes[r_src][\"name\"])\n",
    "    for r_targ in regions:\n",
    "        if r_targ == r_src:\n",
    "            continue\n",
    "        elif nx.has_path(sd.region_graph, r_src, r_targ):\n",
    "            print(f\"{r_src} is parent of {r_targ}\")\n",
    "\n",
    "    # for brain in brain_ids:\n",
    "    #     if DG.nodes[r_src][brain] == 0:\n",
    "    #         print(\n",
    "    #             f\"Brain {brain} has no somas in {sd.region_graph.nodes[r_src]['name']}\"\n",
    "    #         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "DG = sd.region_graph\n",
    "\n",
    "for region in regions:\n",
    "    for subtype in colors.keys():\n",
    "        data = []\n",
    "        for brain in brain_ids:\n",
    "            if brain2paths[brain][\"subtype\"] == subtype:\n",
    "                total = DG.nodes[997][brain]\n",
    "                data.append(np.log(DG.nodes[region][brain] / total))\n",
    "                # data.append(DG.nodes[region][brain] / total)\n",
    "        if np.any([(not np.isfinite(d)) for d in data]):\n",
    "            print(f\"Zero detected in region {region} for subtype {subtype}\")\n",
    "        else:\n",
    "            _, p = shapiro(data)\n",
    "            if p < 0.05:\n",
    "                plt.hist(data)\n",
    "                plt.title(f\"{subtype} - {DG.nodes[region]['name']}: p={p}\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compositional Data Analysis\n",
    "- Means and variance\n",
    "- PCA\n",
    "- permutation test on distances between centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_coarse_part\n",
    "composite_region = {}\n",
    "\n",
    "region_names = []\n",
    "pcts = []\n",
    "counts = []\n",
    "ids = []\n",
    "subtypes = []\n",
    "subtype_counts = {}\n",
    "\n",
    "for brain_id in sd.brain_ids:\n",
    "    subtype = sd.brain2paths[brain_id][\"subtype\"]\n",
    "    if subtype in subtype_counts.keys():\n",
    "        subtype_counts[subtype] = subtype_counts[subtype] + 1\n",
    "    else:\n",
    "        subtype_counts[subtype] = 1\n",
    "\n",
    "    for region in regions:\n",
    "        count = np.amax([pad, sd.region_graph.nodes[region][brain_id]])\n",
    "        pct = count / sd.region_graph.nodes[997][brain_id] * 100\n",
    "        if pct == 0:\n",
    "            print(\n",
    "                f\"0 somas in region: {sd.region_graph.nodes[region]['name']} ({region}) for sample {brain_id} in group {subtype}\"\n",
    "            )\n",
    "        pcts.append(pct)\n",
    "        counts.append(sd.region_graph.nodes[region][brain_id])\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(sd.region_graph.nodes[region][\"name\"])\n",
    "    for composite_region in composite_regions.keys():\n",
    "        composite_region_regions = composite_regions[composite_region]\n",
    "        total = 0\n",
    "        for region in composite_region_regions:\n",
    "            total += sd.region_graph.nodes[region][brain_id]\n",
    "        pcts.append(total / sd.region_graph.nodes[997][brain_id] * 100)\n",
    "        counts.append(total)\n",
    "        subtypes.append(subtype)\n",
    "        ids.append(brain_id)\n",
    "        region_names.append(composite_region)\n",
    "\n",
    "# append n to subtypes\n",
    "for i, subtype in enumerate(subtypes):\n",
    "    subtypes[i] = subtype + f\" (n={subtype_counts[subtype]})\"\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"Region\": region_names,\n",
    "    \"Brain ID\": ids,\n",
    "    \"Subtype\": subtypes,\n",
    "    \"Percent of Total Inputs (%)\": pcts,\n",
    "    \"Total Somas\": counts,\n",
    "}\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ilr(vector):\n",
    "    y = np.zeros((len(vector) - 1,))\n",
    "    for im1, _ in enumerate(vector[:-1]):\n",
    "        i = im1 + 1\n",
    "        c = 1 / np.sqrt(i * (i + 1))\n",
    "        l = np.sum(np.log(vector[:i])) - i * np.log(vector[i])\n",
    "        y[im1] = c * l\n",
    "    return y\n",
    "\n",
    "\n",
    "def closure(vector, k=1):\n",
    "    c = [k * v / np.sum(vector) for v in vector]\n",
    "    return c\n",
    "\n",
    "\n",
    "def perturb(x, y):\n",
    "    return [i * j for i, j in zip(x, y)]\n",
    "\n",
    "\n",
    "def power(x, a):\n",
    "    return [i**a for i in x]\n",
    "\n",
    "\n",
    "def ilr_inv(vector):\n",
    "    for im1, y in enumerate(vector):\n",
    "        i = im1 + 1\n",
    "        ei = np.ones((len(vector) + 1))\n",
    "        ei[:i] = np.exp(1 / np.sqrt(i * (i + 1)))\n",
    "        ei[i] = np.exp(-np.sqrt(i / (i + 1)))\n",
    "        ei = closure(ei)\n",
    "        if im1 == 0:\n",
    "            x = closure(power(ei, y))\n",
    "        else:\n",
    "            x = closure(perturb(x, power(ei, y)))\n",
    "    return closure(x)\n",
    "\n",
    "\n",
    "def a_dot(x, y):\n",
    "    D = len(x)\n",
    "    assert len(y) == D\n",
    "    sum = 0\n",
    "    for j in range(D):\n",
    "        for i in range(j):\n",
    "            sum += np.log(x[i] / x[j]) * np.log(y[i] / y[j])\n",
    "    return sum / D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtypes = df[\"Subtype\"].unique()\n",
    "ids = df[\"Brain ID\"].unique()\n",
    "regions = df[\"Region\"].unique()\n",
    "\n",
    "ilrs = {}\n",
    "ids_names = {}\n",
    "\n",
    "for subtype in subtypes:\n",
    "    ys = []\n",
    "    ids_name = []\n",
    "    for id in ids:\n",
    "        if df[df[\"Brain ID\"] == id].iloc[0][\"Subtype\"] == subtype:\n",
    "            x = df[df[\"Brain ID\"] == id][\"Total Somas\"].tolist()\n",
    "            x = [np.amax([1, i]) for i in x]\n",
    "            y = ilr(x)\n",
    "            ys.append(y)\n",
    "            ids_name.append(id)\n",
    "    ilrs[subtype] = ys\n",
    "    ids_names[subtype] = ids_name\n",
    "\n",
    "id_to_ilr = {}\n",
    "for subtype in ids_names.keys():\n",
    "    for id, ilr_v in zip(ids_names[subtype], ilrs[subtype]):\n",
    "        id_to_ilr[id] = ilr_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subtypes = []\n",
    "df_regions = []\n",
    "df_means = []\n",
    "\n",
    "\n",
    "for subtype in ilrs.keys():\n",
    "    mean = ilr_inv(np.mean(ilrs[subtype], axis=0))\n",
    "\n",
    "    for region, mean in zip(regions, mean):\n",
    "        df_regions.append(region)\n",
    "        df_means.append(mean)\n",
    "        df_subtypes.append(subtype)\n",
    "\n",
    "data = {\"Mean\": df_means, \"Subtype\": df_subtypes, \"Region\": df_regions}\n",
    "\n",
    "sns.barplot(x=\"Mean\", y=\"Region\", hue=\"Subtype\", data=pd.DataFrame(data=data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "data_subtypes = []\n",
    "data_ids = []\n",
    "\n",
    "for subtype in ilrs.keys():\n",
    "    X += ilrs[subtype]\n",
    "    data_subtypes += len(ilrs[subtype]) * [subtype]\n",
    "    data_ids += ids_names[subtype]\n",
    "X = np.array(X)\n",
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "X_new = pca.fit_transform(X)\n",
    "vars = pca.explained_variance_ratio_\n",
    "pc1_lbl = f\"PC 1 ({vars[0]:.2f})\"\n",
    "pc2_lbl = f\"PC 2 ({vars[1]:.2f})\"\n",
    "data = {\n",
    "    pc1_lbl: X_new[:, 0],\n",
    "    pc2_lbl: X_new[:, 1],\n",
    "    \"Subtype\": data_subtypes,\n",
    "    \"ID\": data_ids,\n",
    "}\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), dpi=300)\n",
    "ax = sns.scatterplot(x=pc1_lbl, y=pc2_lbl, hue=\"Subtype\", data=df, ax=ax)\n",
    "# for i, row in df.iterrows():\n",
    "#     ax.text(row[pc1_lbl], row[pc2_lbl], row[\"ID\"], rotation=45)\n",
    "\n",
    "# ax.set_xlim(-1.5, -0.5)\n",
    "# ax.set_ylim(-1.5, -0.5)\n",
    "plt.show()\n",
    "#plt.savefig(\"/Users/thomasathey/Desktop/test.svg\", format=\"svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3)\n",
    "\n",
    "for i, (stype1, stype2) in enumerate(\n",
    "    zip(\n",
    "        [\"tph2 gad2\", \"tph2 gad2\", \"tph2 vglut3\"],\n",
    "        [\"tph2 vglut3\", \"gad2 vgat\", \"gad2 vgat\"],\n",
    "    )\n",
    "):\n",
    "    ax = axs[i]\n",
    "    brain_ids_stypes = []\n",
    "    sz = 0\n",
    "    dists = []\n",
    "\n",
    "    for brain in brain_ids:\n",
    "        if sd.brain2paths[brain][\"subtype\"] == stype1:\n",
    "            dist = id_to_ilr[brain]\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "            sz += 1\n",
    "    av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    dists = []\n",
    "    for brain in brain_ids:\n",
    "        if sd.brain2paths[brain][\"subtype\"] == stype2:\n",
    "            dist = id_to_ilr[brain]\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "    av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    dist_true = np.linalg.norm(np.subtract(av_dist1, av_dist2))\n",
    "\n",
    "    dist_perms = []\n",
    "\n",
    "    for combo in tqdm(combinations(brain_ids_stypes, sz)):\n",
    "        dists = []\n",
    "        for brain in combo:\n",
    "            dist = id_to_ilr[brain]\n",
    "            dists.append(dist)\n",
    "        av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        dists = []\n",
    "        for brain in brain_ids:\n",
    "            if brain not in combo:\n",
    "                if (\n",
    "                    sd.brain2paths[brain][\"subtype\"] == stype1\n",
    "                    or sd.brain2paths[brain][\"subtype\"] == stype2\n",
    "                ):\n",
    "                    dist = id_to_ilr[brain]\n",
    "                    dists.append(dist)\n",
    "        av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        \n",
    "        dist_perm = np.linalg.norm(np.subtract(av_dist1, av_dist2))\n",
    "\n",
    "        dist_perms.append(dist_perm)\n",
    "\n",
    "    p = np.sum(dist_perms >= dist_true) / len(dist_perms)\n",
    "    ax.hist(dist_perms)\n",
    "    ax.plot([dist_true, dist_true], [0, 15], c=\"r\", label=f\"pval={p:.2f}\")\n",
    "    ax.set_title(f\"{stype1} vs {stype2} w/{len(dist_perms)} permutations\")\n",
    "    ax.set_xlabel(\"Aitchison Distance between Means\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check atlas keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.BrainLine.util import _setup_atlas_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain2paths = sd.brain2paths\n",
    "\n",
    "if \"filepath\" in brain2paths[\"atlas\"].keys():\n",
    "    vol_atlas = io.imread(brain2paths[\"atlas\"][\"filepath\"])\n",
    "unq = np.unique(vol_atlas)\n",
    "\n",
    "\n",
    "G = _setup_atlas_graph(ontology_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in tqdm(unq):\n",
    "    try:\n",
    "        roi = G.nodes[val]\n",
    "    except KeyError:\n",
    "        if val != 0:\n",
    "            mask = vol_atlas == val\n",
    "            wher = np.where(mask)\n",
    "            print(\n",
    "                f\"region {val} not found with vol: {np.sum(mask)} e.g.{[wher[0][0],wher[1][0],wher[2][0]]}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many more samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, ttest_ind\n",
    "\n",
    "for region in df.Region.unique():\n",
    "    for i, subtype1 in enumerate(df.Subtype.unique()):\n",
    "        for j, subtype2 in enumerate(df.Subtype.unique()[i + 1 :]):\n",
    "            l1 = df[(df[\"Region\"] == region) & (df[\"Subtype\"] == subtype1)][\n",
    "                \"Percent of Total Inputs (%)\"\n",
    "            ].tolist()\n",
    "            l2 = df[(df[\"Region\"] == region) & (df[\"Subtype\"] == subtype2)][\n",
    "                \"Percent of Total Inputs (%)\"\n",
    "            ].tolist()\n",
    "\n",
    "            _, p = mannwhitneyu(l1, l2)\n",
    "            for i in range(10):\n",
    "                if p > 0.0047:\n",
    "                    if len(l1) > len(l2):\n",
    "                        l2.append(np.median(l2))\n",
    "                    else:\n",
    "                        l1.append(np.median(l1))\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                _, p = mannwhitneyu(l1, l2)\n",
    "            print(f\"{region}: {subtype1} vs {subtype2}: need {i} more added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.region_barchart(regions, composite_regions=composite_regions, normalize_region=872)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within group Chi-sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype = \"tph2 gad2\"\n",
    "regions = regions_coarse_part\n",
    "\n",
    "subtype_brains = []\n",
    "for brain_id in sd.brain_ids:\n",
    "    if sd.brain2paths[brain_id][\"subtype\"] == subtype:\n",
    "        subtype_brains.append(brain_id)\n",
    "\n",
    "sd.region_graph\n",
    "\n",
    "cont_table = np.zeros((len(subtype_brains), len(regions)))\n",
    "\n",
    "for bi, brain_id in enumerate(subtype_brains):\n",
    "    for ri, region in enumerate(regions):\n",
    "        cont_table[bi, ri] = sd.region_graph.nodes[region][brain_id]\n",
    "\n",
    "print(f\"{np.sum(cont_table > 5)/cont_table.size} are > 5\")\n",
    "chi2_contingency(cont_table)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=300)\n",
    "ax.pie(\n",
    "    cont_table[0, :],\n",
    "    labels=[sd.region_graph.nodes[r][\"name\"] for r in regions],\n",
    "    textprops={\"color\": \"w\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-sq test and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain2paths = sd.brain2paths\n",
    "region_graph = sd.region_graph\n",
    "\n",
    "data_mat = np.zeros((len(brain_ids), len(regions_coarse)))\n",
    "\n",
    "\n",
    "subtype2idx = {\"tph2 vglut3\": 0, \"tph2 gad2\": 1, \"gad2 vgat\": -1}\n",
    "\n",
    "for bn, brain_id in enumerate(brain_ids):\n",
    "    for rn, region in enumerate(regions_coarse):\n",
    "        data_mat[bn, rn] = region_graph.nodes[region][brain_id]\n",
    "\n",
    "random.shuffle(subtypes)\n",
    "\n",
    "cont_table = np.zeros((len(regions_coarse), 2))\n",
    "for bn, (brain_id, subtype) in enumerate(zip(brain_ids, subtypes)):\n",
    "    subtype = brain2paths[brain_id][\"subtype\"]\n",
    "    if subtype2idx[subtype] >= 0:\n",
    "        cont_table[:, subtype2idx[subtype]] += data_mat[bn, :].T\n",
    "\n",
    "\n",
    "print(np.sum(cont_table > 5) / cont_table.size)\n",
    "chi2_contingency(cont_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain2paths = sd.brain2paths\n",
    "region_graph = sd.region_graph\n",
    "\n",
    "data_mat = np.zeros((len(brain_ids), len(regions)))\n",
    "\n",
    "\n",
    "for bn, brain_id in enumerate(brain_ids):\n",
    "    for rn, region in enumerate(regions):\n",
    "        data_mat[bn, rn] = (\n",
    "            region_graph.nodes[region][brain_id] / region_graph.nodes[997][brain_id]\n",
    "        )\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2 = pca.fit_transform(data_mat)\n",
    "\n",
    "df_pca = {\n",
    "    \"PC 1\": X_2[:, 0],\n",
    "    \"PC 2\": X_2[:, 1],\n",
    "    \"Genotype\": [brain2paths[brain_id][\"subtype\"] for brain_id in brain_ids],\n",
    "    \"Brain ID\": brain_ids,\n",
    "}\n",
    "df_pca = pd.DataFrame(data=df_pca)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(data=df_pca, x=\"PC 1\", y=\"PC 2\", hue=\"Genotype\", ax=ax)\n",
    "\n",
    "\n",
    "for i in range(df_pca.shape[0]):\n",
    "    sign = 2 * (df_pca[\"PC 2\"][i] > 0) - 1\n",
    "    plt.text(\n",
    "        x=df_pca[\"PC 1\"][i] + 0.01,\n",
    "        y=df_pca[\"PC 2\"][i] + sign * 0.001,\n",
    "        s=df_pca[\"Brain ID\"][i],\n",
    "        fontdict=dict(color=\"black\", size=20),\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Input Distribution PCA with Explained Variance: {pca.explained_variance_ratio_}\"\n",
    ")\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Div permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(brain_id, regions, sd):\n",
    "    total = sd.region_graph.nodes[997][brain_id]\n",
    "    dist = []\n",
    "    for region in regions:\n",
    "        dist.append(sd.region_graph.nodes[region][brain_id])\n",
    "    dist.append(total - np.sum(dist))\n",
    "\n",
    "    return np.divide(dist, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regions_coarse_part\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "\n",
    "for i, (stype1, stype2) in enumerate(\n",
    "    zip(\n",
    "        [\"tph2 gad2\", \"tph2 gad2\", \"tph2 vglut3\"],\n",
    "        [\"tph2 vglut3\", \"gad2 vgat\", \"gad2 vgat\"],\n",
    "    )\n",
    "):\n",
    "    ax = axs[i]\n",
    "    brain_ids_stypes = []\n",
    "    sz = 0\n",
    "    dists = []\n",
    "\n",
    "    for brain in brain_ids:\n",
    "        if sd.brain2paths[brain][\"subtype\"] == stype1:\n",
    "            dist = get_dist(brain, regions, sd)\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "            sz += 1\n",
    "    av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    dists = []\n",
    "    for brain in brain_ids:\n",
    "        if sd.brain2paths[brain][\"subtype\"] == stype2:\n",
    "            dist = get_dist(brain, regions, sd)\n",
    "            dists.append(dist)\n",
    "            brain_ids_stypes.append(brain)\n",
    "    av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "    kl_div_true = np.sum(rel_entr(av_dist1, av_dist2)) + np.sum(\n",
    "        rel_entr(av_dist2, av_dist1)\n",
    "    )\n",
    "    if not np.isfinite(kl_div_true) or kl_div_true < 0:\n",
    "        print(f\"Invalid distance between distributions: {av_dist1} and {av_dist2}\")\n",
    "    kl_divs = []\n",
    "\n",
    "    for combo in tqdm(combinations(brain_ids_stypes, sz)):\n",
    "        dists = []\n",
    "        for brain in combo:\n",
    "            dist = get_dist(brain, regions, sd)\n",
    "            dists.append(dist)\n",
    "        av_dist1 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        dists = []\n",
    "        for brain in brain_ids:\n",
    "            if brain not in combo:\n",
    "                if (\n",
    "                    sd.brain2paths[brain][\"subtype\"] == stype1\n",
    "                    or sd.brain2paths[brain][\"subtype\"] == stype2\n",
    "                ):\n",
    "                    dist = get_dist(brain, regions, sd)\n",
    "                    dists.append(dist)\n",
    "        av_dist2 = np.mean(np.array(dists), axis=0)\n",
    "\n",
    "        kl_div_c = np.sum(rel_entr(av_dist1, av_dist2)) + np.sum(\n",
    "            rel_entr(av_dist2, av_dist1)\n",
    "        )\n",
    "\n",
    "        if not np.isfinite(kl_div_c) or kl_div_c < 0:\n",
    "            print(f\"Invalid distance between distributions: {av_dist1} and {av_dist2}\")\n",
    "        kl_divs.append(kl_div_c)\n",
    "\n",
    "    p = np.sum(kl_divs > kl_div_true) / len(kl_divs)\n",
    "    ax.hist(kl_divs)\n",
    "    ax.plot([kl_div_true, kl_div_true], [0, 15], c=\"r\", label=f\"pval={p:.2f}\")\n",
    "    ax.set_title(f\"{stype1} vs {stype2} w/{len(kl_divs)} permutations\")\n",
    "    ax.legend()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(25)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hemisphere plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = []\n",
    "region_data = []\n",
    "left_count_data = []\n",
    "right_count_data = []\n",
    "gtypes = []\n",
    "\n",
    "for region in regions:\n",
    "    for brain in brain_ids:\n",
    "        sample_data.append(brain)\n",
    "        region_data.append(region)\n",
    "        left_count_data.append(sd.region_graph_l.nodes[region][brain])\n",
    "        right_count_data.append(sd.region_graph_r.nodes[region][brain])\n",
    "        gtypes.append(sd.brain2paths[brain][\"subtype\"])\n",
    "data = {\n",
    "    \"Sample\": sample_data,\n",
    "    \"Region\": region_data,\n",
    "    \"Somas Left\": left_count_data,\n",
    "    \"Somas Right\": right_count_data,\n",
    "    \"Subtype\": gtypes,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "fig, axs = plt.subplots(3, 9)\n",
    "\n",
    "for region, ax in zip(regions, axs.flatten()):\n",
    "    for gtype in df[\"Subtype\"].unique():\n",
    "        df_r = df[df[\"Region\"] == region]\n",
    "        df_r = df_r[df_r[\"Subtype\"] == gtype]\n",
    "        graph = sns.regplot(data=df_r, x=\"Somas Left\", y=\"Somas Right\", ax=ax)\n",
    "        r, p = pearsonr(df_r[\"Somas Left\"], df_r[\"Somas Right\"])\n",
    "        txt = f'{sd.region_graph.nodes[region][\"name\"]}*: '  # f'{sd.region_graph.nodes[region][\"name\"]}: r={r:.2f}, p={p:.2f}'\n",
    "        if p < 0.05:\n",
    "            txt = txt + gtype\n",
    "    ax.title.set_text(txt)\n",
    "\n",
    "\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(35)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create local volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = CloudVolume(\n",
    "    \"precomputed://s3://smartspim-precomputed-volumes/2022_03_10/8531/Ch_647_iso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvol = vol[256 * 11 : 256 * 12, 256 * 16 : 256 * 17, 256 * 6 : 256 * 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"image\",\n",
    "    data_type=\"uint16\",  # Channel images might be 'uint8'\n",
    "    encoding=\"raw\",  # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution=vol.resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=vol.voxel_offset,\n",
    "    chunk_size=vol.chunk_size,  # units are voxels\n",
    "    volume_size=vol.volume_size,  # e.g. a cubic millimeter dataset\n",
    ")\n",
    "\n",
    "vol_ex = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example\",\n",
    "    info=info,\n",
    "    compress=False,\n",
    ")\n",
    "vol_ex.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_ex[256 * 11 : 256 * 12, 256 * 16 : 256 * 17, 256 * 6 : 256 * 7] = subvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = CloudVolume(\n",
    "    \"precomputed://file:///Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/brainlit/BrainLine/data/example/endogenous\",\n",
    "    fill_missing=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post detections to ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_id = \"8606\"\n",
    "all_somas_pth = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/detection_soma/wholebrain_results/all_somas_{brain_id}.txt\"\n",
    "\n",
    "from brainlit.BrainLine.data.soma_data import brain2paths\n",
    "from cloudreg.scripts.transform_points import NGLink\n",
    "from cloudreg.scripts.visualization import create_viz_link_from_json\n",
    "\n",
    "coords = []\n",
    "coords_target_space = []\n",
    "file1 = open(all_somas_pth, \"r\")\n",
    "lines = file1.readlines()\n",
    "for line in tqdm(lines, desc=\"parsing coordinates\", leave=False):\n",
    "    if line != \"\\n\":\n",
    "        line = \" \".join(line.split())\n",
    "        elements = line.split(\",\")\n",
    "        coord = [elements[0][1:], elements[1], elements[2][:-1]]\n",
    "\n",
    "        coords.append([float(e.strip()) for e in coord])\n",
    "\n",
    "coords = coords[15000:]\n",
    "print(f\"{len(coords)} detections\")\n",
    "\n",
    "ng_link = brain2paths[brain_id][\"val_info\"][\"url\"]\n",
    "viz_link = NGLink(ng_link.split(\"json_url=\")[-1])\n",
    "ngl_json = viz_link._json\n",
    "\n",
    "ngl_json[\"layers\"] = [\n",
    "    layer for layer in ngl_json[\"layers\"] if layer[\"type\"] != \"annotation\"\n",
    "]\n",
    "\n",
    "ngl_json[\"layers\"].append(\n",
    "    {\"type\": \"annotation\", \"points\": coords, \"name\": \"detected_somas\"}\n",
    ")\n",
    "viz_link = create_viz_link_from_json(\n",
    "    ngl_json, neuroglancer_link=\"https://viz.neurodata.io/?json_url=\"\n",
    ")\n",
    "print(f\"Viz link with detections: {viz_link}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('docs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
