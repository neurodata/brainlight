{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1. install python (3.8) and git\n",
    "2. install virtualenv e.g. with `<path to python> -m to pip install virtualenv`\n",
    "3. create a virtual environment that uses python 3.8 using virtualenv e.g. with `<path to python> -m virtualenv \"<path to virtual environment>\"`\n",
    "4. activate the virtual environment e.g. on windows with `.\\<pathto env>\\Scripts\\activate`\n",
    "5. install vscode and python extension\n",
    "6. git clone brainlit (https://github.com/neurodata/brainlit) and neuroglancer (https://github.com/google/neuroglancer)\n",
    "7. install brainlit from source e.g. `pip install -e .` in brainlit folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.write import czi_to_zarr, zarr_to_omezarr\n",
    "import zarr\n",
    "from cloudvolume import CloudVolume\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert czi to zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data/\"  # \"C:\\\\Users\\\\Sriram Sudarsanam\\\\Desktop\\\\NeuroglancerTrial\\\\\"\n",
    "czi_path = f\"{project_path}test.czi\"  # path to czi image\n",
    "out_dir = f\"{project_path}\"  # path to directory where zarr should be made, should end in slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 2 zarrs of shape 1998x2009x40 from czi with dims [{'X': (0, 2009), 'Y': (0, 1998), 'Z': (0, 40), 'C': (0, 2), 'T': (0, 1), 'V': (0, 1), 'B': (0, 1)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving slices foreground...: 100%|██████████| 4/4 [00:00<00:00, 58.38it/s]\n",
      "Saving slices background...: 100%|██████████| 4/4 [00:00<00:00, 2512.69it/s]\n"
     ]
    }
   ],
   "source": [
    "zarr_paths = czi_to_zarr(czi_path=czi_path, out_dir=out_dir, fg_channel=1, parallel=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert zarr to ome-zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"{project_path}fg_ome.zarr\"  # path of ome zarr to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting /Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data/fg.zarr to ome-zarr\n"
     ]
    }
   ],
   "source": [
    "zarr_to_omezarr(zarr_path=zarr_paths[0], out_path=out_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View ome-zarr on neuroglancer\n",
    "\n",
    "1. Use https://github.com/google/neuroglancer/blob/master/cors_webserver.py to serve the data e.g. `python cors_webserver.py -d \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data\" -p 9010`\n",
    "2. Launch neuroglancer app e.g. https://neuroglancer-demo.appspot.com\n",
    "3. Add layer to neuroglancer app e.g. zarr://http://127.0.0.1:9010/sriram-adipo-brain1-im3/fg_ome.zarr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add trace layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_dir = f\"{out_dir}traces/\"\n",
    "z = zarr.open(out_dir + \"fg.zarr\")\n",
    "volume_size = z.shape\n",
    "chunk_size = z.chunks\n",
    "resolution = [1000000000, 1000000000, 1000000000]\n",
    "\n",
    "outpath = f\"precomputed://file://{traces_dir}\"\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"segmentation\",\n",
    "    data_type=\"uint16\",\n",
    "    encoding=\"raw\",\n",
    "    resolution=resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=[0, 0, 0],  # x,y,z offset in voxels from the origin\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size=chunk_size,  # units are voxels\n",
    "    volume_size=volume_size,  # e.g. a cubic millimeter dataset\n",
    "    skeletons=\"skeletons\",\n",
    ")\n",
    "vol = CloudVolume(outpath, info=info, compress=False)\n",
    "vol.commit_info()\n",
    "vol.skeleton.meta.commit_info()\n",
    "\n",
    "# remove vertex type attribute because it is a uint8 and incompatible with neuroglancer\n",
    "info_path = f\"{traces_dir}skeletons/info\"\n",
    "with open(info_path) as f:\n",
    "    data = json.load(f)\n",
    "    for i, attr in enumerate(data[\"vertex_attributes\"]):\n",
    "        if attr[\"id\"] == \"vertex_types\":\n",
    "            data[\"vertex_attributes\"].pop(i)\n",
    "            break\n",
    "\n",
    "with open(info_path, \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to trace\n",
    "Use `trace.py` to trace neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Activate ViterBrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io \n",
    "from brainlit.algorithms.generate_fragments.state_generation import state_generation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = out_dir + \"fg.zarr\"\n",
    "ilastik_program_path = \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"\n",
    "ilastik_project_path = out_dir + \"ex_fg.ilp\"\n",
    "chunk_size = [z_im.chunks[0], z_im.chunks[1], 40]\n",
    "data_bin = out_dir + \"data_bin/\"\n",
    "\n",
    "prob_path = out_dir + \"probs.zarr\"\n",
    "fragment_path = out_dir + \"labels.zarr\"\n",
    "tiered_path = out_dir + \"tiered.zarr\"\n",
    "states_path = out_dir + \"nx.pickle\"\n",
    "\n",
    "sg = state_generation(image_path = image_path,\n",
    "                      new_layers_dir = out_dir,\n",
    "                      ilastik_program_path = ilastik_program_path,\n",
    "                      ilastik_project_path = ilastik_project_path,\n",
    "                      chunk_size=chunk_size,\n",
    "                      parallel=6,\n",
    "                    #   prob_path = prob_path,\n",
    "                    #   fragment_path=fragment_path,\n",
    "                    #   tiered_path=tiered_path,\n",
    "                    #   states_path = states_path\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 46.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image of shape (1998, 2009, 40) with chunks (200, 200, 10) into probability image /Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data/probs.zarr of shape (1998, 2009, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Ilastik Predictions: 100%|██████████| 2/2 [04:43<00:00, 141.88s/it]\n"
     ]
    }
   ],
   "source": [
    "sg.predict(data_bin=data_bin)\n",
    "sg.compute_frags()\n",
    "sg.compute_soma_lbls()\n",
    "sg.compute_image_tiered()\n",
    "sg.compute_states()\n",
    "sg.compute_edge_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_im = zarr.open(image_path)\n",
    "subvol = z[:40,:40,:40]\n",
    "io.imsave(out_dir + \"/train.tif\", subvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from brainlit.algorithms.connect_fragments.viterbrain import explain_viterbrain\n",
    "\n",
    "with open(\"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data/viterbrain.pickle\", \"rb\") as handle:\n",
    "    vb = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 states\n",
      "7 coordinates\n",
      "0: [558, 549, 4] f1176 \n",
      "1: [534, 510, 15] f1176 s2351\n",
      "2: [526, 524, 9] f1154 s2351\n",
      "Transition: 2351->2307: [(2351, 2294, None), (2351, 2295, None), (2351, 2306, None), (2351, 2307, None), (2351, 2344, None), (2351, 2346, None), (2351, 2357, None), (2351, 2373, None), (2351, 2374, None), (2351, 2380, None), (2351, 2381, None), (2351, 2382, None), (2351, 2383, None), (2351, 2386, None), (2351, 2387, None), (2351, 2388, None), (2351, 2397, None), (2351, 2399, None)]\n",
      "2: [526, 524, 9] f1154 s2307\n",
      "3: [512, 526, 10] f1154 s2307\n",
      "Transition: 2307->2343: [(2307, 2285, None), (2307, 2294, None), (2307, 2295, None), (2307, 2296, None), (2307, 2297, None), (2307, 2310, None), (2307, 2343, None), (2307, 2344, None), (2307, 2345, None), (2307, 2346, None), (2307, 2350, None), (2307, 2373, None), (2307, 2374, None), (2307, 2375, None), (2307, 2380, None), (2307, 2381, None), (2307, 2396, None), (2307, 2397, None)]\n",
      "3: [512, 526, 10] f1154 s2343\n",
      "4: [498, 510, 4] f1172 s2343\n",
      "5: [482, 498, 2] f1172 s2343\n"
     ]
    }
   ],
   "source": [
    "explain_viterbrain(vb, [558, 549, 4], [480, 517, 2], [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vs fragments [1176, 1173, 1172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
