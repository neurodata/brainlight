{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1. install python (3.8) and git\n",
    "2. install virtualenv e.g. with `<path to python> -m to pip install virtualenv`\n",
    "3. create a virtual environment that uses python 3.8 using virtualenv e.g. with `<path to python> -m virtualenv \"<path to virtual environment>\"`\n",
    "4. activate the virtual environment e.g. on windows with `.\\<pathto env>\\Scripts\\activate`\n",
    "5. install vscode and python extension\n",
    "6. git clone brainlit (https://github.com/neurodata/brainlit) and neuroglancer (https://github.com/google/neuroglancer)\n",
    "7. install brainlit from source e.g. `pip install -e .` in brainlit folder \n",
    "8. Place `test-czi.zip` file in `brainlit/experiments/sriramg/data/` and unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.write import czi_to_zarr, zarr_to_omezarr\n",
    "import zarr\n",
    "from cloudvolume import CloudVolume\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert czi to zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data/test-czi\"  # \"E:\\\\Projects\\\\KolodkinLab\\\\Sriram\\\\brainlit-tracing\\\\brainlit\\\\experiments\\\\sriram\\\\data\\\\\" \"C:\\\\Users\\\\Sriram Sudarsanam\\\\Desktop\\\\NeuroglancerTrial\\\\\"\n",
    "\n",
    "project_path = Path(project_path)\n",
    "czi_path = project_path / \"test.czi\"  # path to czi image\n",
    "out_dir = (\n",
    "    project_path  # path to directory where zarr should be made, should end in slash\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_paths = czi_to_zarr(czi_path=czi_path, out_dir=out_dir, fg_channel=1, parallel=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert zarr to ome-zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = project_path / \"fg_ome.zarr\"  # path of ome zarr to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_to_omezarr(zarr_path=zarr_paths[0], out_path=out_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View ome-zarr on neuroglancer\n",
    "\n",
    "1. Use https://github.com/google/neuroglancer/blob/master/cors_webserver.py to serve the data e.g. `python cors_webserver.py -d \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data\" -p 9010`\n",
    "2. Launch neuroglancer app e.g. https://neuroglancer-demo.appspot.com\n",
    "3. Add layer to neuroglancer app e.g. zarr://http://127.0.0.1:9010/sriram-adipo-brain1-im3/fg_ome.zarr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add trace layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_dir = out_dir / \"traces\"\n",
    "z = zarr.open_array(out_dir / \"fg_ome.zarr\" / \"0\")\n",
    "volume_size = z.shape\n",
    "chunk_size = z.chunks\n",
    "resolution = [1000000000, 1000000000, 1000000000]\n",
    "\n",
    "outpath = f\"precomputed://file://\" + str(traces_dir)\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"segmentation\",\n",
    "    data_type=\"uint16\",\n",
    "    encoding=\"raw\",\n",
    "    resolution=resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=[0, 0, 0],  # x,y,z offset in voxels from the origin\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size=chunk_size,  # units are voxels\n",
    "    volume_size=volume_size,  # e.g. a cubic millimeter dataset\n",
    "    skeletons=\"skeletons\",\n",
    ")\n",
    "vol = CloudVolume(outpath, info=info, compress=False)\n",
    "vol.commit_info()\n",
    "vol.skeleton.meta.commit_info()\n",
    "\n",
    "# remove vertex type attribute because it is a uint8 and incompatible with neuroglancer\n",
    "info_path = traces_dir / \"skeletons/info\"\n",
    "with open(info_path) as f:\n",
    "    data = json.load(f)\n",
    "    for i, attr in enumerate(data[\"vertex_attributes\"]):\n",
    "        if attr[\"id\"] == \"vertex_types\":\n",
    "            data[\"vertex_attributes\"].pop(i)\n",
    "            break\n",
    "\n",
    "with open(info_path, \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to trace\n",
    "Use `trace.py` to trace neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Activate ViterBrain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to download ilastik: https://www.ilastik.org/download.html\n",
    "\n",
    "Update `ilastik_program_path` below, e.g. for Mac/Linux use the path to run_ilastik.sh, for Windows, use the path to ilastik.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.algorithms.generate_fragments.state_generation import state_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilastik_program_path = \"/Applications/ilastik-1.4.0b21-OSX.app/Contents/ilastik-release/run_ilastik.sh\"  # path to ilastik executable e.g. for windows something like \"\\Program Files\\ilastik-1.3.2\\ilastik.exe\"\n",
    "\n",
    "\n",
    "image_path = out_dir / \"fg_ome.zarr\" / \"0\"\n",
    "z_im = zarr.open_array(image_path)\n",
    "ilastik_project_path = out_dir / \"ex_fg.ilp\"\n",
    "chunk_size = [c * 2 for c in z_im.chunks]\n",
    "data_bin = out_dir / \"data_bin/\"\n",
    "\n",
    "prob_path = out_dir / \"probs.zarr\"\n",
    "fragment_path = out_dir / \"labels.zarr\"\n",
    "tiered_path = out_dir / \"tiered.zarr\"\n",
    "states_path = out_dir / \"nx.pickle\"\n",
    "\n",
    "sg = state_generation(\n",
    "    image_path=image_path,\n",
    "    new_layers_dir=out_dir,\n",
    "    ilastik_program_path=ilastik_program_path,\n",
    "    ilastik_project_path=ilastik_project_path,\n",
    "    chunk_size=chunk_size,\n",
    "    parallel=6,\n",
    "    #   prob_path = prob_path,\n",
    "    #   fragment_path=fragment_path,\n",
    "    #   tiered_path=tiered_path,\n",
    "    #   states_path = states_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.predict(data_bin=data_bin)\n",
    "sg.compute_frags()\n",
    "sg.compute_soma_lbls()\n",
    "sg.compute_image_tiered()\n",
    "sg.compute_states()\n",
    "sg.compute_edge_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "z_im = zarr.open(image_path)\n",
    "subvol = z[:40, :40, :40]\n",
    "io.imsave(out_dir + \"/train.tif\", subvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from brainlit.algorithms.connect_fragments.viterbrain import explain_viterbrain\n",
    "\n",
    "with open(\n",
    "    \"/Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/sriram/data/viterbrain.pickle\",\n",
    "    \"rb\",\n",
    ") as handle:\n",
    "    vb = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_viterbrain(vb, [558, 549, 4], [480, 517, 2], [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vs fragments [1176, 1173, 1172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
