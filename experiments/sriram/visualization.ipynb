{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1. install python (3.8) and git\n",
    "2. install virtualenv e.g. with `<path to python> -m to pip install virtualenv`\n",
    "3. create a virtual environment that uses python 3.8 using virtualenv e.g. with `<path to python> -m virtualenv \"<path to virtual environment>\"`\n",
    "4. activate the virtual environment e.g. on windows with `.\\<pathto env>\\Scripts\\activate`\n",
    "5. install vscode and python extension\n",
    "6. git clone brainlit (https://github.com/neurodata/brainlit) and neuroglancer (https://github.com/google/neuroglancer)\n",
    "7. install brainlit from source e.g. `pip install -e .` in brainlit folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.write import czi_to_zarr, zarr_to_omezarr\n",
    "import zarr\n",
    "from cloudvolume import CloudVolume\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert czi to zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/cis/project/sriram/\" # \"C:\\\\Users\\\\Sriram Sudarsanam\\\\Desktop\\\\NeuroglancerTrial\\\\\"\n",
    "czi_path = f\"{project_path}Sriram/SS IUE 175 SNOVA RFP single channel AdipoClear Brain 1 full Image 3.czi\" # path to czi image\n",
    "out_dir = f\"{project_path}ng_data/sriram-adipo-brain1-im3/\" # path to directory where zarr should be made, should end in slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_paths = czi_to_zarr(czi_path=czi_path, out_dir=out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert zarr to ome-zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"{project_path}ng_data/sriram-adipo-brain1-im3/fg_ome.zarr\" # path of ome zarr to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_to_omezarr(zarr_path=zarr_paths[0], out_path=out_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View ome-zarr on neuroglancer\n",
    "\n",
    "1. Use https://github.com/google/neuroglancer/blob/master/cors_webserver.py to serve the data e.g. `python cors_webserver.py -d \"/cis/project/sriram/ng_data/\" -p 9010`\n",
    "2. Launch neuroglancer app e.g. https://neuroglancer-demo.appspot.com\n",
    "3. Add layer to neuroglancer app e.g. zarr://http://127.0.0.1:9010/sriram-adipo-brain1-im3/fg_ome.zarr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add trace layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_dir = f\"{out_dir}traces/\"\n",
    "z = zarr.open(out_dir + \"fg.zarr\")\n",
    "volume_size = z.shape\n",
    "chunk_size = z.chunks\n",
    "resolution = [1000000000, 1000000000, 1000000000]\n",
    "\n",
    "outpath = (\n",
    "    f\"precomputed://file://{traces_dir}\"\n",
    ")\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels=1,\n",
    "    layer_type=\"segmentation\",\n",
    "    data_type=\"uint16\", \n",
    "    encoding=\"raw\",\n",
    "    resolution=resolution,  # Voxel scaling, units are in nanometers\n",
    "    voxel_offset=[0, 0, 0],  # x,y,z offset in voxels from the origin\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size=chunk_size,  # units are voxels\n",
    "    volume_size=volume_size,  # e.g. a cubic millimeter dataset\n",
    "    skeletons=\"skeletons\",\n",
    ")\n",
    "vol = CloudVolume(outpath, info=info, compress=False)\n",
    "vol.commit_info()\n",
    "vol.skeleton.meta.commit_info()\n",
    "\n",
    "# remove vertex type attribute because it is a uint8 and incompatible with neuroglancer\n",
    "info_path = f\"{traces_dir}skeletons/info\"\n",
    "with open(info_path) as f:\n",
    "    data = json.load(f)\n",
    "    for i, attr in enumerate(data['vertex_attributes']):\n",
    "        if attr['id'] == 'vertex_types':\n",
    "            data['vertex_attributes'].pop(i)\n",
    "            break\n",
    "\n",
    "with open(info_path, \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, May  4 2021, 03:05:50) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
